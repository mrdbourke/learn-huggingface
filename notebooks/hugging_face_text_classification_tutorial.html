<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Text Classification with Hugging Face Transformers – Learn Hugging Face 🤗</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Learn Hugging Face 🤗</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Natural Language Processing (NLP)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/hugging_face_text_classification_tutorial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Text Classification (work in progress)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tk---overview" id="toc-tk---overview" class="nav-link active" data-scroll-target="#tk---overview"><span class="header-section-number">1</span> TK - Overview</a>
  <ul class="collapse">
  <li><a href="#tk---what-were-going-to-build" id="toc-tk---what-were-going-to-build" class="nav-link" data-scroll-target="#tk---what-were-going-to-build"><span class="header-section-number">1.1</span> TK - What we’re going to build</a></li>
  <li><a href="#tk---what-is-hugging-face" id="toc-tk---what-is-hugging-face" class="nav-link" data-scroll-target="#tk---what-is-hugging-face"><span class="header-section-number">1.2</span> TK - What is Hugging Face?</a></li>
  <li><a href="#tk---why-hugging-face" id="toc-tk---why-hugging-face" class="nav-link" data-scroll-target="#tk---why-hugging-face"><span class="header-section-number">1.3</span> TK - Why Hugging Face?</a></li>
  <li><a href="#tk---what-is-text-classification" id="toc-tk---what-is-text-classification" class="nav-link" data-scroll-target="#tk---what-is-text-classification"><span class="header-section-number">1.4</span> TK - What is text classification?</a></li>
  <li><a href="#tk---why-train-your-own-text-classification-models" id="toc-tk---why-train-your-own-text-classification-models" class="nav-link" data-scroll-target="#tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.5</span> TK - Why train your own text classification models?</a></li>
  </ul></li>
  <li><a href="#tk---importing-necessary-libraries" id="toc-tk---importing-necessary-libraries" class="nav-link" data-scroll-target="#tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</a></li>
  <li><a href="#tk---getting-a-dataset" id="toc-tk---getting-a-dataset" class="nav-link" data-scroll-target="#tk---getting-a-dataset"><span class="header-section-number">3</span> TK - Getting a dataset</a>
  <ul class="collapse">
  <li><a href="#where-can-you-get-more-datasets" id="toc-where-can-you-get-more-datasets" class="nav-link" data-scroll-target="#where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</a></li>
  <li><a href="#loading-the-dataset" id="toc-loading-the-dataset" class="nav-link" data-scroll-target="#loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</a></li>
  <li><a href="#tk---inspect-random-examples-from-the-dataset" id="toc-tk---inspect-random-examples-from-the-dataset" class="nav-link" data-scroll-target="#tk---inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> TK - Inspect random examples from the dataset</a></li>
  </ul></li>
  <li><a href="#tk---preparing-data-for-text-classification" id="toc-tk---preparing-data-for-text-classification" class="nav-link" data-scroll-target="#tk---preparing-data-for-text-classification"><span class="header-section-number">4</span> TK - Preparing data for text classification</a>
  <ul class="collapse">
  <li><a href="#tk---creating-a-mapping-from-labels-to-numbers" id="toc-tk---creating-a-mapping-from-labels-to-numbers" class="nav-link" data-scroll-target="#tk---creating-a-mapping-from-labels-to-numbers"><span class="header-section-number">4.1</span> TK - Creating a mapping from labels to numbers</a></li>
  <li><a href="#tk---split-the-dataset-into-training-and-test-sets" id="toc-tk---split-the-dataset-into-training-and-test-sets" class="nav-link" data-scroll-target="#tk---split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.2</span> TK - Split the dataset into training and test sets</a></li>
  <li><a href="#tk---tokenizing-text-data" id="toc-tk---tokenizing-text-data" class="nav-link" data-scroll-target="#tk---tokenizing-text-data"><span class="header-section-number">4.3</span> TK - Tokenizing text data</a></li>
  <li><a href="#tk---making-a-preprocessing-function-to-tokenize-text" id="toc-tk---making-a-preprocessing-function-to-tokenize-text" class="nav-link" data-scroll-target="#tk---making-a-preprocessing-function-to-tokenize-text"><span class="header-section-number">4.4</span> TK - Making a preprocessing function to tokenize text</a></li>
  <li><a href="#tokenization-takeaways" id="toc-tokenization-takeaways" class="nav-link" data-scroll-target="#tokenization-takeaways"><span class="header-section-number">4.5</span> Tokenization takeaways</a></li>
  </ul></li>
  <li><a href="#tk---setting-up-an-evaluation-metric" id="toc-tk---setting-up-an-evaluation-metric" class="nav-link" data-scroll-target="#tk---setting-up-an-evaluation-metric"><span class="header-section-number">5</span> TK - Setting up an evaluation metric</a></li>
  <li><a href="#tk---setting-up-a-model-for-training" id="toc-tk---setting-up-a-model-for-training" class="nav-link" data-scroll-target="#tk---setting-up-a-model-for-training"><span class="header-section-number">6</span> TK - Setting up a model for training</a>
  <ul class="collapse">
  <li><a href="#tk---create-a-directory-for-saving-models" id="toc-tk---create-a-directory-for-saving-models" class="nav-link" data-scroll-target="#tk---create-a-directory-for-saving-models"><span class="header-section-number">6.1</span> TK - Create a directory for saving models</a></li>
  <li><a href="#tk---setup-training-arguments" id="toc-tk---setup-training-arguments" class="nav-link" data-scroll-target="#tk---setup-training-arguments"><span class="header-section-number">6.2</span> TK - Setup training arguments</a></li>
  <li><a href="#tk---setup-trainer-class" id="toc-tk---setup-trainer-class" class="nav-link" data-scroll-target="#tk---setup-trainer-class"><span class="header-section-number">6.3</span> TK - Setup trainer class</a></li>
  <li><a href="#tk---training-our-text-classification-model" id="toc-tk---training-our-text-classification-model" class="nav-link" data-scroll-target="#tk---training-our-text-classification-model"><span class="header-section-number">6.4</span> TK - Training our text classification model</a></li>
  <li><a href="#tk---inspect-the-model-results" id="toc-tk---inspect-the-model-results" class="nav-link" data-scroll-target="#tk---inspect-the-model-results"><span class="header-section-number">6.5</span> TK - Inspect the model results</a></li>
  <li><a href="#tk---save-the-model-for-later-use" id="toc-tk---save-the-model-for-later-use" class="nav-link" data-scroll-target="#tk---save-the-model-for-later-use"><span class="header-section-number">6.6</span> TK - Save the model for later use</a></li>
  <li><a href="#tk---push-the-model-to-hugging-face-hub" id="toc-tk---push-the-model-to-hugging-face-hub" class="nav-link" data-scroll-target="#tk---push-the-model-to-hugging-face-hub"><span class="header-section-number">6.7</span> TK - Push the model to Hugging Face Hub</a></li>
  <li><a href="#tk---make-and-evaluate-predictions-on-the-test-set" id="toc-tk---make-and-evaluate-predictions-on-the-test-set" class="nav-link" data-scroll-target="#tk---make-and-evaluate-predictions-on-the-test-set"><span class="header-section-number">6.8</span> TK - Make and evaluate predictions on the test set</a></li>
  </ul></li>
  <li><a href="#tk---make-and-inspect-predictions-on-new-text-data" id="toc-tk---make-and-inspect-predictions-on-new-text-data" class="nav-link" data-scroll-target="#tk---make-and-inspect-predictions-on-new-text-data"><span class="header-section-number">7</span> TK - Make and inspect predictions on new text data</a>
  <ul class="collapse">
  <li><a href="#tk---pipeline-mode" id="toc-tk---pipeline-mode" class="nav-link" data-scroll-target="#tk---pipeline-mode"><span class="header-section-number">7.1</span> TK - Pipeline mode</a></li>
  <li><a href="#tk---batch-prediction" id="toc-tk---batch-prediction" class="nav-link" data-scroll-target="#tk---batch-prediction"><span class="header-section-number">7.2</span> TK - Batch prediction</a></li>
  <li><a href="#tk---time-our-model-across-larger-sample-sizes" id="toc-tk---time-our-model-across-larger-sample-sizes" class="nav-link" data-scroll-target="#tk---time-our-model-across-larger-sample-sizes"><span class="header-section-number">7.3</span> TK - Time our model across larger sample sizes</a></li>
  <li><a href="#pytorch-mode" id="toc-pytorch-mode" class="nav-link" data-scroll-target="#pytorch-mode"><span class="header-section-number">7.4</span> PyTorch mode</a></li>
  </ul></li>
  <li><a href="#tk---turning-our-model-into-a-demo" id="toc-tk---turning-our-model-into-a-demo" class="nav-link" data-scroll-target="#tk---turning-our-model-into-a-demo"><span class="header-section-number">8</span> TK - Turning our model into a demo</a>
  <ul class="collapse">
  <li><a href="#tk---creating-a-simple-function-to-perform-inference" id="toc-tk---creating-a-simple-function-to-perform-inference" class="nav-link" data-scroll-target="#tk---creating-a-simple-function-to-perform-inference"><span class="header-section-number">8.1</span> TK - Creating a simple function to perform inference</a></li>
  <li><a href="#tk---uploadingrunning-the-demo" id="toc-tk---uploadingrunning-the-demo" class="nav-link" data-scroll-target="#tk---uploadingrunning-the-demo"><span class="header-section-number">8.2</span> TK - Uploading/running the demo</a></li>
  <li><a href="#tk---testing-the-live-demo" id="toc-tk---testing-the-live-demo" class="nav-link" data-scroll-target="#tk---testing-the-live-demo"><span class="header-section-number">8.3</span> TK - Testing the live demo</a></li>
  </ul></li>
  <li><a href="#tk---exercises-and-extensions" id="toc-tk---exercises-and-extensions" class="nav-link" data-scroll-target="#tk---exercises-and-extensions"><span class="header-section-number">9</span> TK - Exercises and Extensions</a></li>
  <li><a href="#tk---extra-resources" id="toc-tk---extra-resources" class="nav-link" data-scroll-target="#tk---extra-resources"><span class="header-section-number">10</span> TK - Extra resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Text Classification with Hugging Face Transformers</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a target="_blank" href="https://colab.research.google.com/github/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"> </a></p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Next:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add tools used in this overview (e.g. overview of the project)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset with text generation, e.g. 50x spam/not_spam emails and train a classifier on it ✅</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see notebook: https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the dataset to Hugging Face Datasets ✅</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see dataset: https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a classifier on it ✅</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the model to the Hugging Face Model Hub ✅</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a with Gradio and test the model in the wild ✅ </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="tk---overview" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="tk---overview"><span class="header-section-number">1</span> TK - Overview</h2>
<section id="tk---what-were-going-to-build" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="tk---what-were-going-to-build"><span class="header-section-number">1.1</span> TK - What we’re going to build</h3>
<p>In this project, we’re going to learn various aspects of the Hugging Face ecosystem whilst building a text classification model.</p>
<p>To keep things as practical as possible, we’re going to be bulding a <code>food</code>/<code>not_food</code> text classification model.</p>
<p>Given a piece of a text, our model will be able to predict if it’s about food or not.</p>
<p>This is the same kind of model I use in my own work on <a href="https://www.nutrify.app">Nutrify</a> (an app to help people learn about food).</p>
<p>More specifically, we’re going to follow the following steps:</p>
<ol type="1">
<li><strong>Problem defintion and dataset preparation</strong> - Getting a dataset/setting up the problem space.</li>
<li><strong>Finding, training and evaluating a model</strong> - Finding a text classification model suitable for our problem on Hugging Face and customizing it to our own dataset.</li>
<li><strong>Creating a demo and put our model into the real world</strong> - Sharing our trained model in a way others can access and use.</li>
</ol>
<p>By the end of this project, you’ll have a trained model and <a href="https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo">demo on Hugging Face</a> you can share with others.</p>
<p>TK image - see the finished product (demo)</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note this is a hands-on project, so we’ll be focused on writing reusable code and building a model that can be used in the real world. If you are looking for explainers to the theory of what we’re doing, I’ll leave links in the extra-curriculum section.</p>
</div>
</div>
</section>
<section id="tk---what-is-hugging-face" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="tk---what-is-hugging-face"><span class="header-section-number">1.2</span> TK - What is Hugging Face?</h3>
<p>Hugging Face is a platform that offers access to many different kinds of open-source machine learning models and datasets.</p>
<p>They’re also the creators of the popular <code>transformers</code> library which is a Python-based library for working with pre-trained models as well as custom models and datasets.</p>
<p>If you’re getting into the world of AI and machine learning, you’re going to come across Hugging Face.</p>
</section>
<section id="tk---why-hugging-face" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="tk---why-hugging-face"><span class="header-section-number">1.3</span> TK - Why Hugging Face?</h3>
<p>Many of the biggest companies in the world use Hugging Face for their open-source machine learning projects including <a href="https://huggingface.co/apple">Apple</a>, <a href="https://huggingface.co/google">Google</a>, <a href="https://huggingface.co/facebook">Facebook</a> (Meta), <a href="https://huggingface.co/microsoft">Microsoft</a>, <a href="https://huggingface.co/openai">OpenAI</a>, <a href="https://huggingface.co/ByteDance">ByteDance</a> and more.</p>
<p>TK image - image of people using Hugging Face</p>
<p>Not only does Hugging Face make it so you can use state-of-the-art machine learning models such as <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1">Stable Diffusion</a> (for image generation) and <a href="https://huggingface.co/openai/whisper-large-v3">Whipser</a> (for audio transcription) easily, it also makes it so you can share your own models, datasets and resources.</p>
<p>Consider Hugging Face the homepage of your AI/machine learning profile.</p>
</section>
<section id="tk---what-is-text-classification" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="tk---what-is-text-classification"><span class="header-section-number">1.4</span> TK - What is text classification?</h3>
<p>Text classification is the process of assigning a category to a piece of text.</p>
<p>Where a category can be almost anything and a piece of text can be a word, phrase, sentence, paragraph or entire document.</p>
<p>TK image - example of text classification</p>
<p>Example text classification problems include:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Description</strong></th>
<th><strong>Problem Type</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spam email detection</td>
<td>Is an email spam or not spam?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Sentiment analysis</td>
<td>Is a piece of text positive, negative or neutral?</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="odd">
<td>Language detection</td>
<td>What language is a piece of text written in?</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="even">
<td>Topic classification</td>
<td>What topic(s) does a news article belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
<tr class="odd">
<td>Hate speech detection</td>
<td>Is a comment hateful or not hateful?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Product categorization</td>
<td>What categories does a product belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
</tbody>
</table>
<p>There are several different kinds of models you can use for text classification.</p>
<p>And each will have its pros and cons depending on the problem you’re working on.</p>
<p>Example text classification models include:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Description</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Rule-based</td>
<td>Uses a set of rules to classify text (e.g.&nbsp;if text contains “sad” -&gt; sentiment = low)</td>
<td>Simple, easy to understand</td>
<td>Requires manual creation of rules</td>
</tr>
<tr class="even">
<td><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words</a></td>
<td>Counts the frequency of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn’t capture word order</td>
</tr>
<tr class="odd">
<td><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a></td>
<td>Weighs the importance of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn’t capture word order</td>
</tr>
<tr class="even">
<td>Deep learning-based models</td>
<td>Uses neural networks to learn patterns in text</td>
<td>Can learn complex patterns at scale</td>
<td>Can require large amounts of data/compute power to run, not as easy to understand (can be hard to debug)</td>
</tr>
</tbody>
</table>
<p>We’re going to use a deep learning model our case.</p>
<p>Why?</p>
<p>Because Hugging Face helps us do so.</p>
<p>And in most cases, with a large enough dataset, a deep learning model will often perform better than a rule-based or other model.</p>
</section>
<section id="tk---why-train-your-own-text-classification-models" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.5</span> TK - Why train your own text classification models?</h3>
<p>You can use pre-trained models for text classification as well as API-powered models and LLMs such as GPT-4 or Gemini.</p>
<p>However, it’s often a good idea to train your own text classification models for a few reasons:</p>
<ul>
<li>They can be much faster than API-powered models (since they’re running on your own hardware, this can save on costs and time).</li>
<li>They’re customized to your own data.</li>
<li>They don’t require you to send your data elsewhere (privacy).</li>
<li>If a service goes down, you’ll still have access to your model (reliability).</li>
</ul>
<p>TK image - example of training your own model vs using an API-powered model</p>
</section>
</section>
<section id="tk---importing-necessary-libraries" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</h2>
<p>Let’s get started!</p>
<p>First, we’ll import the required libraries.</p>
<p>If you’re running on your local computer, be sure to check out the getting setup guide (tk - link to getting setup guide) to make sure you have everything you need.</p>
<p>If you’re using Google Colab, many of them the following libraries will be installed by default.</p>
<p>However, we’ll have to install a few extras to get everything working.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you’re running on Google Colab, this notebook will work best with access to a GPU. To enable a GPU, go to <code>Runtime</code> ➡️ <code>Change runtime type</code> ➡️ <code>Hardware accelerator</code> ➡️ <code>GPU</code>.</p>
</div>
</div>
<p>We’ll need to install the following libraries from the Hugging Face ecosystem:</p>
<ul>
<li><a href="https://huggingface.co/docs/transformers/en/installation"><code>transformers</code></a> - comes pre-installed on Google Colab but if you’re running on your local machine, you can install it via <code>pip install transformers</code>.</li>
<li><a href="https://huggingface.co/docs/datasets/installation"><code>datasets</code></a> - a library for accessing and manipulating datasets on and off the Hugging Face Hub, you can install it via <code>pip install datasets</code>.</li>
<li><a href="https://huggingface.co/docs/evaluate/installation"><code>evaluate</code></a> - a library for evaluating machine learning model performance with various metrics, you can install it via <code>pip install evaluate</code>.</li>
<li><a href="https://huggingface.co/docs/accelerate/basic_tutorials/install"><code>accelerate</code></a> - a library for training machine learning models faster, you can install it via <code>pip install accelerate</code>.</li>
<li><a href="https://www.gradio.app/guides/quickstart#installation"><code>gradio</code></a> - a library for creating interactive demos of machine learning models, you can install it via <code>pip install gradio</code>.</li>
</ul>
<p>We can also check the versions of our software with <code>package_name.__version__</code>.</p>
<div id="cell-9" class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-outputid="ccd72531-249d-402f-91b0-7b701b2dc7eb" data-scrolled="true" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install dependencies (this is mostly for Google Colab, as the other dependences are available by default in Colab)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ModuleNotFoundError</span>:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span>pip install <span class="op">-</span>U datasets evaluate accelerate gradio <span class="co"># -U stands for "upgrade" so we'll get the latest version by default</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using transformers version: </span><span class="sc">{</span>transformers<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using datasets version: </span><span class="sc">{</span>datasets<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using torch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using transformers version: 4.41.2
Using datasets version: 2.19.1
Using torch version: 2.2.0+cu121</code></pre>
</div>
</div>
<p>Wonderful, as long as your versions are the same or higher to the versions above, you should be able to run the code below.</p>
</section>
<section id="tk---getting-a-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="tk---getting-a-dataset"><span class="header-section-number">3</span> TK - Getting a dataset</h2>
<p>Okay, now we’re got the required libraries, let’s get a dataset.</p>
<p>Getting a dataset is one of the most important things a machine learning project.</p>
<p>The dataset you often determines the type of model you use as well as the quality of the outputs of that model.</p>
<p>Meaning, if you have a high quality dataset, chances are, your future model could also have high quality outputs.</p>
<p>It also means if your dataset is of poor quality, your model will likely also have poor quality outputs.</p>
<p>For a text classificaiton problem, your dataset will likely come in the form of text (e.g.&nbsp;a paragraph, sentence or phrase) and a label (e.g.&nbsp;what category the text belongs to).</p>
<ul>
<li>TK image - showcase what a supervised dataset looks like (e.g.&nbsp;text and label, this can be the dataset we’ve got on Hugging Face hub, showcase the different parts of the dataset as well including the name etc)</li>
</ul>
<p>In our case, our dataset comes in the form of a collection of synthetic image captions and their corresponding labels (food or not food).</p>
<p>This is a dataset I’ve created earlier to help us practice building a text classification model.</p>
<p>You can find it on Hugging Face under the name <a href="https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions"><code>mrdbourke/learn_hf_food_not_food_image_captions</code></a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resource
</div>
</div>
<div class="callout-body-container callout-body">
<p>See how the food/not_food image caption dataset was created in the (TK - add notebook link and title, make this available on the website)</p>
<ul>
<li>TK - see dataset creation:
<ul>
<li>Done, see notebook: https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing</li>
<li>Done, see dataset: https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions</li>
</ul></li>
</ul>
</div>
</div>
<section id="where-can-you-get-more-datasets" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</h3>
<p>The are many different places you can get datasets for text-based problems.</p>
<p>One of the best places is on the Hugging Face Hub, specifically <a href="https://huggingface.co/datasets">huggingface.co/datasets</a>.</p>
<p>Here you can find many different kinds of problem specific data such as <a href="https://huggingface.co/datasets?task_categories=task_categories:text-classification&amp;sort=trending">text classification</a>.</p>
<p>TK image - show example image of text classification datasets</p>
</section>
<section id="loading-the-dataset" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</h3>
<p>Once we’ve found/prepared a dataset on the Hugging Face Hub, we can use the <code>datasets</code> library to load it.</p>
<p>To load a dataset we can use the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/loading_methods#datasets.load_dataset"><code>datasets.load_dataset(path=NAME_OR_PATH_OF_DATASET)</code></a> function and pass it the name/path of the dataset we want to load.</p>
<p>In our case, our dataset name is <code>mrdbourke/learn_hf_food_not_food_image_captions</code>.</p>
<p>And since our dataset is hosted on Hugging Face, when we run the following code for the first time, it will download it.</p>
<p>If your target dataset is quite large, this download may take a while.</p>
<p>However, once the dataset is downloaded, subsequent reloads will be mush faster.</p>
<div id="cell-14" class="cell" data-outputid="2f45489c-02e8-4c03-bb7c-d73faa46c5b1" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset from Hugging Face Hub</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> datasets.load_dataset(path<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_image_captions"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the dataset</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 250
    })
})</code></pre>
</div>
</div>
<p>Dataset loaded!</p>
<p>Looks like our dataset has two features, <code>text</code> and <code>label</code>.</p>
<p>And 250 total rows (the number of examples in our dataset).</p>
<p>We can check the column names with <code>dataset.column_names</code>.</p>
<div id="cell-16" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What features are there?</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dataset.column_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>{'train': ['text', 'label']}</code></pre>
</div>
</div>
<p>Looks like our dataset comes with a <code>train</code> split already (the whole dataset).</p>
<p>We can access the <code>train</code> split with <code>dataset["train"]</code> (some datasets also come with built-in <code>"test"</code> splits too).</p>
<div id="cell-18" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the training split</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 250
})</code></pre>
</div>
</div>
<p>How about we check out a single sample?</p>
<p>We can do so with indexing.</p>
<div id="cell-20" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
 'label': 'food'}</code></pre>
</div>
</div>
<p>Nice! We get back a dictionary with the keys <code>text</code> and <code>label</code>.</p>
<p>The <code>text</code> key contains the text of the image caption and the <code>label</code> key contains the label (food or not food).</p>
</section>
<section id="tk---inspect-random-examples-from-the-dataset" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="tk---inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> TK - Inspect random examples from the dataset</h3>
<p>At 250 total samples, our dataset isn’t too large.</p>
<p>So we could sit there and explore the samples one by one.</p>
<p>But whenever I interact with a new dataset, I like to view a bunch of random examples and get a <em>feel</em> of the data.</p>
<p>Doing so is inline with the data explorer’s motto: <em>visualize, visualize, visualize!</em></p>
<p>As a rule of thumb, I like to view at least 20-100 random examples when interacting with a new dataset.</p>
<p>Let’s write some code to view 5 random indexes of our data and their corresponding text and labels at a time.</p>
<div id="cell-23" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>random_indexs <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset[<span class="st">"train"</span>])), <span class="dv">5</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> dataset[<span class="st">"train"</span>][random_indexs]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random samples from dataset:</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> <span class="bu">zip</span>(random_samples[<span class="st">"text"</span>], random_samples[<span class="st">"label"</span>]):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>item[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> | Label: </span><span class="sc">{</span>item[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random samples from dataset:

Text: A boy building a fort in the living room with his curious cat watching | Label: not_food
Text: Set of straws held in a holder | Label: not_food
Text: Yoga mat rolled up and ready in a corner | Label: not_food
Text: Crunchy sushi roll with a creamy filling, featuring shrimp tempura and avocado. | Label: food
Text: A gourmet pizza with a pesto base, topped with grilled chicken and sun-dried tomatoes | Label: food</code></pre>
</div>
</div>
<p>Beautiful! Looks like our data contains a mix of shorter and longer sentences (between 5 and 20 words) of texts about food and not food.</p>
<p>We can get the unique labels in our dataset with <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.unique"><code>dataset["train"].unique("label")</code></a>.</p>
<div id="cell-25" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get unique label values</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>].unique(<span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>['food', 'not_food']</code></pre>
</div>
</div>
<p>If our dataset is small enough to fit into memory, we can count the number of different labels with Python’s <a href="https://docs.python.org/3/library/collections.html#counter-objects"><code>collections.Counter</code></a> (a method for counting objects in an iterable or mapping).</p>
<div id="cell-27" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check number of each label</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>Counter(dataset[<span class="st">"train"</span>][<span class="st">"label"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Counter({'food': 125, 'not_food': 125})</code></pre>
</div>
</div>
<p>Excellent, looks like our dataset is well balanced with 125 samples of food and 125 samples of not food.</p>
<p>In a binary classification case, this is ideal.</p>
<p>If the classes were dramatically unbalanced (e.g.&nbsp;90% food and 10% not food) we might have to consider collecting/creating more data.</p>
<p>But best to train a model and see how it goes before making any drastic dataset changes.</p>
<p>Because our dataset is small, we could also inspect it via a pandas DataFrame (however, this may not be possible for extremely large datasets).</p>
<div id="cell-29" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn our dataset into a DataFrame and get a random sample</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df <span class="op">=</span> pd.DataFrame(dataset[<span class="st">"train"</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>food_not_food_df.sample(<span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">207</td>
<td>Walking in the park, a man jogs with his energ...</td>
<td>not_food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">116</td>
<td>A girl feeding her rabbit in the garden</td>
<td>not_food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">241</td>
<td>Close-up of a sushi roll with avocado, cucumbe...</td>
<td>food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">127</td>
<td>Zucchini in a bowl, sprinkled with basil and s...</td>
<td>food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">187</td>
<td>Assorted sushi rolls on a plate, featuring Cal...</td>
<td>food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">83</td>
<td>Stack of books waiting to be read on a bookshelf</td>
<td>not_food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">95</td>
<td>Set of keys hanging on a hook by the door</td>
<td>not_food</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-30" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the value counts of the label column</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df[<span class="st">"label"</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>label
food        125
not_food    125
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
</section>
<section id="tk---preparing-data-for-text-classification" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="tk---preparing-data-for-text-classification"><span class="header-section-number">4</span> TK - Preparing data for text classification</h2>
<p>We’ve got our data ready but there are a few steps we’ll need to take before we can model it.</p>
<p>The main two being:</p>
<ol type="1">
<li><strong>Tokenization</strong> - turning our text into a numerical representation (machines prefer numbers rather than words), for example, <code>{"a": 0, "b": 1, "c": 2...}</code>.</li>
<li><strong>Creating a train/test split</strong> - right now our data is in a training split only but we’ll create a test set to evaluate our model’s performance.</li>
</ol>
<p>These don’t necessarily have to be in order either.</p>
<p>Before we get to them, let’s create a small mapping from our labels to numbers.</p>
<p>In the same way we need to tokenize our text into numerical representation, we also need to do the same for our labels.</p>
<section id="tk---creating-a-mapping-from-labels-to-numbers" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="tk---creating-a-mapping-from-labels-to-numbers"><span class="header-section-number">4.1</span> TK - Creating a mapping from labels to numbers</h3>
<p>Our machine learning model will want to see all numbers.</p>
<p>This goes for text as well as label input.</p>
<p>So let’s create a mapping from our labels to numbers.</p>
<p>Since we’ve only got a couple of labels (<code>"food"</code> and <code>"not_food"</code>), we can create a dictionary to map them to numbers, however, if you’ve got a fair few labels, you may want to make this mapping programmatically.</p>
<p>We can use these dictionaries later on for our model training as well as evaluation.</p>
<div id="cell-33" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping from id2label and label2id</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"not_food"</span>, <span class="dv">1</span>: <span class="st">"food"</span>}</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {<span class="st">"not_food"</span>: <span class="dv">0</span>, <span class="st">"food"</span>: <span class="dv">1</span>}</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label to ID mapping: </span><span class="sc">{</span>label2id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ID to Label mapping: </span><span class="sc">{</span>id2label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label to ID mapping: {'not_food': 0, 'food': 1}
ID to Label mapping: {0: 'not_food', 1: 'food'}</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a binary classification task, the positive class, in our case <code>"food"</code>, is usually given the label <code>1</code> and the negative class (<code>"not_food"</code>) is given the label <code>0</code>.</p>
</div>
</div>
<div id="cell-35" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mappings programmatically from dataset</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {idx: label <span class="cf">for</span> idx, label <span class="kw">in</span> <span class="bu">enumerate</span>(dataset[<span class="st">"train"</span>].unique(<span class="st">"label"</span>)[::<span class="op">-</span><span class="dv">1</span>])} <span class="co"># reverse sort list to have "not_food" first</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {label: idx <span class="cf">for</span> idx, label <span class="kw">in</span> id2label.items()}</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label to ID mapping: </span><span class="sc">{</span>label2id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ID to Label mapping: </span><span class="sc">{</span>id2label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label to ID mapping: {'not_food': 0, 'food': 1}
ID to Label mapping: {0: 'not_food', 1: 'food'}</code></pre>
</div>
</div>
<p>With our dictionary mappings created, we can update the labels of our dataset to be numeric.</p>
<p>We can do this using the <a href="https://huggingface.co/docs/datasets/en/process#map"><code>datasets.Dataset.map</code></a> method and passing it a function to apply to each example.</p>
<p>Let’s create a small function which turns an example label into a number.</p>
<div id="cell-37" class="cell" data-outputid="eba840c3-7652-41a8-a121-546cb9a8147f" data-execution_count="13">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn labels into 0 or 1 (e.g. 0 for "not_food", 1 for "food")</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> map_labels_to_number(example):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  example[<span class="st">"label"</span>] <span class="op">=</span> label2id[example[<span class="st">"label"</span>]]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> example</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>example_sample <span class="op">=</span> {<span class="st">"text"</span>: <span class="st">"This is a sentence about my favourite food: honey."</span>, <span class="st">"label"</span>: <span class="st">"food"</span>}</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>map_labels_to_number(example_sample)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>{'text': 'This is a sentence about my favourite food: honey.', 'label': 1}</code></pre>
</div>
</div>
<p>Looks like our function works!</p>
<p>How about we map it to the whole dataset?</p>
<div id="cell-39" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map our dataset labels to numbers</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset[<span class="st">"train"</span>].<span class="bu">map</span>(map_labels_to_number)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>dataset[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
  'Set of books stacked on a desk',
  'Watching TV together, a family has their dog stretched out on the floor',
  'Wooden dresser with a mirror reflecting the room',
  'Lawn mower stored in a shed'],
 'label': [1, 0, 0, 0, 0]}</code></pre>
</div>
</div>
<p>Nice! Looks like our labels are all numerical now.</p>
<p>We can check a few random samples using <a href="https://huggingface.co/docs/datasets/en/process#shuffle"><code>dataset.shuffle()</code></a> and indexing for the first few.</p>
<div id="cell-41" class="cell" data-outputid="8089bfe3-2322-4bac-d2fd-89f626d0a1e6" data-execution_count="15">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the dataset and view the first 5 samples (will return different results each time) </span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>dataset.shuffle()[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'text': ['Celery in a bowl, served with a side of peanut butter and a sprinkle of raisins for a classic, tasty snack.',
  'A whole pizza pie with a thin and crispy crust',
  'Three black dogs laying on the garage floor with a blue car in the background',
  'Working from home at her desk, a woman deals with a cat sitting on the keyboard',
  'Set of forks kept in a holder'],
 'label': [1, 1, 0, 0, 0]}</code></pre>
</div>
</div>
</section>
<section id="tk---split-the-dataset-into-training-and-test-sets" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="tk---split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.2</span> TK - Split the dataset into training and test sets</h3>
<p>Right now our dataset only has a training split.</p>
<p>However, we’d like to create a test split so we can evaluate our model.</p>
<p>In essence, our model will learn patterns (the relationship between text captions and their labels of food/not_food) on the training data.</p>
<p>And we will evaluate those learned patterns on the test data.</p>
<p>We can split our data using the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.train_test_split"><code>datasets.Dataset.train_test_split</code></a> method.</p>
<p>We can use the <code>test_size</code> parameter to define the percentage of data we’d like to use in our test set (e.g.&nbsp;<code>test_size=0.2</code> would mean 20% of the data goes to the test set).</p>
<div id="cell-43" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train/test splits</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>) <span class="co"># note: seed isn't needed, just here for reproducibility, without it you will get different splits each time you run the cell</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 200
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 50
    })
})</code></pre>
</div>
</div>
<p>Perfect!</p>
<p>Our dataset has been split into 200 training examples and 50 testing examples.</p>
<p>Let’s visualize a few random examples to make sure they still look okay.</p>
<div id="cell-45" class="cell" data-outputid="35f0da00-ab15-42e0-9d81-757ad3da1618" data-execution_count="17">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>random_idx_train <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"train"</span>]))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>random_sample_train <span class="op">=</span> dataset[<span class="st">"train"</span>][random_idx_train]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>random_idx_test <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"test"</span>]))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>random_sample_test <span class="op">=</span> dataset[<span class="st">"test"</span>][random_idx_test]</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from training dataset:"</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_train[<span class="st">'text'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Label: </span><span class="sc">{</span>random_sample_train[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_train[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from testing dataset:"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_test[<span class="st">'text'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Label: </span><span class="sc">{</span>random_sample_test[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_test[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random sample from training dataset:
Text: Set of headphones resting on a desk
Label: 0 (not_food)

[INFO] Random sample from testing dataset:
Text: Yoga mat rolled up and ready in a corner
Label: 0 (not_food)</code></pre>
</div>
</div>
</section>
<section id="tk---tokenizing-text-data" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="tk---tokenizing-text-data"><span class="header-section-number">4.3</span> TK - Tokenizing text data</h3>
<p>Labels numericalized, dataset split, time to turn our text into numbers.</p>
<p>Tokenization is the process of converting a non-numerical data source into numbers.</p>
<p>Why?</p>
<p>Because machines (especially machine learning models) prefer numbers to human-style data.</p>
<p>In the case of the text <code>"I love pizza"</code> a very simple method of tokenization might be to convert each word to a number.</p>
<p>For example, <code>{"I": 0, "love": 1, "pizza": 2}</code>.</p>
<p>However, for most modern machine learning models, the tokenization process is a bit more nuanced.</p>
<p>For example, the text <code>"I love pizza"</code> might be tokenized into something more like <code>[101, 1045, 2293, 10733, 102]</code>.</p>
<p>TK image - showcase an example using OpenAI’s tokenization tool and what this looks like with “I love pizza”: https://platform.openai.com/tokenizer</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Depending on the model you use, the tokenization process could be different. For example, one model might turn <code>"I love pizza"</code> into <code>[40, 3021, 23317]</code>, where as another model might turn it into <code>[101, 1045, 2293, 10733, 102]</code>.</p>
<p>To deal with this, Hugging Face models often pair models with their own tokenizers by pairing a tokenizer configuration with a model’s weights.</p>
<p>Such is the case with <a href="https://huggingface.co/distilbert/distilbert-base-uncased"><code>distilbert/distilbert-base-uncased</code></a> (there is a <code>tokenizer.json</code> file as well as a <code>tokenizer_config.json</code> file which contains all of the tokenizer implementation details).</p>
<p>For more examples of tokenization, you can see OpenAI’s <a href="https://platform.openai.com/tokenizer">tokenization visualizer tool</a> as well as their open-source library <a href="https://github.com/openai/tiktoken"><code>tiktoken</code></a>, Google also have an open-source tokenization library called <a href="https://github.com/google/sentencepiece"><code>sentencepiece</code></a>, finally Hugging Face’s <a href="https://github.com/huggingface/tokenizers"><code>tokenizers</code></a> library is also a great resource (this is what we’ll be using behind the scenes).</p>
</div>
</div>
<p>Many of the text-based models on Hugging Face come paired with their own tokenizer.</p>
<p>For example, the <a href="https://huggingface.co/distilbert/distilbert-base-uncased"><code>distilbert/distilbert-base-uncased</code></a> model can be used with the <code>distilbert/distilbert-base-uncased</code> tokenizer.</p>
<p>We can load the tokenizer for a given model using the <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes"><code>transformers.AutoTokenizer.from_pretrained</code></a> method and passing it the name of the model we’d like to use.</p>
<p>The <code>transformers.AutoTokenizer</code> class is part of a series of Auto Classes (such as <code>AutoConfig</code>, <code>AutoModel</code>, <code>AutoProcessor</code>) which automatically loads the correct configuration settings for a given model.</p>
<p>Let’s load the tokenizer for the <code>distilbert/distilbert-base-uncased</code> model and see how it works.</p>
<p>UPTOHERE - “why this model?”, add reasoning to why the distilbert model, Hugging Face has many models, often it takes a bit of practice to see which is best to use</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why use the <code>distilbert/distilbert-base-uncased</code> model?</p>
<p>The short answer is that I’ve used it before and it works well (and fast) on various text classification tasks.</p>
<p>The longer answer is that Hugging Face has many available open-source models for many different problems available at <a href="https://huggingface.co/models">https://huggingface.co/models</a>.</p>
<p>Navigating these models can take some practice.</p>
<p>And several models may be suited for the same task (though with various tradeoffs such as size and speed).</p>
<p>However, overtime and with adequate experimentation, you’ll start to build an intuition on which models are good for which problems.</p>
</div>
</div>
<div id="cell-47" class="cell" data-outputid="f277b622-267d-4d06-b2cb-6bc204b2f62d" data-execution_count="18">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(pretrained_model_name_or_path<span class="op">=</span><span class="st">"distilbert/distilbert-base-uncased"</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                                          use_fast<span class="op">=</span><span class="va">True</span>) <span class="co"># uses fast tokenization (backed by tokenziers library and implemented in Rust) by default, if not available will default to Python implementation</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>tokenizer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
    0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    100: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    101: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    102: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    103: AddedToken("[MASK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}</code></pre>
</div>
</div>
<p>Nice!</p>
<p>There’s our tokenizer!</p>
<p>It’s an instance of the <a href="https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"><code>transformers.DistilBertTokenizerFast</code></a> class.</p>
<p>You can read more about it in the documentation.</p>
<p>For now, let’s try it out by passing it a string of text.</p>
<div id="cell-49" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out tokenizer</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"I love pizza"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<div id="cell-50" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try adding a "!" at the end</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"I love pizza!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>Woohoo!</p>
<p>Our text gets turned into numbers (or tokens).</p>
<p>Notice how with even a slight change in the text, the tokenizer produces different results?</p>
<p>The <code>input_ids</code> are our tokens.</p>
<p>And the <code>attention_mask</code> (in our case, all <code>[1, 1, 1, 1, 1, 1]</code>) is a mask which tells the model which tokens to use or not. Tokens with a mask value of <code>1</code> get used and tokens with a mask value of <code>0</code> get ignored.</p>
<p>There are several attributes of the <code>tokenizer</code> we can explore.</p>
<ul>
<li><code>tokenizer.vocab</code> will return the vocabulary of the tokenizer or in other words, the unique words/word pieces the tokenizer is capable of converting into numbers.</li>
<li><code>tokenizer.model_max_length</code> will return the maximum length of a sequence the tokenizer can process, pass anything longer than this and the sequence will be truncated.</li>
</ul>
<div id="cell-52" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the length of the vocabulary </span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>length_of_tokenizer_vocab <span class="op">=</span> <span class="bu">len</span>(tokenizer.vocab)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Length of tokenizer vocabulary: </span><span class="sc">{</span>length_of_tokenizer_vocab<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the maximum sequence length the tokenizer can handle</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>max_tokenizer_input_sequence_length <span class="op">=</span> tokenizer.model_max_length</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max tokenizer input sequence length: </span><span class="sc">{</span>max_tokenizer_input_sequence_length<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length of tokenizer vocabulary: 30522
Max tokenizer input sequence length: 512</code></pre>
</div>
</div>
<p>Woah, looks like our tokenizer has a vocabulary of <code>30,522</code> different words and word pieces.</p>
<p>And it can handle a sequence length of up to <code>512</code> (any sequence longer than this will be automatically truncated from the end).</p>
<p>Let’s check out some of the vocab.</p>
<p>Can I find my own name?</p>
<div id="cell-54" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Does "daniel" occur in the vocab?</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"daniel"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>3817</code></pre>
</div>
</div>
<p>Oooh, looks like my name is <code>3817</code> in the tokenizer’s vocab.</p>
<p>Can you find your own name? (note: there may be an error if the token doesn’t exist, we’ll get to this)</p>
<p>How about “pizza”?</p>
<div id="cell-56" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"pizza"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>10733</code></pre>
</div>
</div>
<p>What if a word doesn’t exist in the vocab?</p>
<div id="cell-58" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"akash"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[24], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg">tokenizer</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">vocab</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">akash</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">]</span>

<span class="ansi-red-fg">KeyError</span>: 'akash'</pre>
</div>
</div>
</div>
<p>Dam, we get a <code>KeyError</code>.</p>
<p>Not to worry, this is okay, since when calling the <code>tokenizer</code> on the word, it will automatically split the word into word pieces or subwords.</p>
<div id="cell-60" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"akash"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>{'input_ids': [101, 9875, 4095, 102], 'attention_mask': [1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>It works!</p>
<p>We can check what word pieces <code>"akash"</code> got broken into with <a href="https://huggingface.co/docs/transformers/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.convert_ids_to_tokens"><code>tokenizer.convert_ids_to_tokens(input_ids)</code></a>.</p>
<div id="cell-62" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>tokenizer.convert_ids_to_tokens(tokenizer(<span class="st">"akash"</span>).input_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>['[CLS]', 'aka', '##sh', '[SEP]']</code></pre>
</div>
</div>
<p>Ahhh, it seems <code>"akash"</code> was split into two tokens, <code>["aka", "##sh"]</code>.</p>
<p>The <code>"##"</code> at the start of <code>"##sh"</code> means that the sequence is part of a larger sequence.</p>
<p>And the <code>"[CLS]"</code> and <code>"[SEP]"</code> tokens are special tokens indicating the start and end of a sequence.</p>
<p>Now, since tokenizers can deal with any text, what if there was an unknown token?</p>
<p>For example, rather than <code>"pizza"</code> someone used the pizza emoji 🍕?</p>
<p>Let’s try!</p>
<div id="cell-64" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to tokenize an emoji</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>tokenizer.convert_ids_to_tokens(tokenizer(<span class="st">"🍕"</span>).input_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>['[CLS]', '[UNK]', '[SEP]']</code></pre>
</div>
</div>
<p>Ahh, we get the special <code>"[UNK]"</code> token.</p>
<p>This stands for “unknown”.</p>
<p>The combination of word pieces and <code>"[UNK]"</code> special token means that our <code>tokenizer</code> will be able to turn almost any text into numbers for our model.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Keep in mind that just because one tokenizer uses an unknown special token for a particular word or emoji (🍕) doesn’t mean another will.</p>
</div>
</div>
<p>Since the <code>tokenizer.vocab</code> is a Python dictionary, we can get a sample of the vocabulary using <code>tokenizer.vocab.items()</code>.</p>
<p>How about we get the first 5?</p>
<div id="cell-66" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first 5 items in the tokenizer vocab</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(tokenizer.vocab.items())[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>[('!', 999), ('"', 1000), ('#', 1001), ('##!', 29612), ('##"', 29613)]</code></pre>
</div>
</div>
<p>There’s our <code>'!'</code> from before! Looks like the first five items are all related to punctuation points.</p>
<p>How about a random sample of tokens?</p>
<div id="cell-68" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>random.sample(<span class="bu">sorted</span>(tokenizer.vocab.items()), k<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>[('##র', 29908),
 ('glove', 15913),
 ('1952', 3999),
 ('certified', 7378),
 ('र', 1333)]</code></pre>
</div>
</div>
</section>
<section id="tk---making-a-preprocessing-function-to-tokenize-text" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="tk---making-a-preprocessing-function-to-tokenize-text"><span class="header-section-number">4.4</span> TK - Making a preprocessing function to tokenize text</h3>
<p>Rather than tokenizing our texts one by one, it’s best practice to define a preprocessing function which does it for us.</p>
<p>This process works regardless of whether you’re working with text data or other kinds of data such as images or audio.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Turning data into numbers
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any kind of machine learning workflow, an important first step is turning your input data into numbers.</p>
<p>As machine learning models are algorithms which find patterns in numbers, before they can find patterns in your data (text, images, audio, tables) it must be numerically encoded first (e.g.&nbsp;tokenizing text).</p>
<p>To help with this, <code>transformers</code> has an <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoProcessor"><code>AutoProcessor</code></a> class which can preprocess data in a specific format required for a paired model.</p>
</div>
</div>
<p>To prepare our text data, let’s create a preprocessing function to take in a dictionary which contains the key <code>"text"</code> which has the value of a target string (our data samples come in the form of dictionaries) and then returns the tokenized <code>"text"</code>.</p>
<p>We’ll set the following parameters in our <code>tokenizer</code>:</p>
<ul>
<li><code>padding=True</code> - This will make all the sequences in a batch the same length by padding shorter sequences with 0’s until they equal the longest size in the batch. Why? If there are different size sequences in a batch, you can sometimes run into dimensionality issues.</li>
<li><code>truncation=True</code> - This will shorten sequences longer than the model can handle to the model’s max input size (e.g.&nbsp;if a sequence is 1000 long and the model can handle 512, it will be shortened to 512 via removing all tokens after 512).</li>
</ul>
<p>You can see more parameters available for the <code>tokenizer</code> in the <a href="https://huggingface.co/docs/transformers/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"><code>transformers.PreTrainedTokenizer</code> documentation</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For more on padding and truncation (two important concepts in sequence processing), I’d recommend reading the Hugging Face documentation on <a href="https://huggingface.co/docs/transformers/en/pad_truncation">Padding and Truncation</a>.</p>
</div>
</div>
<div id="cell-70" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_text(examples):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Tokenize given example text and return the tokenized text.</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>],</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                     padding<span class="op">=</span><span class="va">True</span>, <span class="co"># pad short sequences to longest sequence in the batch</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>                     truncation<span class="op">=</span><span class="va">True</span>) <span class="co"># truncate long sequences to the maximum length the model can handle</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wonderful!</p>
<p>Now let’s try it out on an example sample.</p>
<div id="cell-72" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>example_sample_2 <span class="op">=</span> {<span class="st">"text"</span>: <span class="st">"I love pizza"</span>, <span class="st">"label"</span>: <span class="dv">1</span>}</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>tokenize_text(example_sample_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>Looking good!</p>
<p>How about we map our <code>tokenize_text</code> function to our whole <code>dataset</code>?</p>
<p>We can do so with the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.map"><code>datasets.Dataset.map</code> method</a>.</p>
<p>The <code>map</code> method allows us to apply a given function to all examples in a dataset.</p>
<p>By setting <code>batched=True</code> we can apply the given function to batches of examples (many at a time) to speed up computation time.</p>
<p>Let’s create a <code>tokenized_dataset</code> object by calling <code>map</code> on our <code>dataset</code> and passing it our <code>tokenize_text</code> function.</p>
<div id="cell-74" class="cell" data-outputid="d72b4325-b4de-4f65-f930-50007d45c8d5" data-execution_count="43">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset.map() docs -&gt; https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.map </span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(function<span class="op">=</span>tokenize_text, </span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>                                batched<span class="op">=</span><span class="va">True</span>, <span class="co"># set batched=True to operate across batches of examples rather than only single examples</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>                                batch_size<span class="op">=</span><span class="dv">1000</span>) <span class="co"># defaults to 1000, can be increased if you have a large dataset</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>tokenized_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 200
    })
    test: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 50
    })
})</code></pre>
</div>
</div>
<p>Dataset tokenized!</p>
<p>Let’s inspect a pair of samples.</p>
<div id="cell-76" class="cell" data-outputid="c1b0b958-b9a5-4274-e8c1-eaf0ac4cdf3a" data-execution_count="47">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get two samples from the tokenized dataset</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>train_tokenized_sample <span class="op">=</span> tokenized_dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>test_tokenized_sample <span class="op">=</span> tokenized_dataset[<span class="st">"test"</span>][<span class="dv">0</span>]</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key <span class="kw">in</span> train_tokenized_sample.keys():</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Key: </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Train sample: </span><span class="sc">{</span>train_tokenized_sample[key]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Test sample: </span><span class="sc">{</span>test_tokenized_sample[key]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Key: text
Train sample: Set of headphones placed on a desk
Test sample: A slice of pepperoni pizza with a layer of melted cheese

[INFO] Key: label
Train sample: 0
Test sample: 1

[INFO] Key: input_ids
Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

[INFO] Key: attention_mask
Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
</code></pre>
</div>
</div>
<p>Beautiful! Our samples have been tokenized.</p>
<p>Notice the zeroes on the end of the <code>inpud_ids</code> and <code>attention_mask</code> values.</p>
<p>These are padding tokens to ensure that each sample has the same length as the longest sequence in a given batch.</p>
<p>We can now use these tokenized samples later on in our model.</p>
</section>
<section id="tokenization-takeaways" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="tokenization-takeaways"><span class="header-section-number">4.5</span> Tokenization takeaways</h3>
<p>We’ve seen tokenizers in practice.</p>
<p>A few takeaways before we start to build a model:</p>
<ul>
<li>Tokenizers are used to turn text (or other forms of data such as images and audio) into a numerical representation ready to be used with a machine learning model.</li>
<li>Many models reuse existing tokenizers and many models have their own specific tokenizer paired with them. Hugging Face’s <code>transformers.AutoTokenizer</code>, <code>transformers.AutoProcessor</code> and <code>transformers.AutoModel</code> classes make it easy to pair tokenizers and models based on their name (e.g.&nbsp;<code>distilbert/distilbert-base-uncased</code>).</li>
</ul>
</section>
</section>
<section id="tk---setting-up-an-evaluation-metric" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="tk---setting-up-an-evaluation-metric"><span class="header-section-number">5</span> TK - Setting up an evaluation metric</h2>
<p>Aside from training a model, one of the most important steps in machine learning is evaluating a model.</p>
<p>To do, we can use evaluation metrics.</p>
<p>There are many different kinds of evaluation metrics for various problems.</p>
<p>But since we’re focused on text classification, we’ll use <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification">accuracy</a> as our evaluation metric.</p>
<p>A model which gets 99/100 predictions correct has an accuracy of 99%.</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{correct classifications}}{\text{all classifications}}
\]</span></p>
<p>For some projects, you may have a minimum standard of a metric.</p>
<p>For example, when I worked on an insurance claim classification model, the clients required over 98% accuracy for it to be viable to use in production.</p>
<p>We can craft these evaluation metrics ourselves.</p>
<p>However, Hugging Face has a library called <a href="https://huggingface.co/docs/evaluate/en/index"><code>evaluate</code></a> which has various metrics built in ready to use.</p>
<p>We can load a metric using <code>evaluate.load("METRIC_NAME")</code>.</p>
<p>Let’s load in <code>"accuracy"</code> and build a function to measure accuracy by comparing arrays of predictions and labels.</p>
<div id="cell-80" class="cell" data-outputid="4a2b0f85-db47-4f0f-cbc3-fa148c19a646" data-execution_count="56">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>accuracy_metric <span class="op">=</span> evaluate.load(<span class="st">"accuracy"</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Computes the accuracy of a model by comparing the predictions and labels.</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>  predictions, labels <span class="op">=</span> predictions_and_labels</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get highest prediction probability of each prediction if predictions are probabilities</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(predictions.shape) <span class="op">&gt;=</span> <span class="dv">2</span>:</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> accuracy_metric.compute(predictions<span class="op">=</span>predictions, references<span class="op">=</span>labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Accuracy function created!</p>
<p>Now let’s test it out.</p>
<div id="cell-82" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create example list of predictions and labels</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>example_predictions_all_correct <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>example_predictions_one_wrong <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>example_labels <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy when all predictions are correct: </span><span class="sc">{</span>compute_accuracy((example_predictions_all_correct, example_labels))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy when one prediction is wrong: </span><span class="sc">{</span>compute_accuracy((example_predictions_one_wrong, example_labels))<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy when all predictions are correct: {'accuracy': 1.0}
Accuracy when one prediction is wrong: {'accuracy': 0.9}</code></pre>
</div>
</div>
<p>Excellent, our function works just as we’d like.</p>
<p>When all predictions are correct, it scores 1.0 (or 100% accuracy) and when 9/10 predictions are correct, it returns 0.9 (or 90% accuracy).</p>
<p>We can use this function during training and evaluation of our model.</p>
</section>
<section id="tk---setting-up-a-model-for-training" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="tk---setting-up-a-model-for-training"><span class="header-section-number">6</span> TK - Setting up a model for training</h2>
<p>UPTOHERE</p>
<p>Next:</p>
<ul>
<li>loading a model</li>
<li>trying to make a prediction (failing)</li>
<li>inspecting the architecture of the model</li>
<li>counting the number of parameters (can use this model on smaller devices)</li>
<li>preparing it for sequence classification</li>
<li>creating a save dir</li>
<li>setting up TrainingArguments (read the docs)</li>
</ul>
<p>See: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#train</p>
<ul>
<li>TK image - steps for training in Hugging Face</li>
</ul>
<p>Steps for training:</p>
<ol type="1">
<li>Create and preprocess data</li>
<li>Define model</li>
<li>Define training arguments</li>
<li>Pass training arguments to Trainer</li>
<li>Call <code>train()</code></li>
</ol>
<ul>
<li>TK - What kind of training are we doing? Supervised learning + fine-tuning an existing model</li>
</ul>
<div id="cell-85" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - Remember these</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>id2label, label2id</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>({0: 'not_food', 1: 'food'}, {'not_food': 0, 'food': 1})</code></pre>
</div>
</div>
<div id="cell-86" class="cell" data-outputid="ed01beb4-3cf7-4209-eaea-444e5aa51c5b" data-execution_count="61">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># AutoModelForSequenceClassification docs -&gt; https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification </span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This model comes with a sequence classification head </span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    pretrained_model_name_or_path<span class="op">=</span><span class="st">"distilbert/distilbert-base-uncased"</span>,</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">2</span>, <span class="co"># can customize this to the number of classes in your dataset</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    id2label<span class="op">=</span>id2label,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    label2id<span class="op">=</span>label2id</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<ul>
<li>TK - notice this output on pretraining advice</li>
</ul>
<blockquote class="blockquote">
<p>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: [‘classifier.bias’, ‘classifier.weight’, ‘pre_classifier.bias’, ‘pre_classifier.weight’] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p>
</blockquote>
<p>Let’s try and make a prediction with our model and see what happens.</p>
<div id="cell-88" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try and make a prediction with the loaded model (this will error)</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>model(<span class="op">**</span>tokenized_dataset[<span class="st">"train"</span>][:<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[71], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Try and make a prediction with the loaded model (this will error)</span>
<span class="ansi-green-fg">----&gt; 2</span> <span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">tokenized_dataset</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">train</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">[</span><span class="ansi-yellow-bg">:</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">2</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1511</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1509</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color:rgb(98,98,98)">*</span>args, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>kwargs)  <span style="font-style:italic;color:rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-fg ansi-bold">   1510</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1511</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1520</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1515</span> <span style="font-style:italic;color:rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-fg ansi-bold">   1516</span> <span style="font-style:italic;color:rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-fg ansi-bold">   1517</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> (<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-fg ansi-bold">   1518</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1519</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1520</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1522</span> <span style="font-weight:bold;color:rgb(0,135,0)">try</span>:
<span class="ansi-green-fg ansi-bold">   1523</span>     result <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>

<span class="ansi-red-fg">TypeError</span>: DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'text'</pre>
</div>
</div>
</div>
<div id="cell-89" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the model </span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>DistilBertForSequenceClassification(
  (distilbert): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)</code></pre>
</div>
</div>
<div id="cell-90" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_params(model):</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Count the parameters of a PyTorch model.</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    trainable_parameters <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>    total_parameters <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"trainable_parameters"</span>: trainable_parameters, <span class="st">"total_parameters"</span>: total_parameters}</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the parameters of the model</span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>count_params(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>{'trainable_parameters': 66955010, 'total_parameters': 66955010}</code></pre>
</div>
</div>
<section id="tk---create-a-directory-for-saving-models" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="tk---create-a-directory-for-saving-models"><span class="header-section-number">6.1</span> TK - Create a directory for saving models</h3>
<div id="cell-92" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model output directory</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models directory</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>models_dir <span class="op">=</span> Path(<span class="st">"models"</span>)</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>models_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save name</span></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>model_save_name <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save path</span></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>model_save_dir <span class="op">=</span> Path(models_dir, model_save_name)</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>model_save_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')</code></pre>
</div>
</div>
</section>
<section id="tk---setup-training-arguments" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="tk---setup-training-arguments"><span class="header-section-number">6.2</span> TK - Setup training arguments</h3>
<ul>
<li>TK - add markdown table of different parameters and what they do (e.g.&nbsp;most of the common ones but add a note that these may want to be changed depending on the problem + there are many more in the docs)</li>
</ul>
<div id="cell-94" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training arguments</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># See: https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.TrainingArguments</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Turn off Weights &amp; Biases logging? Or add it in?</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - exercise: spend 10 minutes reading the TrainingArguments documentation</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>model_save_dir, <span class="co"># </span><span class="al">TODO</span><span class="co">: change this path to model save path, e.g. 'learn_hf_food_not_food_text_classifier_model' </span></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>, <span class="co"># load the best model when finished training</span></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span><span class="st">"epoch"</span>, <span class="co"># log training results every epoch</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span> <span class="co"># optional: log experiments to Weights &amp; Biases/other similar experimenting tracking services (we'll turn this off for now) </span></span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># push_to_hub=True # optional: automatically upload the model to the Hub (we'll do this manually later on)</span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># hub_token="your_token_here" # optional: add your Hugging Face Hub token to push to the Hub (will default to huggingface-cli login)</span></span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---setup-trainer-class" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="tk---setup-trainer-class"><span class="header-section-number">6.3</span> TK - Setup trainer class</h3>
<div id="cell-96" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Trainer</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Trainer</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: Trainer applies dynamic padding by default when you pass `tokenizer` to it.</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case, you don't need to specify a data collator explicitly.</span></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"train"</span>],</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"test"</span>],</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tokenizer=tokenizer, # Pass tokenizer to the Trainer for dynamic padding (padding as the training happens)</span></span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_accuracy</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---training-our-text-classification-model" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="tk---training-our-text-classification-model"><span class="header-section-number">6.4</span> TK - Training our text classification model</h3>
<div id="cell-98" class="cell" data-outputid="22937d9f-a794-4579-bc67-70ba6cb05dcd" data-execution_count="47">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="70" max="70" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [70/70 00:06, Epoch 10/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.615200</td>
<td>0.450918</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.405600</td>
<td>0.257541</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.219900</td>
<td>0.123121</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.108100</td>
<td>0.062602</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.056800</td>
<td>0.036242</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.035900</td>
<td>0.025235</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.026700</td>
<td>0.019986</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.021900</td>
<td>0.017336</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>9</td>
<td>0.019400</td>
<td>0.016042</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.018200</td>
<td>0.015633</td>
<td>1.000000</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
</section>
<section id="tk---inspect-the-model-results" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="tk---inspect-the-model-results"><span class="header-section-number">6.5</span> TK - Inspect the model results</h3>
<div id="cell-100" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - go through these</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>total_train_time <span class="op">=</span> results.metrics[<span class="st">"train_runtime"</span>]</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>train_samples_per_second <span class="op">=</span> results.metrics[<span class="st">"train_samples_per_second"</span>]</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total training time: </span><span class="sc">{</span>total_train_time<span class="sc">}</span><span class="ss"> seconds"</span>)</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training samples per second: </span><span class="sc">{</span>train_samples_per_second<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total training time: 6.7168 seconds
Training samples per second: 297.761</code></pre>
</div>
</div>
<div id="cell-101" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - get loss curves</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>trainer_history <span class="op">=</span> trainer.state.log_history[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>trainer_training_time <span class="op">=</span> trainer_history[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>trainer_history[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>[{'loss': 0.6152,
  'grad_norm': 3.3377952575683594,
  'learning_rate': 1.8e-05,
  'epoch': 1.0,
  'step': 7},
 {'eval_loss': 0.45091766119003296,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0113,
  'eval_samples_per_second': 4423.998,
  'eval_steps_per_second': 176.96,
  'epoch': 1.0,
  'step': 7},
 {'loss': 0.4056,
  'grad_norm': 2.4789676666259766,
  'learning_rate': 1.6000000000000003e-05,
  'epoch': 2.0,
  'step': 14},
 {'eval_loss': 0.25754112005233765,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0124,
  'eval_samples_per_second': 4023.931,
  'eval_steps_per_second': 160.957,
  'epoch': 2.0,
  'step': 14},
 {'loss': 0.2199,
  'grad_norm': 1.6385667324066162,
  'learning_rate': 1.4e-05,
  'epoch': 3.0,
  'step': 21}]</code></pre>
</div>
</div>
<div id="cell-102" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract training and evaluation metrics</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>trainer_history_training_set <span class="op">=</span> []</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_set <span class="op">=</span> []</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> trainer_history[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    item_keys <span class="op">=</span> <span class="bu">list</span>(item.keys())</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"eval"</span> <span class="kw">in</span> item <span class="cf">for</span> item <span class="kw">in</span> item_keys):</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>        trainer_history_eval_set.append(item)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>        trainer_history_training_set.append(item)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-103" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df <span class="op">=</span> pd.DataFrame(trainer_history_training_set)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df <span class="op">=</span> pd.DataFrame(trainer_history_eval_set)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">grad_norm</th>
<th data-quarto-table-cell-role="th">learning_rate</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.6152</td>
<td>3.337795</td>
<td>0.000018</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.4056</td>
<td>2.478968</td>
<td>0.000016</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.2199</td>
<td>1.638567</td>
<td>0.000014</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.1081</td>
<td>0.902428</td>
<td>0.000012</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0568</td>
<td>0.546689</td>
<td>0.000010</td>
<td>5.0</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.0359</td>
<td>0.347724</td>
<td>0.000008</td>
<td>6.0</td>
<td>42</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.0267</td>
<td>0.309794</td>
<td>0.000006</td>
<td>7.0</td>
<td>49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0.0219</td>
<td>0.273363</td>
<td>0.000004</td>
<td>8.0</td>
<td>56</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.0194</td>
<td>0.244860</td>
<td>0.000002</td>
<td>9.0</td>
<td>63</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>0.0182</td>
<td>0.245236</td>
<td>0.000000</td>
<td>10.0</td>
<td>70</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-104" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">eval_loss</th>
<th data-quarto-table-cell-role="th">eval_accuracy</th>
<th data-quarto-table-cell-role="th">eval_runtime</th>
<th data-quarto-table-cell-role="th">eval_samples_per_second</th>
<th data-quarto-table-cell-role="th">eval_steps_per_second</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.450918</td>
<td>1.0</td>
<td>0.0113</td>
<td>4423.998</td>
<td>176.960</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.257541</td>
<td>1.0</td>
<td>0.0124</td>
<td>4023.931</td>
<td>160.957</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.123121</td>
<td>1.0</td>
<td>0.0115</td>
<td>4338.068</td>
<td>173.523</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.062602</td>
<td>1.0</td>
<td>0.0115</td>
<td>4349.855</td>
<td>173.994</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.036242</td>
<td>1.0</td>
<td>0.0112</td>
<td>4448.585</td>
<td>177.943</td>
<td>5.0</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.025235</td>
<td>1.0</td>
<td>0.0122</td>
<td>4100.485</td>
<td>164.019</td>
<td>6.0</td>
<td>42</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.019986</td>
<td>1.0</td>
<td>0.0116</td>
<td>4327.147</td>
<td>173.086</td>
<td>7.0</td>
<td>49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0.017336</td>
<td>1.0</td>
<td>0.0113</td>
<td>4406.522</td>
<td>176.261</td>
<td>8.0</td>
<td>56</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.016042</td>
<td>1.0</td>
<td>0.0116</td>
<td>4315.128</td>
<td>172.605</td>
<td>9.0</td>
<td>63</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-105" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training and evaluation loss</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_training_df[<span class="st">"epoch"</span>], trainer_history_training_df[<span class="st">"loss"</span>], label<span class="op">=</span><span class="st">"Training loss"</span>)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_eval_df[<span class="st">"epoch"</span>], trainer_history_eval_df[<span class="st">"eval_loss"</span>], label<span class="op">=</span><span class="st">"Evaluation loss"</span>)</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Training and evaluation loss over time"</span>)</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hugging_face_text_classification_tutorial_files/figure-html/cell-52-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="tk---save-the-model-for-later-use" class="level3" data-number="6.6">
<h3 data-number="6.6" class="anchored" data-anchor-id="tk---save-the-model-for-later-use"><span class="header-section-number">6.6</span> TK - Save the model for later use</h3>
<div id="cell-107" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See docs: https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.save_model </span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>trainer.save_model(model_save_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---push-the-model-to-hugging-face-hub" class="level3" data-number="6.7">
<h3 data-number="6.7" class="anchored" data-anchor-id="tk---push-the-model-to-hugging-face-hub"><span class="header-section-number">6.7</span> TK - Push the model to Hugging Face Hub</h3>
<p>TK - optional to share the model/use elsewhere</p>
<ul>
<li>see here: https://huggingface.co/docs/transformers/en/model_sharing</li>
<li>also see here for how to setup <code>huggingface-cli</code> so you can write your model to your account</li>
</ul>
<div id="cell-109" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - have a note here for the errors</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: you may see the following error</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 403 Forbidden: You don't have the rights to create a model under the namespace "mrdbourke".</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cannot access content at: https://huggingface.co/api/repos/create.</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are trying to create or update content,make sure you have a token with the `write` role.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-110" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - Push model to hub (for later re-use)</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Push this model to the hub to be able to use it later</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - this requires a "write" token from the Hugging Face Hub</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - see docs: https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.push_to_hub </span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - for example, on my local computer, my token is saved to: "/home/daniel/.cache/huggingface/token"</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - Can create a model card with create_model_card()</span></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="co"># see here: https://huggingface.co/docs/transformers/v4.41.3/en/main_classes/trainer#transformers.Trainer.create_model_card </span></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>trainer.push_to_hub(</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier model"</span> <span class="co"># set to False if you want the model to be public</span></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token="YOUR_HF_TOKEN_HERE" # note: this will default to the token you have saved in your Hugging Face config</span></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>CommitInfo(commit_url='https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/commit/7c9a4a6b17da981559f484538d51f6ff9a14c12d', commit_message='Uploading food not food text classifier model', commit_description='', oid='7c9a4a6b17da981559f484538d51f6ff9a14c12d', pr_url=None, pr_revision=None, pr_num=None)</code></pre>
</div>
</div>
<ul>
<li>TK - note: this will make the model public, to make it private,</li>
</ul>
<p>See the model here saved for later: https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</p>
</section>
<section id="tk---make-and-evaluate-predictions-on-the-test-set" class="level3" data-number="6.8">
<h3 data-number="6.8" class="anchored" data-anchor-id="tk---make-and-evaluate-predictions-on-the-test-set"><span class="header-section-number">6.8</span> TK - Make and evaluate predictions on the test set</h3>
<div id="cell-113" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform predictions on the test set</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>predictions_all <span class="op">=</span> trainer.predict(tokenized_dataset[<span class="st">"test"</span>])</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>prediction_metrics <span class="op">=</span> predictions_all.metrics</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>prediction_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>{'test_loss': 0.015632618218660355,
 'test_accuracy': 1.0,
 'test_runtime': 0.0391,
 'test_samples_per_second': 1280.07,
 'test_steps_per_second': 51.203}</code></pre>
</div>
</div>
<div id="cell-114" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>predictions_all</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>PredictionOutput(predictions=array([[-2.261428 ,  1.890655 ],
       [ 1.8613493, -1.8532594],
       [-2.2970695,  1.9171791],
       [ 2.187019 , -2.1593657],
       [ 2.1193414, -2.1615388],
       [-2.2868803,  1.9454829],
       [ 2.0827348, -2.1099336],
       [ 2.154141 , -2.1266923],
       [-2.279855 ,  1.9362432],
       [-2.277952 ,  1.9518106],
       [-2.2772808,  1.9423369],
       [-1.9777709,  1.5732591],
       [ 2.1512635, -2.0508409],
       [-2.3032587,  1.9534686],
       [-2.138177 ,  1.7531359],
       [ 2.194142 , -2.1277084],
       [-2.2709608,  1.9498663],
       [ 1.9596925, -1.919577 ],
       [-2.2827635,  1.9249418],
       [-2.290854 ,  1.9592198],
       [-2.2823153,  1.8799024],
       [-2.3003585,  1.9387653],
       [ 2.043029 , -2.0384376],
       [ 2.0885575, -2.1244206],
       [-2.2873669,  1.9443382],
       [-2.2972584,  1.9009027],
       [-2.2450745,  1.8596792],
       [ 2.1050394, -2.040059 ],
       [-2.2972147,  1.8946056],
       [ 2.130832 , -2.133735 ],
       [-2.2846339,  1.9422101],
       [-2.2931519,  1.9279182],
       [-2.3040657,  1.9485677],
       [ 2.1816792, -2.141174 ],
       [-2.3019922,  1.9271733],
       [-2.2885954,  1.9124153],
       [-2.2813184,  1.9542999],
       [-2.304743 ,  1.8892938],
       [ 2.1249578, -2.089177 ],
       [ 2.043159 , -1.941504 ],
       [-2.1469579,  1.8099191],
       [-2.269732 ,  1.9235427],
       [-2.0776005,  1.7352381],
       [ 1.9634217, -2.0820174],
       [-2.2788396,  1.9341636],
       [-2.2946444,  1.9408271],
       [-2.2920046,  1.9059081],
       [-2.3030152,  1.9264866],
       [ 2.1768198, -2.1458352],
       [-2.301217 ,  1.9053475]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,
       1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.015632618218660355, 'test_accuracy': 1.0, 'test_runtime': 0.0391, 'test_samples_per_second': 1280.07, 'test_steps_per_second': 51.203})</code></pre>
</div>
</div>
<div id="cell-115" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>predictions_all._asdict().keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>dict_keys(['predictions', 'label_ids', 'metrics'])</code></pre>
</div>
</div>
<div id="cell-116" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> torch.softmax(torch.tensor(predictions_all.predictions), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>pred_labels <span class="op">=</span> np.argmax(predictions_all.predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> dataset[<span class="st">"test"</span>][<span class="st">"label"</span>]</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(true_labels, pred_labels)</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>1.0</code></pre>
</div>
</div>
<div id="cell-117" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a DataFrame of test predictions</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>test_predictions_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: dataset[<span class="st">"test"</span>][<span class="st">"text"</span>],</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"true_label"</span>: true_labels,</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_label"</span>: pred_labels,</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_prob"</span>: torch.<span class="bu">max</span>(pred_probs, dim<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-9"><a href="#cb102-9" aria-hidden="true" tabindex="-1"></a>test_predictions_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A slice of pepperoni pizza with a layer of mel...</td>
<td>1</td>
<td>1</td>
<td>0.984512</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Red brick fireplace with a mantel serving as a...</td>
<td>0</td>
<td>0</td>
<td>0.976215</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A bowl of sliced bell peppers with a sprinkle ...</td>
<td>1</td>
<td>1</td>
<td>0.985432</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Set of mugs hanging on a hook</td>
<td>0</td>
<td>0</td>
<td>0.987212</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Standing floor lamp providing light next to an...</td>
<td>0</td>
<td>0</td>
<td>0.986358</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-118" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show 10 examples with low prediction probability</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - this is good to find samples where the model is unsure </span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>test_predictions_df.sort_values(<span class="st">"pred_prob"</span>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">11</td>
<td>A close-up shot of a cheesy pizza slice being ...</td>
<td>1</td>
<td>1</td>
<td>0.972105</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Red brick fireplace with a mantel serving as a...</td>
<td>0</td>
<td>0</td>
<td>0.976215</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>Boxes of apples, pears, pineapple, manadrins a...</td>
<td>1</td>
<td>1</td>
<td>0.978392</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>Relaxing on the porch, a couple enjoys the com...</td>
<td>0</td>
<td>0</td>
<td>0.979753</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>Two handfuls of bananas in a fruit bowl with g...</td>
<td>1</td>
<td>1</td>
<td>0.979990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">40</td>
<td>A bowl of cherries with a sprig of mint for ga...</td>
<td>1</td>
<td>1</td>
<td>0.981236</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">39</td>
<td>A close-up of a woman practicing yoga in the l...</td>
<td>0</td>
<td>0</td>
<td>0.981741</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>Set of muffin tins stacked together</td>
<td>0</td>
<td>0</td>
<td>0.982799</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>Two people sitting at a dining room table with...</td>
<td>0</td>
<td>0</td>
<td>0.983398</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">26</td>
<td>A fruit platter with a variety of exotic fruit...</td>
<td>1</td>
<td>1</td>
<td>0.983774</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="tk---make-and-inspect-predictions-on-new-text-data" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="tk---make-and-inspect-predictions-on-new-text-data"><span class="header-section-number">7</span> TK - Make and inspect predictions on new text data</h2>
<p>UPTOHERE - load the model (locally + from Hub) - make sure to change the save paths when loading the model to the new paths - make predictions on new text data - build a demo with Gradio (optional)</p>
<p>Making predictions on our own text options.</p>
<p>See: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#inference</p>
<div id="cell-120" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>model_save_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')</code></pre>
</div>
</div>
<div id="cell-121" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup local model path</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>local_model_path <span class="op">=</span> <span class="st">"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Hugging Face model path (see: https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased)</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>huggingface_model_path <span class="op">=</span> <span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="tk---pipeline-mode" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="tk---pipeline-mode"><span class="header-section-number">7.1</span> TK - Pipeline mode</h3>
<ul>
<li>Tk - what is a pipeline?</li>
</ul>
<div id="cell-123" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: TK - set device agnostic code for CUDA/Mac/CPU?</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_device():</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Set device to CUDA if available, else MPS (Mac), else CPU.</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="co">    This defaults to using the best available device (usually).</span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> torch.backends.mps.is_available() <span class="kw">and</span> torch.backends.mps.is_built():</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> device</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>DEVICE <span class="op">=</span> set_device()</span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Using device: </span><span class="sc">{</span>DEVICE<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Using device: cuda</code></pre>
</div>
</div>
<div id="cell-124" class="cell" data-outputid="fb71c373-8dc5-42c3-9749-c58ab59253c3" data-execution_count="146">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup batch size for batched inference (can be adjusted depending on how much memory is available)</span></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - why use batch size? -&gt; multiple samples at inference = faster</span></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>                                    model<span class="op">=</span>local_model_path,</span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>                                    batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>                                    device<span class="op">=</span>DEVICE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-125" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>sample_text_food <span class="op">=</span> <span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast"</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="147">
<pre><code>[{'label': 'food', 'score': 0.99871826171875}]</code></pre>
</div>
</div>
<div id="cell-126" class="cell" data-outputid="7d9f1336-883e-474a-cc9a-aa605ba2afc1" data-execution_count="148">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>sample_text_not_food <span class="op">=</span> <span class="st">"A yellow tractor driving over the hill"</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_not_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="148">
<pre><code>[{'label': 'not_food', 'score': 0.9989410042762756}]</code></pre>
</div>
</div>
<div id="cell-127" class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline also works with remote models (will have to laod the model locally first)</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>                                           model<span class="op">=</span>huggingface_model_path,</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>                                           batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>                                           device<span class="op">=</span>DEVICE)</span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote(<span class="st">"This is some new text about bananas and pancakes and ice cream"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="150">
<pre><code>[{'label': 'food', 'score': 0.9981549382209778}]</code></pre>
</div>
</div>
</section>
<section id="tk---batch-prediction" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="tk---batch-prediction"><span class="header-section-number">7.2</span> TK - Batch prediction</h3>
<ul>
<li>TK - what is batch prediction?</li>
</ul>
<div id="cell-129" class="cell" data-outputid="3a50b522-c155-49fd-8c0e-27541486bca4" data-execution_count="151">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting works with lists</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Can find the examples with highest confidence and keep those</span></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>,</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"We need to marinate these ideas overnight before presenting them to the client."</span>,</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The new software is definitely a spicy upgrade, taking some time to get used to."</span>,</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Her social media post was the perfect recipe for a viral sensation."</span>,</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"He served up a rebuttal full of facts, leaving his opponent speechless."</span>,</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The team needs to simmer down a bit before tackling the next challenge."</span>,</span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Our budget is a bit thin, so we'll have to use budget-friendly materials for this project."</span>,</span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The presentation was a delicious blend of humor and information, keeping the audience engaged."</span>,</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Daniel Bourke is really cool :D"</span>,</span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"My favoruite food is biltong!"</span></span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sentences)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="151">
<pre><code>[{'label': 'not_food', 'score': 0.9410305619239807},
 {'label': 'not_food', 'score': 0.9650871753692627},
 {'label': 'not_food', 'score': 0.9215793609619141},
 {'label': 'not_food', 'score': 0.9115400910377502},
 {'label': 'not_food', 'score': 0.9625208377838135},
 {'label': 'not_food', 'score': 0.9476941823959351},
 {'label': 'not_food', 'score': 0.9451109170913696},
 {'label': 'not_food', 'score': 0.9027702808380127},
 {'label': 'not_food', 'score': 0.9954429864883423},
 {'label': 'food', 'score': 0.7653573155403137}]</code></pre>
</div>
</div>
</section>
<section id="tk---time-our-model-across-larger-sample-sizes" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="tk---time-our-model-across-larger-sample-sizes"><span class="header-section-number">7.3</span> TK - Time our model across larger sample sizes</h3>
<ul>
<li>TK - our model is fast!</li>
</ul>
<div id="cell-131" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10_000</span>]:</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>    sentences_big <span class="op">=</span> sentences <span class="op">*</span> i</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Number of sentences: </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier(sentences_big)</span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Inference time for </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss"> sentences: </span><span class="sc">{</span><span class="bu">round</span>(end_time <span class="op">-</span> start_time, <span class="dv">5</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Avg inference time per sentence: </span><span class="sc">{</span><span class="bu">round</span>((end_time <span class="op">-</span> start_time) <span class="op">/</span> <span class="bu">len</span>(sentences_big), <span class="dv">8</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Number of sentences: 100
[INFO] Inference time for 100 sentences: 0.07726 seconds.
[INFO] Avg inference time per sentence: 0.0007726 seconds.

[INFO] Number of sentences: 1000
[INFO] Inference time for 1000 sentences: 0.32344 seconds.
[INFO] Avg inference time per sentence: 0.00032344 seconds.

[INFO] Number of sentences: 10000
[INFO] Inference time for 10000 sentences: 1.43834 seconds.
[INFO] Avg inference time per sentence: 0.00014383 seconds.

[INFO] Number of sentences: 100000
[INFO] Inference time for 100000 sentences: 14.4585 seconds.
[INFO] Avg inference time per sentence: 0.00014459 seconds.

CPU times: user 15.8 s, sys: 552 ms, total: 16.3 s
Wall time: 16.3 s</code></pre>
</div>
</div>
</section>
<section id="pytorch-mode" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="pytorch-mode"><span class="header-section-number">7.4</span> PyTorch mode</h3>
<div id="cell-133" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"learn_hf_food_not_food_text_classifier_model"</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(sample_text_food, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-134" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(<span class="st">"learn_hf_food_not_food_text_classifier_model"</span>)</span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>  logits <span class="op">=</span> model(<span class="op">**</span>inputs).logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-135" class="cell" data-outputid="bfc30a2d-9a47-441f-f2e9-7cee7fd4989d" data-execution_count="54">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted class</span></span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>predicted_class_id <span class="op">=</span> logits.argmax().item()</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>sample_text_food<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted label: </span><span class="sc">{</span>model<span class="sc">.</span>config<span class="sc">.</span>id2label[predicted_class_id]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Text: A delicious photo of a plate of scrambled eggs, bacon and toast
Predicted label: food</code></pre>
</div>
</div>
</section>
</section>
<section id="tk---turning-our-model-into-a-demo" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="tk---turning-our-model-into-a-demo"><span class="header-section-number">8</span> TK - Turning our model into a demo</h2>
<ul>
<li>TK - why build a demo?
<ul>
<li><ul>
<li>try our model in the wild, see samples which don’t work properly, e.g.&nbsp;use cases we didn’t think of… “pie”/“tea” (short words), “hjflasdjhfhwerr” (gibberish)</li>
</ul></li>
</ul></li>
<li>TK - build a demo with Gradio, see it here: https://www.gradio.app/guides/quickstart</li>
<li>TK - requires <code>pip install gradio</code></li>
</ul>
<div id="cell-137" class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set top_k=2 to get top 2 predictions (in our case, food and not_food)</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"Testing the pipeline"</span>, top_k<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>[{'label': 'not_food', 'score': 0.9977033734321594},
 {'label': 'food', 'score': 0.002296620048582554}]</code></pre>
</div>
</div>
<section id="tk---creating-a-simple-function-to-perform-inference" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="tk---creating-a-simple-function-to-perform-inference"><span class="header-section-number">8.1</span> TK - Creating a simple function to perform inference</h3>
<ul>
<li>TK - this is required for gradio -&gt; output a dict of {“label_1”: probability_1, “label_2”: probability_2…}</li>
<li>2 options:
<ul>
<li>Local demo (for our own inspection)</li>
<li>Hosted demo on Hugging Face Spaces (for sharing with others)</li>
</ul></li>
</ul>
<div id="cell-139" class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text):</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span>local_model_path,</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>                                        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>,</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-16"><a href="#cb127-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb127-17"><a href="#cb127-17" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb127-18"><a href="#cb127-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-19"><a href="#cb127-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb127-20"><a href="#cb127-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-21"><a href="#cb127-21" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"My lunch today was bacon and eggs"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="160">
<pre><code>{'food': 0.7966588139533997, 'not_food': 0.20334114134311676}</code></pre>
</div>
</div>
<div id="cell-140" class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>    fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Food or Not Food Classifier"</span>,</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">"A text classifier to determine if a sentence is about food or not food."</span>,</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>              [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running on local URL:  http://127.0.0.1:7863

To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7863/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code></code></pre>
</div>
</div>
</section>
<section id="tk---uploadingrunning-the-demo" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="tk---uploadingrunning-the-demo"><span class="header-section-number">8.2</span> TK - Uploading/running the demo</h3>
<p>Options: * Uploading manually to Hugging Face Spaces - hf.co/new-space * Uploading programmatically to Hugging Face Spaces - https://www.gradio.app/guides/using-hugging-face-integrations#hosting-your-gradio-demos-on-spaces * Running the demo locally - <code>Interface.launch()</code> (only works if you have Gradio installed)</p>
<div id="cell-142" class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a directory for demos</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>demos_dir <span class="op">=</span> Path(<span class="st">"../demos"</span>)</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>demos_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a folder for the food_not_food_text_classifer demo</span></span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir <span class="op">=</span> Path(demos_dir, <span class="st">"food_not_food_text_classifier"</span>)</span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-143" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>app.py</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text):</span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set up text classification pipeline</span></span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span>, <span class="co"># link to model on HF Hub</span></span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>,</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb133-13"><a href="#cb133-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-14"><a href="#cb133-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb133-15"><a href="#cb133-15" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb133-16"><a href="#cb133-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-17"><a href="#cb133-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb133-18"><a href="#cb133-18" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb133-19"><a href="#cb133-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb133-20"><a href="#cb133-20" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb133-21"><a href="#cb133-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-22"><a href="#cb133-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb133-23"><a href="#cb133-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-24"><a href="#cb133-24" aria-hidden="true" tabindex="-1"></a>description <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb133-25"><a href="#cb133-25" aria-hidden="true" tabindex="-1"></a><span class="st">A text classifier to determine if a sentence is about food or not food.</span></span>
<span id="cb133-26"><a href="#cb133-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-27"><a href="#cb133-27" aria-hidden="true" tabindex="-1"></a><span class="st">TK - See source code:</span></span>
<span id="cb133-28"><a href="#cb133-28" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb133-29"><a href="#cb133-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-30"><a href="#cb133-30" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb133-31"><a href="#cb133-31" aria-hidden="true" tabindex="-1"></a>             inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb133-32"><a href="#cb133-32" aria-hidden="true" tabindex="-1"></a>             outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb133-33"><a href="#cb133-33" aria-hidden="true" tabindex="-1"></a>             title<span class="op">=</span><span class="st">"🍗🚫🥑 Food or Not Food Text Classifier"</span>,</span>
<span id="cb133-34"><a href="#cb133-34" aria-hidden="true" tabindex="-1"></a>             description<span class="op">=</span>description,</span>
<span id="cb133-35"><a href="#cb133-35" aria-hidden="true" tabindex="-1"></a>             examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb133-36"><a href="#cb133-36" aria-hidden="true" tabindex="-1"></a>                       [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb133-37"><a href="#cb133-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-38"><a href="#cb133-38" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb133-39"><a href="#cb133-39" aria-hidden="true" tabindex="-1"></a>    demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/app.py</code></pre>
</div>
</div>
<p>TK - note: you will often need a requirements.txt file</p>
<pre><code>===== Application Startup at 2024-06-13 05:37:21 =====

Traceback (most recent call last):
  File "/home/user/app/app.py", line 1, in &lt;module&gt;
    import torch
ModuleNotFoundError: No module named 'torch'</code></pre>
<div id="cell-145" class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>requirements.txt</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>gradio</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>torch</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/requirements.txt</code></pre>
</div>
</div>
<p>Create a <code>README.md</code> file with metadata instructions (these are specific to Hugging Face Spaces).</p>
<div id="cell-147" class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>README.md</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>title: Food Not Food Text Classifier</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>emoji: 🍗🚫🥑</span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>colorFrom: blue</span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a>colorTo: yellow</span>
<span id="cb138-7"><a href="#cb138-7" aria-hidden="true" tabindex="-1"></a>sdk: gradio</span>
<span id="cb138-8"><a href="#cb138-8" aria-hidden="true" tabindex="-1"></a>sdk_version: <span class="fl">4.36.1</span></span>
<span id="cb138-9"><a href="#cb138-9" aria-hidden="true" tabindex="-1"></a>app_file: app.py</span>
<span id="cb138-10"><a href="#cb138-10" aria-hidden="true" tabindex="-1"></a>pinned: false</span>
<span id="cb138-11"><a href="#cb138-11" aria-hidden="true" tabindex="-1"></a>license: apache<span class="op">-</span><span class="fl">2.0</span></span>
<span id="cb138-12"><a href="#cb138-12" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb138-13"><a href="#cb138-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-14"><a href="#cb138-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 🍗🚫🥑 Food Not Food Text Classifier</span></span>
<span id="cb138-15"><a href="#cb138-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-16"><a href="#cb138-16" aria-hidden="true" tabindex="-1"></a>Small demo to showcase a text classifier to determine <span class="cf">if</span> a sentence <span class="kw">is</span> about food <span class="kw">or</span> <span class="kw">not</span> food.</span>
<span id="cb138-17"><a href="#cb138-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-18"><a href="#cb138-18" aria-hidden="true" tabindex="-1"></a>DistillBERT model fine<span class="op">-</span>tuned on a small synthetic dataset of <span class="dv">250</span> generated [Food <span class="kw">or</span> Not Food image captions](https:<span class="op">//</span>huggingface.co<span class="op">/</span>datasets<span class="op">/</span>mrdbourke<span class="op">/</span>learn_hf_food_not_food_image_captions).</span>
<span id="cb138-19"><a href="#cb138-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-20"><a href="#cb138-20" aria-hidden="true" tabindex="-1"></a>TK <span class="op">-</span> see the demo notebook on how to create this</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/README.md</code></pre>
</div>
</div>
<div id="cell-148" class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> (</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>    create_repo,</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>    get_full_repo_name,</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>    upload_file, <span class="co"># for uploading a single file</span></span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>    upload_folder <span class="co"># for uploading multiple files (in a folder)</span></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a>path_to_demo_folder <span class="op">=</span> <span class="st">"../demos/food_not_food_text_classifier"</span></span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a>repo_type <span class="op">=</span> <span class="st">"space"</span> <span class="co"># we're creating a Hugging Face Space</span></span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a repo on Hugging Face</span></span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a><span class="co"># see docs: https://huggingface.co/docs/huggingface_hub/v0.23.3/en/package_reference/hf_api#huggingface_hub.HfApi.create_repo</span></span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a>target_space_name <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier_demo"</span></span>
<span id="cb140-14"><a href="#cb140-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Creating repo: </span><span class="sc">{</span>target_space_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb140-15"><a href="#cb140-15" aria-hidden="true" tabindex="-1"></a>create_repo(</span>
<span id="cb140-16"><a href="#cb140-16" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>target_space_name,</span>
<span id="cb140-17"><a href="#cb140-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#token="YOUR_HF_TOKEN"</span></span>
<span id="cb140-18"><a href="#cb140-18" aria-hidden="true" tabindex="-1"></a>    private<span class="op">=</span><span class="va">False</span>, <span class="co"># set to True if you want the repo to be private</span></span>
<span id="cb140-19"><a href="#cb140-19" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>repo_type, <span class="co"># create a Hugging Face Space</span></span>
<span id="cb140-20"><a href="#cb140-20" aria-hidden="true" tabindex="-1"></a>    space_sdk<span class="op">=</span><span class="st">"gradio"</span>, <span class="co"># we're using Gradio to build our demo </span></span>
<span id="cb140-21"><a href="#cb140-21" aria-hidden="true" tabindex="-1"></a>    exist_ok<span class="op">=</span><span class="va">True</span>, <span class="co"># set to False if you want to create the repo even if it already exists            </span></span>
<span id="cb140-22"><a href="#cb140-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb140-23"><a href="#cb140-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-24"><a href="#cb140-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the full repo name (e.g. "mrdbourke/learn_hf_food_not_food_text_classifier_demo")</span></span>
<span id="cb140-25"><a href="#cb140-25" aria-hidden="true" tabindex="-1"></a>full_repo_name <span class="op">=</span> get_full_repo_name(model_id<span class="op">=</span>target_space_name)</span>
<span id="cb140-26"><a href="#cb140-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Full repo name: </span><span class="sc">{</span>full_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb140-27"><a href="#cb140-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-28"><a href="#cb140-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload a file</span></span>
<span id="cb140-29"><a href="#cb140-29" aria-hidden="true" tabindex="-1"></a><span class="co"># see docs: https://huggingface.co/docs/huggingface_hub/v0.23.3/en/package_reference/hf_api#huggingface_hub.HfApi.upload_file </span></span>
<span id="cb140-30"><a href="#cb140-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Uploading </span><span class="sc">{</span>path_to_demo_folder<span class="sc">}</span><span class="ss"> to repo: </span><span class="sc">{</span>full_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb140-31"><a href="#cb140-31" aria-hidden="true" tabindex="-1"></a>file_url <span class="op">=</span> upload_folder(</span>
<span id="cb140-32"><a href="#cb140-32" aria-hidden="true" tabindex="-1"></a>    folder_path<span class="op">=</span>path_to_demo_folder,</span>
<span id="cb140-33"><a href="#cb140-33" aria-hidden="true" tabindex="-1"></a>    path_in_repo<span class="op">=</span><span class="st">"."</span>, <span class="co"># save to the root of the repo</span></span>
<span id="cb140-34"><a href="#cb140-34" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>full_repo_name,</span>
<span id="cb140-35"><a href="#cb140-35" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>repo_type,</span>
<span id="cb140-36"><a href="#cb140-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">#token="YOUR_HF_TOKEN"</span></span>
<span id="cb140-37"><a href="#cb140-37" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier demo app.py"</span></span>
<span id="cb140-38"><a href="#cb140-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Creating repo: learn_hf_food_not_food_text_classifier_demo
[INFO] Full repo name: mrdbourke/learn_hf_food_not_food_text_classifier_demo
[INFO] Uploading ../demos/food_not_food_text_classifier to repo: mrdbourke/learn_hf_food_not_food_text_classifier_demo</code></pre>
</div>
</div>
<ul>
<li>TK - see the demo link here: https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo</li>
</ul>
</section>
<section id="tk---testing-the-live-demo" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="tk---testing-the-live-demo"><span class="header-section-number">8.3</span> TK - Testing the live demo</h3>
<div id="cell-151" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="co"># You can get embeddable HTML code for your demo by clicking the "Embed" button on the demo page</span></span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>HTML(<span class="st">'''</span></span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;iframe</span></span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a><span class="st">    src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space"</span></span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a><span class="st">    frameborder="0"</span></span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a><span class="st">    width="850"</span></span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a><span class="st">    height="450"</span></span>
<span id="cb142-11"><a href="#cb142-11" aria-hidden="true" tabindex="-1"></a><span class="st">&gt;&lt;/iframe&gt;     </span></span>
<span id="cb142-12"><a href="#cb142-12" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

<iframe src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space" frameborder="0" width="850" height="450"></iframe>     
</div>
</div>
</section>
</section>
<section id="tk---exercises-and-extensions" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="tk---exercises-and-extensions"><span class="header-section-number">9</span> TK - Exercises and Extensions</h2>
<ul>
<li>Where does our model fail? E.g. what kind of sentences does it struggle with? How could you fix this?
<ul>
<li>Make an extra 10-50 examples of these and add them to the dataset and then retrain the model</li>
<li>See here: https://discuss.huggingface.co/t/how-do-i-add-things-rows-to-an-already-saved-dataset/27423</li>
</ul></li>
<li>Build your own text classifier on a different dataset/your own custom dataset</li>
<li>How might we make our dataset multi-class? (e.g.&nbsp;more than 2 classes)</li>
</ul>
</section>
<section id="tk---extra-resources" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="tk---extra-resources"><span class="header-section-number">10</span> TK - Extra resources</h2>
<ul>
<li>Hugging Face guide on text classification: https://huggingface.co/docs/transformers/en/tasks/sequence_classification</li>
<li>Hugging Face documentation on padding and truncation - https://huggingface.co/docs/transformers/en/pad_truncation</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrdbourke\.github\.io\/learn-huggingface\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>