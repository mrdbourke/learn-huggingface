<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.55">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Text Classification with Hugging Face Transformers – Learn Hugging Face 🤗</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Learn Hugging Face 🤗</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Natural Language Processing (NLP)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/hugging_face_text_classification_tutorial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Text Classification (work in progress)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tk---overview" id="toc-tk---overview" class="nav-link active" data-scroll-target="#tk---overview"><span class="header-section-number">1</span> TK - Overview</a>
  <ul class="collapse">
  <li><a href="#what-were-going-to-build" id="toc-what-were-going-to-build" class="nav-link" data-scroll-target="#what-were-going-to-build"><span class="header-section-number">1.1</span> What we’re going to build</a></li>
  <li><a href="#tk---what-is-text-classification" id="toc-tk---what-is-text-classification" class="nav-link" data-scroll-target="#tk---what-is-text-classification"><span class="header-section-number">1.2</span> TK - What is text classification?</a></li>
  <li><a href="#tk---why-train-your-own-text-classification-models" id="toc-tk---why-train-your-own-text-classification-models" class="nav-link" data-scroll-target="#tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.3</span> TK - Why train your own text classification models?</a></li>
  <li><a href="#tk---workflow-were-going-to-follow" id="toc-tk---workflow-were-going-to-follow" class="nav-link" data-scroll-target="#tk---workflow-were-going-to-follow"><span class="header-section-number">1.4</span> TK - Workflow we’re going to follow</a></li>
  </ul></li>
  <li><a href="#tk---importing-necessary-libraries" id="toc-tk---importing-necessary-libraries" class="nav-link" data-scroll-target="#tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</a></li>
  <li><a href="#getting-a-dataset" id="toc-getting-a-dataset" class="nav-link" data-scroll-target="#getting-a-dataset"><span class="header-section-number">3</span> Getting a dataset</a>
  <ul class="collapse">
  <li><a href="#where-can-you-get-more-datasets" id="toc-where-can-you-get-more-datasets" class="nav-link" data-scroll-target="#where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</a></li>
  <li><a href="#loading-the-dataset" id="toc-loading-the-dataset" class="nav-link" data-scroll-target="#loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</a></li>
  <li><a href="#inspect-random-examples-from-the-dataset" id="toc-inspect-random-examples-from-the-dataset" class="nav-link" data-scroll-target="#inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> Inspect random examples from the dataset</a></li>
  </ul></li>
  <li><a href="#preparing-data-for-text-classification" id="toc-preparing-data-for-text-classification" class="nav-link" data-scroll-target="#preparing-data-for-text-classification"><span class="header-section-number">4</span> Preparing data for text classification</a>
  <ul class="collapse">
  <li><a href="#creating-a-mapping-from-labels-to-numbers" id="toc-creating-a-mapping-from-labels-to-numbers" class="nav-link" data-scroll-target="#creating-a-mapping-from-labels-to-numbers"><span class="header-section-number">4.1</span> Creating a mapping from labels to numbers</a></li>
  <li><a href="#split-the-dataset-into-training-and-test-sets" id="toc-split-the-dataset-into-training-and-test-sets" class="nav-link" data-scroll-target="#split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.2</span> Split the dataset into training and test sets</a></li>
  <li><a href="#tk---tokenizing-text-data" id="toc-tk---tokenizing-text-data" class="nav-link" data-scroll-target="#tk---tokenizing-text-data"><span class="header-section-number">4.3</span> TK - Tokenizing text data</a></li>
  <li><a href="#making-a-preprocessing-function-to-tokenize-text" id="toc-making-a-preprocessing-function-to-tokenize-text" class="nav-link" data-scroll-target="#making-a-preprocessing-function-to-tokenize-text"><span class="header-section-number">4.4</span> Making a preprocessing function to tokenize text</a></li>
  <li><a href="#tokenization-takeaways" id="toc-tokenization-takeaways" class="nav-link" data-scroll-target="#tokenization-takeaways"><span class="header-section-number">4.5</span> Tokenization takeaways</a></li>
  </ul></li>
  <li><a href="#tk---setting-up-an-evaluation-metric" id="toc-tk---setting-up-an-evaluation-metric" class="nav-link" data-scroll-target="#tk---setting-up-an-evaluation-metric"><span class="header-section-number">5</span> TK - Setting up an evaluation metric</a></li>
  <li><a href="#setting-up-a-model-for-training" id="toc-setting-up-a-model-for-training" class="nav-link" data-scroll-target="#setting-up-a-model-for-training"><span class="header-section-number">6</span> Setting up a model for training</a>
  <ul class="collapse">
  <li><a href="#counting-the-parameters-of-our-model" id="toc-counting-the-parameters-of-our-model" class="nav-link" data-scroll-target="#counting-the-parameters-of-our-model"><span class="header-section-number">6.1</span> Counting the parameters of our model</a></li>
  <li><a href="#create-a-directory-for-saving-models" id="toc-create-a-directory-for-saving-models" class="nav-link" data-scroll-target="#create-a-directory-for-saving-models"><span class="header-section-number">6.2</span> Create a directory for saving models</a></li>
  <li><a href="#setting-up-training-arguments-with-trainingarguments" id="toc-setting-up-training-arguments-with-trainingarguments" class="nav-link" data-scroll-target="#setting-up-training-arguments-with-trainingarguments"><span class="header-section-number">6.3</span> Setting up training arguments with TrainingArguments</a></li>
  <li><a href="#setting-up-an-instance-of-trainer" id="toc-setting-up-an-instance-of-trainer" class="nav-link" data-scroll-target="#setting-up-an-instance-of-trainer"><span class="header-section-number">6.4</span> Setting up an instance of Trainer</a></li>
  <li><a href="#training-our-text-classification-model" id="toc-training-our-text-classification-model" class="nav-link" data-scroll-target="#training-our-text-classification-model"><span class="header-section-number">6.5</span> Training our text classification model</a></li>
  <li><a href="#save-the-model-for-later-use" id="toc-save-the-model-for-later-use" class="nav-link" data-scroll-target="#save-the-model-for-later-use"><span class="header-section-number">6.6</span> Save the model for later use</a></li>
  <li><a href="#inspecting-the-model-training-metrics" id="toc-inspecting-the-model-training-metrics" class="nav-link" data-scroll-target="#inspecting-the-model-training-metrics"><span class="header-section-number">6.7</span> Inspecting the model training metrics</a></li>
  <li><a href="#pushing-our-model-to-the-hugging-face-hub" id="toc-pushing-our-model-to-the-hugging-face-hub" class="nav-link" data-scroll-target="#pushing-our-model-to-the-hugging-face-hub"><span class="header-section-number">6.8</span> Pushing our model to the Hugging Face Hub</a></li>
  </ul></li>
  <li><a href="#making-and-evaluating-predictions-on-the-test-data" id="toc-making-and-evaluating-predictions-on-the-test-data" class="nav-link" data-scroll-target="#making-and-evaluating-predictions-on-the-test-data"><span class="header-section-number">7</span> Making and evaluating predictions on the test data</a></li>
  <li><a href="#making-and-inspecting-predictions-on-custom-text-data" id="toc-making-and-inspecting-predictions-on-custom-text-data" class="nav-link" data-scroll-target="#making-and-inspecting-predictions-on-custom-text-data"><span class="header-section-number">8</span> Making and inspecting predictions on custom text data</a>
  <ul class="collapse">
  <li><a href="#discussing-ways-to-make-predictions-inference" id="toc-discussing-ways-to-make-predictions-inference" class="nav-link" data-scroll-target="#discussing-ways-to-make-predictions-inference"><span class="header-section-number">8.1</span> Discussing ways to make predictions (inference)</a></li>
  <li><a href="#making-predictions-with-pipeline" id="toc-making-predictions-with-pipeline" class="nav-link" data-scroll-target="#making-predictions-with-pipeline"><span class="header-section-number">8.2</span> Making predictions with pipeline</a></li>
  <li><a href="#making-multiple-predictions-at-the-same-time-with-batch-prediction" id="toc-making-multiple-predictions-at-the-same-time-with-batch-prediction" class="nav-link" data-scroll-target="#making-multiple-predictions-at-the-same-time-with-batch-prediction"><span class="header-section-number">8.3</span> Making multiple predictions at the same time with batch prediction</a></li>
  <li><a href="#time-our-model-across-larger-sample-sizes" id="toc-time-our-model-across-larger-sample-sizes" class="nav-link" data-scroll-target="#time-our-model-across-larger-sample-sizes"><span class="header-section-number">8.4</span> Time our model across larger sample sizes</a></li>
  <li><a href="#making-predictions-with-pytorch" id="toc-making-predictions-with-pytorch" class="nav-link" data-scroll-target="#making-predictions-with-pytorch"><span class="header-section-number">8.5</span> Making predictions with PyTorch</a></li>
  </ul></li>
  <li><a href="#turning-our-model-into-a-demo" id="toc-turning-our-model-into-a-demo" class="nav-link" data-scroll-target="#turning-our-model-into-a-demo"><span class="header-section-number">9</span> Turning our model into a demo</a>
  <ul class="collapse">
  <li><a href="#creating-a-simple-function-to-perform-inference" id="toc-creating-a-simple-function-to-perform-inference" class="nav-link" data-scroll-target="#creating-a-simple-function-to-perform-inference"><span class="header-section-number">9.1</span> Creating a simple function to perform inference</a></li>
  <li><a href="#building-a-small-gradio-demo-to-run-locally" id="toc-building-a-small-gradio-demo-to-run-locally" class="nav-link" data-scroll-target="#building-a-small-gradio-demo-to-run-locally"><span class="header-section-number">9.2</span> Building a small Gradio demo to run locally</a></li>
  </ul></li>
  <li><a href="#making-our-demo-publicly-accessible" id="toc-making-our-demo-publicly-accessible" class="nav-link" data-scroll-target="#making-our-demo-publicly-accessible"><span class="header-section-number">10</span> Making our demo publicly accessible</a>
  <ul class="collapse">
  <li><a href="#making-an-app-file" id="toc-making-an-app-file" class="nav-link" data-scroll-target="#making-an-app-file"><span class="header-section-number">10.1</span> Making an app file</a></li>
  <li><a href="#making-a-requirements-file" id="toc-making-a-requirements-file" class="nav-link" data-scroll-target="#making-a-requirements-file"><span class="header-section-number">10.2</span> Making a requirements file</a></li>
  <li><a href="#making-a-readme-file" id="toc-making-a-readme-file" class="nav-link" data-scroll-target="#making-a-readme-file"><span class="header-section-number">10.3</span> Making a README file</a></li>
  <li><a href="#uploading-our-demo-to-hugging-face-spaces" id="toc-uploading-our-demo-to-hugging-face-spaces" class="nav-link" data-scroll-target="#uploading-our-demo-to-hugging-face-spaces"><span class="header-section-number">10.4</span> Uploading our demo to Hugging Face Spaces</a></li>
  <li><a href="#testing-our-hosted-demo" id="toc-testing-our-hosted-demo" class="nav-link" data-scroll-target="#testing-our-hosted-demo"><span class="header-section-number">10.5</span> Testing our hosted demo</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">11</span> Summary</a></li>
  <li><a href="#tk---exercises-and-extensions" id="toc-tk---exercises-and-extensions" class="nav-link" data-scroll-target="#tk---exercises-and-extensions"><span class="header-section-number">12</span> TK - Exercises and Extensions</a></li>
  <li><a href="#extra-resources" id="toc-extra-resources" class="nav-link" data-scroll-target="#extra-resources"><span class="header-section-number">13</span> Extra resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Text Classification with Hugging Face Transformers</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a target="_blank" href="https://colab.research.google.com/github/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"> </a></p>
<div id="cell-2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Next:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add tools used in this overview (e.g. overview of the project)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset with text generation, e.g. 50x spam/not_spam emails and train a classifier on it ✅</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see notebook: https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the dataset to Hugging Face Datasets ✅</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see dataset: https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a classifier on it ✅</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the model to the Hugging Face Model Hub ✅</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a with Gradio and test the model in the wild ✅ </span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Make sure notebook runs in Google Colab </span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>   <span class="co"># ✅ Can the notebook run with a demo account? E.g. not my own Hugging Face token? ✅</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Add a link to the dataset notebook - does this need a walkthrough of how it was created? Could do this in one video? ✅</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># UPTOHERE: Go back and edit the TK's through the notebook</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>   <span class="co"># count: 57</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>   <span class="co"># count: 25</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>   <span class="co"># ✅ Can the introduction to Hugging Face be added to the front page? </span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>      <span class="co"># This is universal for projects and won't need to be repeated each project... </span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Add images and diagrams throughout</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Look into Quarto figures and how these work</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure the online book version looks good</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a code only version of the notebook so there's less fluff</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="tk---overview" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="tk---overview"><span class="header-section-number">1</span> TK - Overview</h2>
<ul>
<li>TK - add a note that this notebook can be run in end-to-end in Google Colab, however, it’s best viewed at learnhuggingface.com for formatting purposes</li>
<li>TK image - add an image of the project we’re building</li>
</ul>
<section id="what-were-going-to-build" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="what-were-going-to-build"><span class="header-section-number">1.1</span> What we’re going to build</h3>
<p>In this project, we’re going to learn various aspects of the Hugging Face ecosystem whilst building a text classification model.</p>
<p>To keep things as practical as possible, we’re going to be bulding a <code>food</code>/<code>not_food</code> <strong>text classification model</strong>.</p>
<p>Given a piece of a text (such as an image caption), our model will be able to predict if it’s about food or not.</p>
<p>This is the same kind of model I use in my own work on <a href="https://www.nutrify.app">Nutrify</a> (an app to help people learn about food).</p>
<p>More specifically, we’re going to follow the following steps:</p>
<ol type="1">
<li><strong>Problem defintion and dataset preparation</strong> - Getting a dataset/setting up the problem space.</li>
<li><strong>Finding, training and evaluating a model</strong> - Finding a text classification model suitable for our problem on Hugging Face and customizing it to our own dataset.</li>
<li><strong>Creating a demo and put our model into the real world</strong> - Sharing our trained model in a way others can access and use.</li>
</ol>
<p>By the end of this project, you’ll have a trained model and <a href="https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo">demo on Hugging Face</a> you can share with others:</p>
<div id="cell-4" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>HTML(<span class="st">"""</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;iframe</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="st">    src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="st">    frameborder="0"</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="st">    width="850"</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="st">    height="650"</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="st">&gt;&lt;/iframe&gt;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">

<iframe src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space" frameborder="0" width="850" height="650"></iframe>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note this is a hands-on project, so we’ll be focused on writing reusable code and building a model that can be used in the real world. If you are looking for explainers to the theory of what we’re doing, I’ll leave links in the extra-curriculum section.</p>
</div>
</div>
</section>
<section id="tk---what-is-text-classification" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="tk---what-is-text-classification"><span class="header-section-number">1.2</span> TK - What is text classification?</h3>
<p>Text classification is the process of assigning a category to a piece of text.</p>
<p>Where a category can be almost anything and a piece of text can be a word, phrase, sentence, paragraph or entire document.</p>
<p>TK image - example of text classification</p>
<p>Example text classification problems include:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Description</strong></th>
<th><strong>Problem Type</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spam/phishing email detection</td>
<td>Is an email spam or not spam? Or is it a phishing email or not?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Sentiment analysis</td>
<td>Is a piece of text positive, negative or neutral? Such as classifying product reviews into good/bad/neutral.</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="odd">
<td>Language detection</td>
<td>What language is a piece of text written in?</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="even">
<td>Topic classification</td>
<td>What topic(s) does a news article belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
<tr class="odd">
<td>Hate speech detection</td>
<td>Is a comment hateful or not hateful?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Product categorization</td>
<td>What categories does a product belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
</tbody>
</table>
<p>Text classification is a very common problem in many business settings.</p>
<p>For example, a project I’ve worked on previously as a machine learning engineer was building a text classification model to classify different insurance claims into <code>claimant_at_fault</code>/<code>claimant_not_at_fault</code> for a large insurance company.</p>
<p>It turns out the deep learning-based model we built was very good (98%+ accuracy on the test dataset).</p>
<p>Speaking of models, there are several different kinds of models you can use for text classification.</p>
<p>And each will have its pros and cons depending on the problem you’re working on.</p>
<p>Example text classification models include:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Description</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Rule-based</td>
<td>Uses a set of rules to classify text (e.g.&nbsp;if text contains “sad” -&gt; sentiment = low)</td>
<td>Simple, easy to understand</td>
<td>Requires manual creation of rules</td>
</tr>
<tr class="even">
<td><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words</a></td>
<td>Counts the frequency of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn’t capture word order</td>
</tr>
<tr class="odd">
<td><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a></td>
<td>Weighs the importance of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn’t capture word order</td>
</tr>
<tr class="even">
<td>Deep learning-based models</td>
<td>Uses neural networks to learn patterns in text</td>
<td>Can learn complex patterns at scale</td>
<td>Can require large amounts of data/compute power to run, not as easy to understand (can be hard to debug)</td>
</tr>
</tbody>
</table>
<p>For our project, we’re going to go with a deep learning model.</p>
<p>Why?</p>
<p>Because Hugging Face helps us do so.</p>
<p>And in most cases, with a quality dataset, a deep learning model will often perform better than a rule-based or other model.</p>
</section>
<section id="tk---why-train-your-own-text-classification-models" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.3</span> TK - Why train your own text classification models?</h3>
<p>You can use <strong>pre-trained models</strong> for text classification as well as API-powered models and LLMs such as GPT-4 or Gemini.</p>
<p>However, it’s often a good idea to train your own text classification models for a few reasons:</p>
<ul>
<li>They can be much faster than API-powered models (since they’re running on your own hardware, this can save on costs and time).</li>
<li>They’re customized to your own data.</li>
<li>They don’t require you to send your data elsewhere (privacy).</li>
<li>If a service goes down, you’ll still have access to your model (reliability).</li>
<li>You own the model at the end.</li>
</ul>
<p>TK image - example of training your own model vs using an API-powered model</p>
</section>
<section id="tk---workflow-were-going-to-follow" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="tk---workflow-were-going-to-follow"><span class="header-section-number">1.4</span> TK - Workflow we’re going to follow</h3>
<p>TK - explain the workflow</p>
<ol type="1">
<li>Create and preprocess data.</li>
<li>Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
</section>
</section>
<section id="tk---importing-necessary-libraries" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</h2>
<p>Let’s get started!</p>
<p>First, we’ll import the required libraries.</p>
<p>If you’re running on your local computer, be sure to check out the getting setup guide (tk - link to getting setup guide) to make sure you have everything you need.</p>
<p>If you’re using Google Colab, many of them the following libraries will be installed by default.</p>
<p>However, we’ll have to install a few extras to get everything working.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you’re running on Google Colab, this notebook will work best with access to a GPU. To enable a GPU, go to <code>Runtime</code> ➡️ <code>Change runtime type</code> ➡️ <code>Hardware accelerator</code> ➡️ <code>GPU</code>.</p>
</div>
</div>
<p>We’ll need to install the following libraries from the Hugging Face ecosystem:</p>
<ul>
<li><a href="https://huggingface.co/docs/transformers/en/installation"><code>transformers</code></a> - comes pre-installed on Google Colab but if you’re running on your local machine, you can install it via <code>pip install transformers</code>.</li>
<li><a href="https://huggingface.co/docs/datasets/installation"><code>datasets</code></a> - a library for accessing and manipulating datasets on and off the Hugging Face Hub, you can install it via <code>pip install datasets</code>.</li>
<li><a href="https://huggingface.co/docs/evaluate/installation"><code>evaluate</code></a> - a library for evaluating machine learning model performance with various metrics, you can install it via <code>pip install evaluate</code>.</li>
<li><a href="https://huggingface.co/docs/accelerate/basic_tutorials/install"><code>accelerate</code></a> - a library for training machine learning models faster, you can install it via <code>pip install accelerate</code>.</li>
<li><a href="https://www.gradio.app/guides/quickstart#installation"><code>gradio</code></a> - a library for creating interactive demos of machine learning models, you can install it via <code>pip install gradio</code>.</li>
</ul>
<p>We can also check the versions of our software with <code>package_name.__version__</code>.</p>
<div id="cell-10" class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-outputid="ccd72531-249d-402f-91b0-7b701b2dc7eb" data-scrolled="true" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install dependencies (this is mostly for Google Colab, as the other dependences are available by default in Colab)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ModuleNotFoundError</span>:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span>pip install <span class="op">-</span>U datasets evaluate accelerate gradio <span class="co"># -U stands for "upgrade" so we'll get the latest version by default</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using transformers version: </span><span class="sc">{</span>transformers<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using datasets version: </span><span class="sc">{</span>datasets<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using torch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using transformers version: 4.41.2
Using datasets version: 2.19.1
Using torch version: 2.2.0+cu121</code></pre>
</div>
</div>
<p>Wonderful, as long as your versions are the same or higher to the versions above, you should be able to run the code below.</p>
</section>
<section id="getting-a-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="getting-a-dataset"><span class="header-section-number">3</span> Getting a dataset</h2>
<p>Okay, now we’re got the required libraries, let’s get a dataset.</p>
<p>Getting a dataset is one of the most important things a machine learning project.</p>
<p>The dataset you often determines the type of model you use as well as the quality of the outputs of that model.</p>
<p>Meaning, if you have a high quality dataset, chances are, your future model could also have high quality outputs.</p>
<p>It also means if your dataset is of poor quality, your model will likely also have poor quality outputs.</p>
<p>For a text classificaiton problem, your dataset will likely come in the form of text (e.g.&nbsp;a paragraph, sentence or phrase) and a label (e.g.&nbsp;what category the text belongs to).</p>
<ul>
<li>TK image - showcase what a supervised dataset looks like (e.g.&nbsp;text and label, this can be the dataset we’ve got on Hugging Face hub, showcase the different parts of the dataset as well including the name etc)</li>
</ul>
<p>In our case, our dataset comes in the form of a collection of synthetic image captions and their corresponding labels (food or not food).</p>
<p>This is a dataset I’ve created earlier to help us practice building a text classification model.</p>
<p>You can find it on Hugging Face under the name <a href="https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions"><code>mrdbourke/learn_hf_food_not_food_image_captions</code></a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Food Not Food Image Caption Dataset Creation
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can see how the Food Not Food image caption dataset was created in the example <a href="https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing">Google Colab notebook</a>.</p>
<p>A Large Language Model (LLM) was asked to generate various image caption texts about food and not food.</p>
<p>Getting another model to create data for a problem is known as <strong>synthetic data generation</strong> and is a very good way of bootstrapping towards creating a model.</p>
<p>One workflow would be to use real data wherever possible and use synthetic data to boost when needed.</p>
<p>Note that it’s always advised to evaluate/test models on real-life data as opposed to synthetic data.</p>
</div>
</div>
<section id="where-can-you-get-more-datasets" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</h3>
<p>The are many different places you can get datasets for text-based problems.</p>
<p>One of the best places is on the Hugging Face Hub, specifically <a href="https://huggingface.co/datasets">huggingface.co/datasets</a>.</p>
<p>Here you can find many different kinds of problem specific data such as <a href="https://huggingface.co/datasets?task_categories=task_categories:text-classification&amp;sort=trending">text classification</a>.</p>
<p>TK image - show example image of text classification datasets</p>
</section>
<section id="loading-the-dataset" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</h3>
<p>Once we’ve found/prepared a dataset on the Hugging Face Hub, we can use the Hugging Face <a href="https://huggingface.co/docs/datasets/en/index"><code>datasets</code></a> library to load it.</p>
<p>To load a dataset we can use the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/loading_methods#datasets.load_dataset"><code>datasets.load_dataset(path=NAME_OR_PATH_OF_DATASET)</code></a> function and pass it the name/path of the dataset we want to load.</p>
<p>In our case, our dataset name is <code>mrdbourke/learn_hf_food_not_food_image_captions</code>.</p>
<p>And since our dataset is hosted on Hugging Face, when we run the following code for the first time, it will download it.</p>
<p>If your target dataset is quite large, this download may take a while.</p>
<p>However, once the dataset is downloaded, subsequent reloads will be mush faster.</p>
<div id="cell-15" class="cell" data-outputid="2f45489c-02e8-4c03-bb7c-d73faa46c5b1" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset from Hugging Face Hub</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> datasets.load_dataset(path<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_image_captions"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the dataset</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 250
    })
})</code></pre>
</div>
</div>
<p>Dataset loaded!</p>
<p>Looks like our dataset has two features, <code>text</code> and <code>label</code>.</p>
<p>And 250 total rows (the number of examples in our dataset).</p>
<p>We can check the column names with <code>dataset.column_names</code>.</p>
<div id="cell-17" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What features are there?</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>dataset.column_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'train': ['text', 'label']}</code></pre>
</div>
</div>
<p>Looks like our dataset comes with a <code>train</code> split already (the whole dataset).</p>
<p>We can access the <code>train</code> split with <code>dataset["train"]</code> (some datasets also come with built-in <code>"test"</code> splits too).</p>
<div id="cell-19" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the training split</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 250
})</code></pre>
</div>
</div>
<p>How about we check out a single sample?</p>
<p>We can do so with indexing.</p>
<div id="cell-21" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
 'label': 'food'}</code></pre>
</div>
</div>
<p>Nice! We get back a dictionary with the keys <code>text</code> and <code>label</code>.</p>
<p>The <code>text</code> key contains the text of the image caption and the <code>label</code> key contains the label (food or not food).</p>
</section>
<section id="inspect-random-examples-from-the-dataset" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> Inspect random examples from the dataset</h3>
<p>At 250 total samples, our dataset isn’t too large.</p>
<p>So we could sit here and explore the samples one by one.</p>
<p>But whenever I interact with a new dataset, I like to view a bunch of random examples and get a <em>feel</em> of the data.</p>
<p>Doing so is inline with the data explorer’s motto: <em>visualize, visualize, visualize!</em></p>
<p>As a rule of thumb, I like to view at least 20-100 random examples when interacting with a new dataset.</p>
<p>Let’s write some code to view 5 random indexes of our data and their corresponding text and labels at a time.</p>
<div id="cell-24" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>random_indexs <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset[<span class="st">"train"</span>])), <span class="dv">5</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> dataset[<span class="st">"train"</span>][random_indexs]</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random samples from dataset:</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> <span class="bu">zip</span>(random_samples[<span class="st">"text"</span>], random_samples[<span class="st">"label"</span>]):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>item[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> | Label: </span><span class="sc">{</span>item[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random samples from dataset:

Text: Pizza with a stuffed crust, oozing with cheese | Label: food
Text: Brushing her cat's fur in her bedroom, a young girl concentrates | Label: not_food
Text: Set of muffin tins stacked together | Label: not_food
Text: Garden hose rolled up and ready in a yard | Label: not_food
Text: A cat and a dog sitting on a couch | Label: not_food</code></pre>
</div>
</div>
<p>Beautiful! Looks like our data contains a mix of shorter and longer sentences (between 5 and 20 words) of texts about food and not food.</p>
<p>We can get the unique labels in our dataset with <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.unique"><code>dataset["train"].unique("label")</code></a>.</p>
<div id="cell-26" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get unique label values</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>].unique(<span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>['food', 'not_food']</code></pre>
</div>
</div>
<p>If our dataset is small enough to fit into memory, we can count the number of different labels with Python’s <a href="https://docs.python.org/3/library/collections.html#counter-objects"><code>collections.Counter</code></a> (a method for counting objects in an iterable or mapping).</p>
<div id="cell-28" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check number of each label</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>Counter(dataset[<span class="st">"train"</span>][<span class="st">"label"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>Counter({'food': 125, 'not_food': 125})</code></pre>
</div>
</div>
<p>Excellent, looks like our dataset is well balanced with 125 samples of food and 125 samples of not food.</p>
<p>In a binary classification case, this is ideal.</p>
<p>If the classes were dramatically unbalanced (e.g.&nbsp;90% food and 10% not food) we might have to consider collecting/creating more data.</p>
<p>But best to train a model and see how it goes before making any drastic dataset changes.</p>
<p>Because our dataset is small, we could also inspect it via a pandas DataFrame (however, this may not be possible for extremely large datasets).</p>
<div id="cell-30" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn our dataset into a DataFrame and get a random sample</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df <span class="op">=</span> pd.DataFrame(dataset[<span class="st">"train"</span>])</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>food_not_food_df.sample(<span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">46</td>
<td>Set of mugs hanging on a hook</td>
<td>not_food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">125</td>
<td>A bowl of sliced cantaloupe with a sprinkle of...</td>
<td>food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30</td>
<td>Set of test tubes arranged in a rack</td>
<td>not_food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">86</td>
<td>A fruit kabob with a variety of fruits, such a...</td>
<td>food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">31</td>
<td>Potatoes, onions, garlic, cauliflower, and bro...</td>
<td>food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">227</td>
<td>A plate of sliced pineapple with a side of whi...</td>
<td>food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">127</td>
<td>Zucchini in a bowl, sprinkled with basil and s...</td>
<td>food</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-31" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the value counts of the label column</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df[<span class="st">"label"</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>label
food        125
not_food    125
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
</section>
<section id="preparing-data-for-text-classification" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="preparing-data-for-text-classification"><span class="header-section-number">4</span> Preparing data for text classification</h2>
<p>We’ve got our data ready but there are a few steps we’ll need to take before we can model it.</p>
<p>The main two being:</p>
<ol type="1">
<li><strong>Tokenization</strong> - turning our text into a numerical representation (machines prefer numbers rather than words), for example, <code>{"a": 0, "b": 1, "c": 2...}</code>.</li>
<li><strong>Creating a train/test split</strong> - right now our data is in a training split only but we’ll create a test set to evaluate our model’s performance.</li>
</ol>
<p>These don’t necessarily have to be in order either.</p>
<p>Before we get to them, let’s create a small mapping from our labels to numbers.</p>
<p>In the same way we need to tokenize our text into numerical representation, we also need to do the same for our labels.</p>
<section id="creating-a-mapping-from-labels-to-numbers" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="creating-a-mapping-from-labels-to-numbers"><span class="header-section-number">4.1</span> Creating a mapping from labels to numbers</h3>
<p>Our machine learning model will want to see all numbers (people do well with text, computers do well with numbers).</p>
<p>This goes for text as well as label input.</p>
<p>So let’s create a mapping from our labels to numbers.</p>
<p>Since we’ve only got a couple of labels (<code>"food"</code> and <code>"not_food"</code>), we can create a dictionary to map them to numbers, however, if you’ve got a fair few labels, you may want to make this mapping programmatically.</p>
<p>We can use these dictionaries later on for our model training as well as evaluation.</p>
<div id="cell-34" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping from id2label and label2id</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"not_food"</span>, <span class="dv">1</span>: <span class="st">"food"</span>}</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {<span class="st">"not_food"</span>: <span class="dv">0</span>, <span class="st">"food"</span>: <span class="dv">1</span>}</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label to ID mapping: </span><span class="sc">{</span>label2id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ID to Label mapping: </span><span class="sc">{</span>id2label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label to ID mapping: {'not_food': 0, 'food': 1}
ID to Label mapping: {0: 'not_food', 1: 'food'}</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a binary classification task (such as what we’re working on), the positive class, in our case <code>"food"</code>, is usually given the label <code>1</code> and the negative class (<code>"not_food"</code>) is given the label <code>0</code>.</p>
</div>
</div>
<div id="cell-36" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mappings programmatically from dataset</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {idx: label <span class="cf">for</span> idx, label <span class="kw">in</span> <span class="bu">enumerate</span>(dataset[<span class="st">"train"</span>].unique(<span class="st">"label"</span>)[::<span class="op">-</span><span class="dv">1</span>])} <span class="co"># reverse sort list to have "not_food" first</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {label: idx <span class="cf">for</span> idx, label <span class="kw">in</span> id2label.items()}</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Label to ID mapping: </span><span class="sc">{</span>label2id<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ID to Label mapping: </span><span class="sc">{</span>id2label<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label to ID mapping: {'not_food': 0, 'food': 1}
ID to Label mapping: {0: 'not_food', 1: 'food'}</code></pre>
</div>
</div>
<p>With our dictionary mappings created, we can update the labels of our dataset to be numeric.</p>
<p>We can do this using the <a href="https://huggingface.co/docs/datasets/en/process#map"><code>datasets.Dataset.map</code></a> method and passing it a function to apply to each example.</p>
<p>Let’s create a small function which turns an example label into a number.</p>
<div id="cell-38" class="cell" data-outputid="eba840c3-7652-41a8-a121-546cb9a8147f" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn labels into 0 or 1 (e.g. 0 for "not_food", 1 for "food")</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> map_labels_to_number(example):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  example[<span class="st">"label"</span>] <span class="op">=</span> label2id[example[<span class="st">"label"</span>]]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> example</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>example_sample <span class="op">=</span> {<span class="st">"text"</span>: <span class="st">"This is a sentence about my favourite food: honey."</span>, <span class="st">"label"</span>: <span class="st">"food"</span>}</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>map_labels_to_number(example_sample)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>{'text': 'This is a sentence about my favourite food: honey.', 'label': 1}</code></pre>
</div>
</div>
<p>Looks like our function works!</p>
<p>How about we map it to the whole dataset?</p>
<div id="cell-40" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map our dataset labels to numbers</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset[<span class="st">"train"</span>].<span class="bu">map</span>(map_labels_to_number)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>dataset[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
  'Set of books stacked on a desk',
  'Watching TV together, a family has their dog stretched out on the floor',
  'Wooden dresser with a mirror reflecting the room',
  'Lawn mower stored in a shed'],
 'label': [1, 0, 0, 0, 0]}</code></pre>
</div>
</div>
<p>Nice! Looks like our labels are all numerical now.</p>
<p>We can check a few random samples using <a href="https://huggingface.co/docs/datasets/en/process#shuffle"><code>dataset.shuffle()</code></a> and indexing for the first few.</p>
<div id="cell-42" class="cell" data-outputid="8089bfe3-2322-4bac-d2fd-89f626d0a1e6" data-execution_count="17">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the dataset and view the first 5 samples (will return different results each time) </span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>dataset.shuffle()[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>{'text': ['Set of measuring cups nested in a drawer',
  'Fennel in a bowl, sprinkled with lemon zest and served with a side of olive oil for a light, refreshing dish.',
  'Creamy spinach and potato curry, featuring fluffy potatoes and nutritious spinach in a rich sauce with cream and garam masala.',
  'A slice of pizza with a spicy kick, featuring jalapeno peppers',
  'A kabob of grilled vegetables, including zucchini, squash, and onion, perfect for a summer barbecue.'],
 'label': [0, 1, 1, 1, 1]}</code></pre>
</div>
</div>
</section>
<section id="split-the-dataset-into-training-and-test-sets" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.2</span> Split the dataset into training and test sets</h3>
<p>Right now our dataset only has a training split.</p>
<p>However, we’d like to create a test split so we can evaluate our model.</p>
<p>In essence, our model will learn patterns (the relationship between text captions and their labels of food/not_food) on the training data.</p>
<p>And we will evaluate those learned patterns on the test data.</p>
<p>We can split our data using the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.train_test_split"><code>datasets.Dataset.train_test_split</code></a> method.</p>
<p>We can use the <code>test_size</code> parameter to define the percentage of data we’d like to use in our test set (e.g.&nbsp;<code>test_size=0.2</code> would mean 20% of the data goes to the test set).</p>
<div id="cell-44" class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train/test splits</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>) <span class="co"># note: seed isn't needed, just here for reproducibility, without it you will get different splits each time you run the cell</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[109], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Create train/test splits</span>
<span class="ansi-green-fg">----&gt; 2</span> dataset <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">dataset</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">train_test_split</span>(test_size<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(98,98,98)">0.2</span>, seed<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(98,98,98)">42</span>) <span style="font-style:italic;color:rgb(95,135,135)"># note: seed isn't needed, just here for reproducibility, without it you will get different splits each time you run the cell</span>
<span class="ansi-green-fg ansi-bold">      3</span> dataset

<span class="ansi-red-fg">AttributeError</span>: 'DatasetDict' object has no attribute 'train_test_split'</pre>
</div>
</div>
</div>
<p>Perfect!</p>
<p>Our dataset has been split into 200 training examples and 50 testing examples.</p>
<p>Let’s visualize a few random examples to make sure they still look okay.</p>
<div id="cell-46" class="cell" data-outputid="35f0da00-ab15-42e0-9d81-757ad3da1618" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>random_idx_train <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"train"</span>]))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>random_sample_train <span class="op">=</span> dataset[<span class="st">"train"</span>][random_idx_train]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>random_idx_test <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"test"</span>]))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>random_sample_test <span class="op">=</span> dataset[<span class="st">"test"</span>][random_idx_test]</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from training dataset:"</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_train[<span class="st">'text'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Label: </span><span class="sc">{</span>random_sample_train[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_train[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from testing dataset:"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_test[<span class="st">'text'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Label: </span><span class="sc">{</span>random_sample_test[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_test[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random sample from training dataset:
Text: Turnips in a bowl, sprinkled with pepper and served with a side of mustard sauce for a hearty, flavorful dish.
Label: 1 (food)

[INFO] Random sample from testing dataset:
Text: Set of stainless steel utensils arranged on a kitchen table
Label: 0 (not_food)</code></pre>
</div>
</div>
</section>
<section id="tk---tokenizing-text-data" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="tk---tokenizing-text-data"><span class="header-section-number">4.3</span> TK - Tokenizing text data</h3>
<p>Labels numericalized, dataset split, time to turn our text into numbers.</p>
<p>How?</p>
<p><strong>Tokenization</strong>.</p>
<p>What’s tokenization?</p>
<p>Tokenization is the process of converting a non-numerical data source into numbers.</p>
<p>Why?</p>
<p>Because machines (especially machine learning models) prefer numbers to human-style data.</p>
<p>In the case of the text <code>"I love pizza"</code> a very simple method of tokenization might be to convert each word to a number.</p>
<p>For example, <code>{"I": 0, "love": 1, "pizza": 2}</code>.</p>
<p>However, for most modern machine learning models, the tokenization process is a bit more nuanced.</p>
<p>For example, the text <code>"I love pizza"</code> might be tokenized into something more like <code>[101, 1045, 2293, 10733, 102]</code>.</p>
<p>TK image - showcase an example using OpenAI’s tokenization tool and what this looks like with “I love pizza”: https://platform.openai.com/tokenizer</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Depending on the model you use, the tokenization process could be different.</p>
<p>For example, one model might turn <code>"I love pizza"</code> into <code>[40, 3021, 23317]</code>, where as another model might turn it into <code>[101, 1045, 2293, 10733, 102]</code>.</p>
<p>To deal with this, Hugging Face models often pair models and tokenizers together by name.</p>
<p>Such is the case with <a href="https://huggingface.co/distilbert/distilbert-base-uncased"><code>distilbert/distilbert-base-uncased</code></a> (there is a <code>tokenizer.json</code> file as well as a <code>tokenizer_config.json</code> file which contains all of the tokenizer implementation details).</p>
<p>For more examples of tokenization, you can see OpenAI’s <a href="https://platform.openai.com/tokenizer">tokenization visualizer tool</a> as well as their open-source library <a href="https://github.com/openai/tiktoken"><code>tiktoken</code></a>, Google also have an open-source tokenization library called <a href="https://github.com/google/sentencepiece"><code>sentencepiece</code></a>, finally Hugging Face’s <a href="https://github.com/huggingface/tokenizers"><code>tokenizers</code></a> library is also a great resource (this is what we’ll be using behind the scenes).</p>
</div>
</div>
<p>Many of the text-based models on Hugging Face come paired with their own tokenizer.</p>
<p>For example, the <a href="https://huggingface.co/distilbert/distilbert-base-uncased"><code>distilbert/distilbert-base-uncased</code></a> model is paired with the <code>distilbert/distilbert-base-uncased</code> tokenizer.</p>
<p>We can load the tokenizer for a given model using the <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes"><code>transformers.AutoTokenizer.from_pretrained</code></a> method and passing it the name of the model we’d like to use.</p>
<p>The <code>transformers.AutoTokenizer</code> class is part of a series of Auto Classes (such as <code>AutoConfig</code>, <code>AutoModel</code>, <code>AutoProcessor</code>) which automatically loads the correct configuration settings for a given model ID.</p>
<p>Let’s load the tokenizer for the <code>distilbert/distilbert-base-uncased</code> model and see how it works.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why use the <code>distilbert/distilbert-base-uncased</code> model?</p>
<p>The short answer is that I’ve used it before and it works well (and fast) on various text classification tasks.</p>
<p>It also performed well in the <a href="https://arxiv.org/abs/1910.01108">original research paper</a> which introduced it.</p>
<p>The longer answer is that Hugging Face has many available open-source models for many different problems available at <a href="https://huggingface.co/models">https://huggingface.co/models</a>.</p>
<p>Navigating these models can take some practice.</p>
<p>And several models may be suited for the same task (though with various tradeoffs such as size and speed).</p>
<p>However, overtime and with adequate experimentation, you’ll start to build an intuition on which models are good for which problems.</p>
</div>
</div>
<div id="cell-48" class="cell" data-outputid="f277b622-267d-4d06-b2cb-6bc204b2f62d" data-execution_count="20">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(pretrained_model_name_or_path<span class="op">=</span><span class="st">"distilbert/distilbert-base-uncased"</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                                          use_fast<span class="op">=</span><span class="va">True</span>) <span class="co"># uses fast tokenization (backed by tokenziers library and implemented in Rust) by default, if not available will default to Python implementation</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>tokenizer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
    0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    100: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    101: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    102: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    103: AddedToken("[MASK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}</code></pre>
</div>
</div>
<p>Nice!</p>
<p>There’s our tokenizer!</p>
<p>It’s an instance of the <a href="https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"><code>transformers.DistilBertTokenizerFast</code></a> class.</p>
<p>You can read more about it in the documentation.</p>
<p>For now, let’s try it out by passing it a string of text.</p>
<div id="cell-50" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out tokenizer</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"I love pizza"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<div id="cell-51" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try adding a "!" at the end</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"I love pizza!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>Woohoo!</p>
<p>Our text gets turned into numbers (or tokens).</p>
<p>Notice how with even a slight change in the text, the tokenizer produces different results?</p>
<p>The <code>input_ids</code> are our tokens.</p>
<p>And the <code>attention_mask</code> (in our case, all <code>[1, 1, 1, 1, 1, 1]</code>) is a mask which tells the model which tokens to use or not.</p>
<p>Tokens with a mask value of <code>1</code> get used and tokens with a mask value of <code>0</code> get ignored.</p>
<p>There are several attributes of the <code>tokenizer</code> we can explore.</p>
<ul>
<li><code>tokenizer.vocab</code> will return the vocabulary of the tokenizer or in other words, the unique words/word pieces the tokenizer is capable of converting into numbers.</li>
<li><code>tokenizer.model_max_length</code> will return the maximum length of a sequence the tokenizer can process, pass anything longer than this and the sequence will be truncated.</li>
</ul>
<div id="cell-53" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the length of the vocabulary </span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>length_of_tokenizer_vocab <span class="op">=</span> <span class="bu">len</span>(tokenizer.vocab)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Length of tokenizer vocabulary: </span><span class="sc">{</span>length_of_tokenizer_vocab<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the maximum sequence length the tokenizer can handle</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>max_tokenizer_input_sequence_length <span class="op">=</span> tokenizer.model_max_length</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Max tokenizer input sequence length: </span><span class="sc">{</span>max_tokenizer_input_sequence_length<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length of tokenizer vocabulary: 30522
Max tokenizer input sequence length: 512</code></pre>
</div>
</div>
<p>Woah, looks like our tokenizer has a vocabulary of <code>30,522</code> different words and word pieces.</p>
<p>And it can handle a sequence length of up to <code>512</code> (any sequence longer than this will be automatically truncated from the end).</p>
<p>Let’s check out some of the vocab.</p>
<p>Can I find my own name?</p>
<div id="cell-55" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Does "daniel" occur in the vocab?</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"daniel"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>3817</code></pre>
</div>
</div>
<p>Oooh, looks like my name is <code>3817</code> in the tokenizer’s vocab.</p>
<p>Can you find your own name? (note: there may be an error if the token doesn’t exist, we’ll get to this)</p>
<p>How about “pizza”?</p>
<div id="cell-57" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"pizza"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>10733</code></pre>
</div>
</div>
<p>What if a word doesn’t exist in the vocab?</p>
<div id="cell-59" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>tokenizer.vocab[<span class="st">"akash"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[26], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg">tokenizer</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">vocab</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">akash</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">]</span>

<span class="ansi-red-fg">KeyError</span>: 'akash'</pre>
</div>
</div>
</div>
<p>Dam, we get a <code>KeyError</code>.</p>
<p>Not to worry, this is okay, since when calling the <code>tokenizer</code> on the word, it will automatically split the word into word pieces or subwords.</p>
<div id="cell-61" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tokenizer(<span class="st">"akash"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>{'input_ids': [101, 9875, 4095, 102], 'attention_mask': [1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>It works!</p>
<p>We can check what word pieces <code>"akash"</code> got broken into with <a href="https://huggingface.co/docs/transformers/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.convert_ids_to_tokens"><code>tokenizer.convert_ids_to_tokens(input_ids)</code></a>.</p>
<div id="cell-63" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>tokenizer.convert_ids_to_tokens(tokenizer(<span class="st">"akash"</span>).input_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>['[CLS]', 'aka', '##sh', '[SEP]']</code></pre>
</div>
</div>
<p>Ahhh, it seems <code>"akash"</code> was split into two tokens, <code>["aka", "##sh"]</code>.</p>
<p>The <code>"##"</code> at the start of <code>"##sh"</code> means that the sequence is part of a larger sequence.</p>
<p>And the <code>"[CLS]"</code> and <code>"[SEP]"</code> tokens are special tokens indicating the start and end of a sequence.</p>
<p>Now, since tokenizers can deal with any text, what if there was an unknown token?</p>
<p>For example, rather than <code>"pizza"</code> someone used the pizza emoji 🍕?</p>
<p>Let’s try!</p>
<div id="cell-65" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to tokenize an emoji</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>tokenizer.convert_ids_to_tokens(tokenizer(<span class="st">"🍕"</span>).input_ids)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>['[CLS]', '[UNK]', '[SEP]']</code></pre>
</div>
</div>
<p>Ahh, we get the special <code>"[UNK]"</code> token.</p>
<p>This stands for “unknown”.</p>
<p>The combination of word pieces and <code>"[UNK]"</code> special token means that our <code>tokenizer</code> will be able to turn almost any text into numbers for our model.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Keep in mind that just because one tokenizer uses an unknown special token for a particular word or emoji (🍕) doesn’t mean another will.</p>
</div>
</div>
<p>Since the <code>tokenizer.vocab</code> is a Python dictionary, we can get a sample of the vocabulary using <code>tokenizer.vocab.items()</code>.</p>
<p>How about we get the first 5?</p>
<div id="cell-67" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the first 5 items in the tokenizer vocab</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(tokenizer.vocab.items())[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>[('!', 999), ('"', 1000), ('#', 1001), ('##!', 29612), ('##"', 29613)]</code></pre>
</div>
</div>
<p>There’s our <code>'!'</code> from before! Looks like the first five items are all related to punctuation points.</p>
<p>How about a random sample of tokens?</p>
<div id="cell-69" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>random.sample(<span class="bu">sorted</span>(tokenizer.vocab.items()), k<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>[('chased', 13303),
 ('luther', 9678),
 ('fossil', 10725),
 ('sphinx', 27311),
 ('murderous', 25303)]</code></pre>
</div>
</div>
</section>
<section id="making-a-preprocessing-function-to-tokenize-text" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="making-a-preprocessing-function-to-tokenize-text"><span class="header-section-number">4.4</span> Making a preprocessing function to tokenize text</h3>
<p>Rather than tokenizing our texts one by one, it’s best practice to define a preprocessing function which does it for us.</p>
<p>This process works regardless of whether you’re working with text data or other kinds of data such as images or audio.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Turning data into numbers
</div>
</div>
<div class="callout-body-container callout-body">
<p>For any kind of machine learning workflow, an important first step is turning your input data into numbers.</p>
<p>As machine learning models are algorithms which find patterns in numbers, before they can find patterns in your data (text, images, audio, tables) it must be numerically encoded first (e.g.&nbsp;tokenizing text).</p>
<p>To help with this, <code>transformers</code> has an <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoProcessor"><code>AutoProcessor</code></a> class which can preprocess data in a specific format required for a paired model.</p>
</div>
</div>
<p>To prepare our text data, let’s create a preprocessing function to take in a dictionary which contains the key <code>"text"</code> which has the value of a target string (our data samples come in the form of dictionaries) and then returns the tokenized <code>"text"</code>.</p>
<p>We’ll set the following parameters in our <code>tokenizer</code>:</p>
<ul>
<li><code>padding=True</code> - This will make all the sequences in a batch the same length by padding shorter sequences with 0’s until they equal the longest size in the batch. Why? If there are different size sequences in a batch, you can sometimes run into dimensionality issues.</li>
<li><code>truncation=True</code> - This will shorten sequences longer than the model can handle to the model’s max input size (e.g.&nbsp;if a sequence is 1000 long and the model can handle 512, it will be shortened to 512 via removing all tokens after 512).</li>
</ul>
<p>You can see more parameters available for the <code>tokenizer</code> in the <a href="https://huggingface.co/docs/transformers/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"><code>transformers.PreTrainedTokenizer</code> documentation</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For more on padding and truncation (two important concepts in sequence processing), I’d recommend reading the Hugging Face documentation on <a href="https://huggingface.co/docs/transformers/en/pad_truncation">Padding and Truncation</a>.</p>
</div>
</div>
<div id="cell-71" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_text(examples):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Tokenize given example text and return the tokenized text.</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>],</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                     padding<span class="op">=</span><span class="va">True</span>, <span class="co"># pad short sequences to longest sequence in the batch</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>                     truncation<span class="op">=</span><span class="va">True</span>) <span class="co"># truncate long sequences to the maximum length the model can handle</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wonderful!</p>
<p>Now let’s try it out on an example sample.</p>
<div id="cell-73" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>example_sample_2 <span class="op">=</span> {<span class="st">"text"</span>: <span class="st">"I love pizza"</span>, <span class="st">"label"</span>: <span class="dv">1</span>}</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>tokenize_text(example_sample_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>{'input_ids': [101, 1045, 2293, 10733, 102], 'attention_mask': [1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<p>Looking good!</p>
<p>How about we map our <code>tokenize_text</code> function to our whole <code>dataset</code>?</p>
<p>We can do so with the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.map"><code>datasets.Dataset.map</code> method</a>.</p>
<p>The <code>map</code> method allows us to apply a given function to all examples in a dataset.</p>
<p>By setting <code>batched=True</code> we can apply the given function to batches of examples (many at a time) to speed up computation time.</p>
<p>Let’s create a <code>tokenized_dataset</code> object by calling <code>map</code> on our <code>dataset</code> and passing it our <code>tokenize_text</code> function.</p>
<div id="cell-75" class="cell" data-outputid="d72b4325-b4de-4f65-f930-50007d45c8d5" data-execution_count="34">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Map our tokenize_text function to the dataset</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(function<span class="op">=</span>tokenize_text, </span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>                                batched<span class="op">=</span><span class="va">True</span>, <span class="co"># set batched=True to operate across batches of examples rather than only single examples</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>                                batch_size<span class="op">=</span><span class="dv">1000</span>) <span class="co"># defaults to 1000, can be increased if you have a large dataset</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>tokenized_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 200
    })
    test: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 50
    })
})</code></pre>
</div>
</div>
<p>Dataset tokenized!</p>
<p>Let’s inspect a pair of samples.</p>
<div id="cell-77" class="cell" data-outputid="c1b0b958-b9a5-4274-e8c1-eaf0ac4cdf3a" data-execution_count="35">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get two samples from the tokenized dataset</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>train_tokenized_sample <span class="op">=</span> tokenized_dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>test_tokenized_sample <span class="op">=</span> tokenized_dataset[<span class="st">"test"</span>][<span class="dv">0</span>]</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key <span class="kw">in</span> train_tokenized_sample.keys():</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Key: </span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Train sample: </span><span class="sc">{</span>train_tokenized_sample[key]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Test sample: </span><span class="sc">{</span>test_tokenized_sample[key]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Key: text
Train sample: Set of headphones placed on a desk
Test sample: A slice of pepperoni pizza with a layer of melted cheese

[INFO] Key: label
Train sample: 0
Test sample: 1

[INFO] Key: input_ids
Train sample: [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Test sample: [101, 1037, 14704, 1997, 11565, 10698, 10733, 2007, 1037, 6741, 1997, 12501, 8808, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

[INFO] Key: attention_mask
Train sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Test sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
</code></pre>
</div>
</div>
<p>Beautiful! Our samples have been tokenized.</p>
<p>Notice the zeroes on the end of the <code>inpud_ids</code> and <code>attention_mask</code> values.</p>
<p>These are padding tokens to ensure that each sample has the same length as the longest sequence in a given batch.</p>
<p>We can now use these tokenized samples later on in our model.</p>
</section>
<section id="tokenization-takeaways" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="tokenization-takeaways"><span class="header-section-number">4.5</span> Tokenization takeaways</h3>
<p>We’ve seen tokenizers in practice.</p>
<p>A few takeaways before we start to build a model:</p>
<ul>
<li>Tokenizers are used to turn text (or other forms of data such as images and audio) into a numerical representation ready to be used with a machine learning model.</li>
<li>Many models reuse existing tokenizers and many models have their own specific tokenizer paired with them. Hugging Face’s <code>transformers.AutoTokenizer</code>, <code>transformers.AutoProcessor</code> and <code>transformers.AutoModel</code> classes make it easy to pair tokenizers and models based on their name (e.g.&nbsp;<code>distilbert/distilbert-base-uncased</code>).</li>
</ul>
</section>
</section>
<section id="tk---setting-up-an-evaluation-metric" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="tk---setting-up-an-evaluation-metric"><span class="header-section-number">5</span> TK - Setting up an evaluation metric</h2>
<p>Aside from training a model, one of the most important steps in machine learning is evaluating a model.</p>
<p>To do, we can use evaluation metrics.</p>
<p>An evaluation metric attempts to represent a model’s performance in a single (or series) of numbers (note, I say “attempts” here because evaluation metrics are useful to guage performance but the real test of a machine learning model is in the real world).</p>
<p>There are many different kinds of evaluation metrics for various problems.</p>
<p>But since we’re focused on text classification, we’ll use <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification">accuracy</a> as our evaluation metric.</p>
<p>A model which gets 99/100 predictions correct has an accuracy of 99%.</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{correct classifications}}{\text{all classifications}}
\]</span></p>
<p>For some projects, you may have a minimum standard of a metric.</p>
<p>For example, when I worked on an insurance claim classification model, the clients required over 98% accuracy on the test dataset for it to be viable to use in production.</p>
<p>If needed, we can craft these evaluation metrics ourselves.</p>
<p>However, Hugging Face has a library called <a href="https://huggingface.co/docs/evaluate/en/index"><code>evaluate</code></a> which has various metrics built in ready to use.</p>
<p>We can load a metric using <code>evaluate.load("METRIC_NAME")</code>.</p>
<p>Let’s load in <code>"accuracy"</code> and build a function to measure accuracy by comparing arrays of predictions and labels.</p>
<div id="cell-81" class="cell" data-outputid="4a2b0f85-db47-4f0f-cbc3-fa148c19a646" data-execution_count="36">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>accuracy_metric <span class="op">=</span> evaluate.load(<span class="st">"accuracy"</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy(predictions_and_labels: Tuple[np.array, np.array]):</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="co">  Computes the accuracy of a model by comparing the predictions and labels.</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>  predictions, labels <span class="op">=</span> predictions_and_labels</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get highest prediction probability of each prediction if predictions are probabilities</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(predictions.shape) <span class="op">&gt;=</span> <span class="dv">2</span>:</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> accuracy_metric.compute(predictions<span class="op">=</span>predictions, references<span class="op">=</span>labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Accuracy function created!</p>
<p>Now let’s test it out.</p>
<div id="cell-83" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create example list of predictions and labels</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>example_predictions_all_correct <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>example_predictions_one_wrong <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>example_labels <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the function</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy when all predictions are correct: </span><span class="sc">{</span>compute_accuracy((example_predictions_all_correct, example_labels))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy when one prediction is wrong: </span><span class="sc">{</span>compute_accuracy((example_predictions_one_wrong, example_labels))<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy when all predictions are correct: {'accuracy': 1.0}
Accuracy when one prediction is wrong: {'accuracy': 0.9}</code></pre>
</div>
</div>
<p>Excellent, our function works just as we’d like.</p>
<p>When all predictions are correct, it scores 1.0 (or 100% accuracy) and when 9/10 predictions are correct, it returns 0.9 (or 90% accuracy).</p>
<p>We can use this function during training and evaluation of our model.</p>
</section>
<section id="setting-up-a-model-for-training" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="setting-up-a-model-for-training"><span class="header-section-number">6</span> Setting up a model for training</h2>
<p>We’ve gone through the important steps of setting data up for training (and evaluation).</p>
<p>Now let’s prepare a model.</p>
<p>We’ll keep going through the following steps:</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<ul>
<li>TK image - steps for training in Hugging Face</li>
</ul>
<p>Let’s start by creating an instance of a model.</p>
<p>Since we’re working on text classification, we’ll do so with <code>transformers.AutoModelForSequenceClassification</code> (where sequence classification means a sequence of something, e.g.&nbsp;our sequences of text).</p>
<p>We can use the <code>from_pretrained()</code> method to instatiate a pretrained model from the Hugging Face Hub.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The “pretrained” in <a href="https://huggingface.co/docs/transformers/v4.42.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained"><code>transformers.AutoModelForSequenceClassification.from_pretrained</code></a> means acquiring a model which has already been trained on a certain dataset.</p>
<p>This is common practice in many machine learning projects and is known as <strong>transfer learning</strong>.</p>
<p>The idea is to take an existing model which works well on a task similar to your target task and then <strong>fine-tune</strong> it to work even better on your target task.</p>
<p>In our case, we’re going to use the pretrained DistilBERT base model (<a href="https://huggingface.co/distilbert/distilbert-base-uncased"><code>distilbert/distilbert-base-uncased</code></a>) which has been trained on <a href="https://huggingface.co/datasets/bookcorpus/bookcorpus">many thousands of books</a> as well as a version of the <a href="https://huggingface.co/datasets/legacy-datasets/wikipedia">English Wikipedia</a> (millions of words).</p>
<p>This training gives it a very good baseline representation of the patterns in language.</p>
<p>We’ll take this baseline representation of the patterns in language and adjust it slightly to focus specifically on predicting whether an image caption is about food or not (based on the words it contains).</p>
<p>The main two benefits of using transfer learning are:</p>
<ol type="1">
<li>Ability to get good results with smaller amounts of data (since the main representations are learned on a larger dataset, we only have to show the model a few examples of our specific problem).</li>
<li>This process can be repeated acorss various domains and tasks. For example, you can take a computer vision model trained on millions of images and customize it to your own use case. Or an audio model trained on many different nature sounds and customize it specifically for birds.</li>
</ol>
<p>So when starting a new machine learning project, one of the first questions you should ask is: does an existing pretrained model similar to my task exist and can I fine-tune it for my own task?</p>
<p>For an end-to-end example of transfer learning in PyTorch (another popular deep learning framework), see <a href="https://www.learnpytorch.io/06_pytorch_transfer_learning/">PyTorch Transfer Learning</a>.</p>
</div>
</div>
<p>Time to setup our <code>model</code> instance.</p>
<p>A few things to note:</p>
<ul>
<li>We’ll use <a href="https://huggingface.co/docs/transformers/v4.42.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained"><code>transformers.AutoModelForSequenceClassification.from_pretrained</code></a>, this will create the model architecture we specify with the <code>pretrained_model_name_or_path</code> parameter.</li>
<li>The <code>AutoModelForSequenceClassification</code> class comes with a classification head on top of our mdoel (so we can customize this to the number of classes we have with the <code>num_labels</code> parameter).</li>
<li>Using <code>from_pretrained</code> will also call the <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/configuration#transformers.PretrainedConfig"><code>transformers.PretrainedConfig</code></a> class which will enable us to set <code>id2label</code> and <code>label2id</code> parameters for our fine-tuning task.</li>
</ul>
<p>Let’s refresh what our <code>id2label</code> and <code>label2id</code> objects look like.</p>
<div id="cell-86" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get id and label mappings</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"id2label: </span><span class="sc">{</span>id2label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"label2id: </span><span class="sc">{</span>label2id<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>id2label: {0: 'not_food', 1: 'food'}
label2id: {'not_food': 0, 'food': 1}</code></pre>
</div>
</div>
<p>Beautiful, we can pass these mappings to <code>transformers.AutoModelForSequenceClassification.from_pretrained</code>.</p>
<div id="cell-88" class="cell" data-outputid="ed01beb4-3cf7-4209-eaea-444e5aa51c5b" data-execution_count="39">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup model for fine-tuning with classification head (top layers of network)</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    pretrained_model_name_or_path<span class="op">=</span><span class="st">"distilbert/distilbert-base-uncased"</span>,</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">2</span>, <span class="co"># can customize this to the number of classes in your dataset</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    id2label<span class="op">=</span>id2label, <span class="co"># mappings from class IDs to the class labels (for classification tasks)</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    label2id<span class="op">=</span>label2id</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<p>Model created!</p>
<p>You’ll notice that a warning message gets displayed:</p>
<blockquote class="blockquote">
<p>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: [‘classifier.bias’, ‘classifier.weight’, ‘pre_classifier.bias’, ‘pre_classifier.weight’] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p>
</blockquote>
<p>This is essentially saying “hey, some of the layers in this model are newly initialized (with random patterns) and you should probably customize them to your own dataset”.</p>
<p>This happens because we used the <code>AutoModelForSequenceClassification</code> class.</p>
<p>Whilst the majority of the layers in our model have already learned patterns from a large corpus of text, the top layers (classifier layers) have been randomly setup so we can customize them on our own.</p>
<p>Let’s try and make a prediction with our model and see what happens.</p>
<div id="cell-90" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try and make a prediction with the loaded model (this will error)</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>model(<span class="op">**</span>tokenized_dataset[<span class="st">"train"</span>][<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[40], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Try and make a prediction with the loaded model (this will error)</span>
<span class="ansi-green-fg">----&gt; 2</span> <span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">tokenized_dataset</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">train</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">0</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1511</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1509</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color:rgb(98,98,98)">*</span>args, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>kwargs)  <span style="font-style:italic;color:rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-fg ansi-bold">   1510</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1511</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1520</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1515</span> <span style="font-style:italic;color:rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-fg ansi-bold">   1516</span> <span style="font-style:italic;color:rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-fg ansi-bold">   1517</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> (<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_backward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-fg ansi-bold">   1518</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_pre_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-fg ansi-bold">   1519</span>         <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_hooks <span style="font-weight:bold;color:rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1520</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1522</span> <span style="font-weight:bold;color:rgb(0,135,0)">try</span>:
<span class="ansi-green-fg ansi-bold">   1523</span>     result <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>

<span class="ansi-red-fg">TypeError</span>: DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'text'</pre>
</div>
</div>
</div>
<p>Oh no! We get an error.</p>
<p>Not to worry, this is only because our model hasn’t been trained on our own dataset yet.</p>
<p>Let’s take a look at the layers in our model.</p>
<div id="cell-92" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the model </span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>DistilBertForSequenceClassification(
  (distilbert): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)</code></pre>
</div>
</div>
<ul>
<li>TK image - show what it looks like when fine-tuning a model for a specific task, e.g.&nbsp;backbone is pre-trained layers, classification head is swapped out</li>
</ul>
<p>You’ll notice that the model comes in 3 main parts (data flows through these sequentially):</p>
<ol type="1">
<li><code>embeddings</code> - This part of the model turns the input tokens into a learned representation. So rather than just a list of integers, the values become a learned representation. This learned representation comes from the base model learning how different words and word pieces relate to eachother thanks to its training data. The size of <code>(30522, 768)</code> means the <code>30,522</code> words in the vocabulary are all represented by vectors of size <code>768</code> (one word gets represented by 768 numbers, these are often not human interpretable).</li>
<li><code>transformer</code> - This is the main body of the model. There are several <code>TransformerBlock</code> layers stacked on top of each other. These layers attempt to learn a deeper representation of the data going through the model. A thorough breakdown of these layers is beyond the scope of this tutorial, however, for and in-depth guide on Transformer-based models, I’d recommend reading <a href="https://peterbloem.nl/blog/transformers"><em>Transformers from scratch</em></a> by Peter Bloem, going through <a href="https://www.youtube.com/watch?v=XfpMkf4rD6E">Andrej Karpathy’s lecture on Transformers and their history</a> or reading the original <a href="https://arxiv.org/abs/1706.03762"><em>Attention is all you need</em></a> paper (this is the paper that introduced the Transformer architecture).</li>
<li><code>classifier</code> - This is what is going to take the representation of the data and compress it into our number of target classes (notice <code>out_features=2</code>, this means that we’ll get two output numbers, one for each of our classes).</li>
</ol>
<p>For more on the entire DistilBert architecture and its training setup, I’d recommend reading the <a href="https://arxiv.org/abs/1910.01108"><em>DistilBert paper</em></a> from the Hugging Face team.</p>
<p>Rather than breakdown the model itself, we’re focused on using it for a particular task (classifying text).</p>
<section id="counting-the-parameters-of-our-model" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="counting-the-parameters-of-our-model"><span class="header-section-number">6.1</span> Counting the parameters of our model</h3>
<p>Before we move into training, we can get another insight into our model by counting its number of parameters.</p>
<p>Let’s create a small function to count the number of trainable (these will update during training) and total parameters in our model.</p>
<div id="cell-95" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_params(model):</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Count the parameters of a PyTorch model.</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    trainable_parameters <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>    total_parameters <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"trainable_parameters"</span>: trainable_parameters, <span class="st">"total_parameters"</span>: total_parameters}</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the parameters of the model</span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>count_params(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>{'trainable_parameters': 66955010, 'total_parameters': 66955010}</code></pre>
</div>
</div>
<p>Nice!</p>
<p>Looks like our model has a total of 66,955,010 parameters and all of them are trainable.</p>
<p>A parameter is a numerical value in a model which is capable of being updated to better represent the input data.</p>
<p>I like to think of them as a small opportunity to learn patterns in the data.</p>
<p>If a model has three parameters, it has three small opportunities to learn patterns in the data.</p>
<p>Whereas, if a model has 60,000,000+ (60M) parameters (like our <code>model</code>), it has 60,000,000+ small opportunities to learn patterns in the data.</p>
<p>Some models such as Large Language Models (LLMs) like <a href="https://huggingface.co/meta-llama/Meta-Llama-3-70B">Llama 3 70B</a> have 70,000,000,000+ (70B) parameters (over 1000x our model).</p>
<p>In essence, the more parameters a model has, the more opportunities it has to learn (generally).</p>
<p>More parameters often results in more capabilities.</p>
<p>However, more parameters also often results in a much larger model size (e.g.&nbsp;many gigabytes versus hundreds of megabytes) as well as a much longer compute time (fewer samples per second).</p>
<p>For our use case, a binary text classification task, 60M parameters is more than enough.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why count the parameters in a model?</p>
<p>While it may be tempting to always go with a model that has the most parameters, there are many considerations to take into account before doing so.</p>
<blockquote class="blockquote">
<p>What hardware is the model going to run on?</p>
</blockquote>
<p>If you need the model to run on cheap hardware, you’ll likely want a smaller model.</p>
<blockquote class="blockquote">
<p>How fast do you need the model to be?</p>
</blockquote>
<p>If you need 100-1000s of predictions per second, you’ll likely want a smaller model.</p>
<blockquote class="blockquote">
<p>“I don’t mind about speed or cost, I just want quality.”</p>
</blockquote>
<p>Go with the biggest model you can.</p>
<p>However, often times you can get really good results by training a small model to do a specific task using quality data than by just always using a large model.</p>
</div>
</div>
</section>
<section id="create-a-directory-for-saving-models" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="create-a-directory-for-saving-models"><span class="header-section-number">6.2</span> Create a directory for saving models</h3>
<p>Training a model can take a while.</p>
<p>So we’ll want a place to save our models.</p>
<p>Let’s create a directory called <code>"learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</code> (it’s a bit verbose and you can change this if you like but I like to be specific).</p>
<div id="cell-98" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model output directory</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models directory</span></span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>models_dir <span class="op">=</span> Path(<span class="st">"models"</span>)</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>models_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save name</span></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>model_save_name <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save path</span></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>model_save_dir <span class="op">=</span> Path(models_dir, model_save_name)</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>model_save_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')</code></pre>
</div>
</div>
</section>
<section id="setting-up-training-arguments-with-trainingarguments" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="setting-up-training-arguments-with-trainingarguments"><span class="header-section-number">6.3</span> Setting up training arguments with TrainingArguments</h3>
<p>Time to get our model ready for training!</p>
<p>We’re up to step 3 of our process:</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>✅ Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<p>The <code>transformers.TrainingArguments</code> class contains a series of helpful items, including hyperparameter settings and model saving strategies to use throughout training.</p>
<p>It has many parameters, too many to explain here.</p>
<p>However, the following table breaks down a helpful handful.</p>
<p>Some of the parameters we’ll set are the same as the defaults (this is on purpose as the defaults are often pretty good), some such as <code>learning_rate</code> are different.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>output_dir</code></td>
<td style="text-align: left;">Name of output directory to save the model and checkpoints to. For example, <code>learn_hf_food_not_food_text_classifier_model</code>.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>learning_rate</code></td>
<td style="text-align: left;">Value of the initial learning rate to use during training. Passed to <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.AdamW</code></a>. Initial learning rate because the learning rate can be dynamic during training. The ideal learning is experimental in nature. Defaults to <code>5e-5</code> or <code>0.00001</code> but we’ll use <code>0.0001</code>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>per_device_train_batch_size</code></td>
<td style="text-align: left;">Size of batches to place on target device during training. For example, a batch size of <code>32</code> means the model will look at 32 samples at a time. A batch size too large will result in out of memory issues (e.g.&nbsp;your GPU can’t handle holding a large number of samples in memory at a time).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>per_device_eval_batch_size</code></td>
<td style="text-align: left;">Size of batches to place on target device during evaluation. Can often be larger than during training because no gradients are being calculated. For example, training batch size could be 32 where as evaluation batch size may be able to be 128 (4x larger). Though these are only esitmates.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>num_train_epochs</code></td>
<td style="text-align: left;">Number of times to pass over the data to try and learn patterns. For example, if <code>num_train_epochs=10</code>, the model will do 10 full passes of the training data. Because we’re working with a small dataset, 10 epochs should be fine to begin with. However, if you had a larger dataset, you may want to do a few experiments using less data (e.g.&nbsp;10% of the data) for a smaller number of epochs to make sure things work.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>eval_strategy</code></td>
<td style="text-align: left;">When to evaluate the model on the evaluation data. If <code>eval_strategy="epoch"</code>, the model will be evaluated every epoch. See the documentation for more options. <strong>Note:</strong> This was previously called <code>evaluation_strategy</code> but was shortened in <code>transformers==4.46</code>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>save_strategy</code></td>
<td style="text-align: left;">When to save a model checkpoint. If <code>save_strategy="epoch"</code>, a checkpoint will be saved every epoch. See the documentation for more save options.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>save_total_limit</code></td>
<td style="text-align: left;">Number of total amount of checkpoints to save (so we don’t save <code>num_train_epochs</code> checkpoints). For example, can limit to 3 saves so the total number of saves are the 3 most recent as well as the best performing checkpoint (as per <code>load_best_model_at_end</code>).</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>use_cpu</code></td>
<td style="text-align: left;">Set to <code>False</code> by default, will use CUDA GPU (<code>torch.device("cuda")</code>) or MPS device (<code>torch.device("mps")</code>, for Mac) if available. This is because training is generally faster on an accelerator device.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>seed</code></td>
<td style="text-align: left;">Set to <code>42</code> by default for reproducibility. Meaning that subsequent runs with the same setup should achieve the same results.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>load_best_model_at_end</code></td>
<td style="text-align: left;">When set to <code>True</code>, makes sure that the best model found during training is loaded when training finishes. This will mean the best model checkpoint gets saved regardless of what epoch it happened on. This is set to <code>False</code> by default.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>logging_strategy</code></td>
<td style="text-align: left;">When to log the training results and metrics. For example, if <code>logging_strategy="epoch"</code>, results will be logged as outputs every epoch. See the documentation for more logging options.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>report_to</code></td>
<td style="text-align: left;">Log experiments to various experiment tracking services. For example, you can log to Weights &amp; Biases using <code>report_to="wandb"</code>. We’ll turn this off for now and keep logging to a local directory by setting <code>report_to="none"</code>.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>push_to_hub</code></td>
<td style="text-align: left;">Automatically upload the model to the Hugging Face Hub every time the model is saved. We’ll set <code>push_to_hub=False</code> as we’ll see how to do this manually later on. See the documentation for more options on saving models to the Hugging Face Hub.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>hub_token</code></td>
<td style="text-align: left;">Add your Hugging Face Hub token to push a model to the Hugging Face Hub with <code>push_to_hub</code> (will default to <a href="https://huggingface.co/docs/huggingface_hub/en/guides/cli"><code>huggingface-cli login</code></a> details).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>hub_private_repo</code></td>
<td style="text-align: left;">Whether or not to make the Hugging Face Hub repository private or public, defaults to <code>False</code> (e.g.&nbsp;set to <code>True</code> if you want the repository to be private).</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>To get more familiar with the <code>transformers.TrainingArguments</code> class, I’d highly recommend <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments">reading the documentation</a> for 15-20 minutes. Perhaps over a couple of sessions. There are quite a large number of parameters which will be helpful to be aware of.</p>
</div>
</div>
<p>Phew!</p>
<p>That was a lot to take in.</p>
<p>But let’s now practice setting up our own instance of <code>transformers.TrainingArguments</code>.</p>
<div id="cell-100" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Saving model checkpoints to: </span><span class="sc">{</span>model_save_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training arguments</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>model_save_dir,</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.0001</span>,</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>    eval_strategy<span class="op">=</span><span class="st">"epoch"</span>, <span class="co"># was previously "evaluation_strategy"</span></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>    save_total_limit<span class="op">=</span><span class="dv">3</span>, <span class="co"># limit the total amount of save checkpoints (so we don't save num_epochs checkpoints)</span></span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>    use_cpu<span class="op">=</span><span class="va">False</span>, <span class="co"># set to False by default, will use CUDA GPU or MPS device if available</span></span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>, <span class="co"># set to 42 by default for reproducibility</span></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>, <span class="co"># load the best model when finished training</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span><span class="st">"epoch"</span>, <span class="co"># log training results every epoch</span></span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>, <span class="co"># optional: log experiments to Weights &amp; Biases/other similar experimenting tracking services (we'll turn this off for now) </span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># push_to_hub=True # optional: automatically upload the model to the Hub (we'll do this manually later on)</span></span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># hub_token="your_token_here" # optional: add your Hugging Face Hub token to push to the Hub (will default to huggingface-cli login)</span></span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a>    hub_private_repo<span class="op">=</span><span class="va">False</span> <span class="co"># optional: make the uploaded model private (defaults to False)</span></span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: Print out training_args to inspect (warning, it is quite a long output)</span></span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a><span class="co"># training_args</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Saving model checkpoints to: models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code></pre>
</div>
</div>
<p>Training arguments created!</p>
<p>Let’s put them to work in an instance of <code>transformers.Trainer</code>.</p>
</section>
<section id="setting-up-an-instance-of-trainer" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="setting-up-an-instance-of-trainer"><span class="header-section-number">6.4</span> Setting up an instance of Trainer</h3>
<p>Time for step 4!</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>✅ Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>✅ Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<p>The <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer"><code>transformers.Trainer</code></a> class allows you to train models.</p>
<p>It’s built on PyTorch so it gets to leverage all of the powerful PyTorch toolkit.</p>
<p>But since it also works closely with the <code>transformers.TrainingArguments</code> class, it offers many helpful features.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>transformers.Trainer</code> can work with <code>torch.nn.Module</code> models, however, it is designed to work best with <a href="https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel"><code>transformers.PreTrainedModel</code></a>’s from the <code>transformers</code> library.</p>
<p>This is not a problem for us as we’re using <code>transformers.AutoModelForSequenceClassification.from_pretrained</code> which loads a <code>transformers.PreTrainedModel</code>.</p>
<p>See the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer"><code>transformers.Trainer</code> documentation</a> for tips on how to make sure your model is compatible.</p>
</div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>model</code></td>
<td style="text-align: left;">The model we’d like to train. Works best with an instance of <code>transformers.PreTrainedModel</code>. Most models loaded using <code>from_pretrained</code> will be of this type.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>args</code></td>
<td style="text-align: left;">Instance of <code>transformers.TrainingArguments</code>. We’ll use the <code>training_args</code> object we defined earlier. But if this is not set, it will default to the default settings for <code>transformers.TrainingArguments</code>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>train_dataset</code></td>
<td style="text-align: left;">Dataset to use during training. We can use our <code>tokenized_dataset["train"]</code> as it has already been preprocessed.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>eval_dataset</code></td>
<td style="text-align: left;">Dataset to use during evaluation (our model will not see this data during training). We can use our <code>tokenized_dataset["test"]</code> as it has already been preprocessed.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>tokenizer</code></td>
<td style="text-align: left;">The <code>tokenizer</code> which was used to preprocess the data. Passing a tokenizer will also pad the inputs to maximum length when batching them. It will also be saved with the model so future re-runs are easier.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>compute_metrics</code></td>
<td style="text-align: left;">An evaluation function to evaluate a model during training and evaluation steps. In our case, we’ll use the <code>compute_accuracy</code> function we defined earlier.</td>
</tr>
</tbody>
</table>
<p>With all this being said, let’s build our <code>Trainer</code>!</p>
<div id="cell-103" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Trainer</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Trainer</span></span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"train"</span>],</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"test"</span>],</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer, <span class="co"># Pass tokenizer to the Trainer for dynamic padding (padding as the training happens) (see "data_collator" in the Trainer docs)</span></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_accuracy</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Woohoo! We’ve created our own <code>trainer</code>.</p>
<p>We’re one step closer to training!</p>
</section>
<section id="training-our-text-classification-model" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="training-our-text-classification-model"><span class="header-section-number">6.5</span> Training our text classification model</h3>
<p>We’ve done most of the hard word setting up our <code>transformers.TrainingArguments</code> as well as our <code>transformers.Trainer</code>.</p>
<p>Now how about we train a model?</p>
<p>Following our steps:</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>✅ Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>✅ Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>✅ Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<p>Looks like all we have to do is call <code>transformers.Trainer.train()</code>.</p>
<p>We’ll be sure to save the results of the training to a variable <code>results</code> so we can inspect them later.</p>
<p>Let’s try!</p>
<div id="cell-106" class="cell" data-outputid="22937d9f-a794-4579-bc67-70ba6cb05dcd" data-execution_count="46">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a text classification model</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="70" max="70" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [70/70 00:06, Epoch 10/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.327000</td>
<td>0.034850</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.018300</td>
<td>0.004165</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.003300</td>
<td>0.001551</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.001500</td>
<td>0.000902</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.000900</td>
<td>0.000657</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.000800</td>
<td>0.000544</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.000600</td>
<td>0.000483</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.000600</td>
<td>0.000450</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>9</td>
<td>0.000600</td>
<td>0.000432</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.000600</td>
<td>0.000426</td>
<td>1.000000</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
<p>Woahhhh!!!</p>
<p>How cool is that!</p>
<p>We just trained a text classification model!</p>
<p>And it looks like the training went pretty quick (thanks to our smaller dataset and relatively small model, for larger datasets, training would likely take longer).</p>
<p>How about we check some of the metrics?</p>
<p>We can do so using the <code>results.metrics</code> attribute (this returns a Python dictionary with stats from our training run).</p>
<div id="cell-108" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect training metrics</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, value <span class="kw">in</span> results.metrics.items():</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>train_runtime: 6.9675
train_samples_per_second: 287.048
train_steps_per_second: 10.047
total_flos: 18110777160000.0
train_loss: 0.03540716338570097
epoch: 10.0</code></pre>
</div>
</div>
<p>Nice!</p>
<p>Looks like our overall training runtime is low because of our small dataset.</p>
<p>And looks like our <code>trainer</code> was able to process a fair few samples per second.</p>
<p>If we were to 1000x the size of our dataset (e.g.&nbsp;~250 samples -&gt; ~250,000 samples which is quite a substantial dataset), it seems our training time still wouldn’t take too long.</p>
<p>The <code>total_flos</code> stands for “<a href="https://en.wikipedia.org/wiki/FLOPS">floating point operations</a>” (also referred to as FLOPS), this is the total number of calculations our model has performed to find patterns in the data. And as you can see, it’s quite a large number!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Depending on the hardware you’re using, the results with respect to <code>train_runtime</code>, <code>train_samples_per_second</code> and <code>train_steps_per_second</code> will likely be different.</p>
<p>The faster your accelerator hardware (e.g.&nbsp;NVIDIA GPU or Mac GPU), the lower your runtime and higher your samples/steps per second will be.</p>
<p>For reference, on my local NVIDIA RTX 4090, I get a <code>train_runtime</code> of 8-9 seconds, <code>train_samples_per_second</code> of 230-250 and <code>train_steps_per_second</code> of 8.565.</p>
</div>
</div>
</section>
<section id="save-the-model-for-later-use" class="level3" data-number="6.6">
<h3 data-number="6.6" class="anchored" data-anchor-id="save-the-model-for-later-use"><span class="header-section-number">6.6</span> Save the model for later use</h3>
<p>Now our model has been trained, let’s save it for later use.</p>
<p>We’ll save it locally first and push it to the Hugging Face Hub later.</p>
<p>We can save our model using the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.save_model"><code>transformers.Trainer.save_model</code></a> method.</p>
<div id="cell-111" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Saving model to </span><span class="sc">{</span>model_save_dir<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>trainer.save_model(output_dir<span class="op">=</span>model_save_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Saving model to models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code></pre>
</div>
</div>
<p>Model saved locally! Before we save it to the Hugging Face Hub, let’s check out its metrics.</p>
</section>
<section id="inspecting-the-model-training-metrics" class="level3" data-number="6.7">
<h3 data-number="6.7" class="anchored" data-anchor-id="inspecting-the-model-training-metrics"><span class="header-section-number">6.7</span> Inspecting the model training metrics</h3>
<p>We can get a log of our model’s training state using <code>trainer.state.log_history</code>.</p>
<p>This will give us a collection of metrics per epoch (as long as we set <code>logging_strategy="epoch"</code> in <code>transformers.TrainingArguments</code>), in particular, it will give us a loss value per epoch.</p>
<p>We can extract these values and inspect them visually for a better understanding our model training.</p>
<p>Let’s get the training history and inspect it.</p>
<div id="cell-114" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get training history </span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>trainer_history_all <span class="op">=</span> trainer.state.log_history </span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>trainer_history_metrics <span class="op">=</span> trainer_history_all[:<span class="op">-</span><span class="dv">1</span>] <span class="co"># get everything except the training time metrics (we've seen these already)</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>trainer_history_training_time <span class="op">=</span> trainer_history_all[<span class="op">-</span><span class="dv">1</span>] <span class="co"># this is the same value as results.metrics from above</span></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="co"># View the first 4 metrics from the training history</span></span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>trainer_history_metrics[:<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>[{'loss': 0.327,
  'grad_norm': 1.2806360721588135,
  'learning_rate': 9e-05,
  'epoch': 1.0,
  'step': 7},
 {'eval_loss': 0.03485037386417389,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0128,
  'eval_samples_per_second': 3911.429,
  'eval_steps_per_second': 156.457,
  'epoch': 1.0,
  'step': 7},
 {'loss': 0.0183,
  'grad_norm': 0.08053876459598541,
  'learning_rate': 8e-05,
  'epoch': 2.0,
  'step': 14},
 {'eval_loss': 0.004165211692452431,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0127,
  'eval_samples_per_second': 3927.839,
  'eval_steps_per_second': 157.114,
  'epoch': 2.0,
  'step': 14}]</code></pre>
</div>
</div>
<p>Okay, looks like the metrics are logged every epochs in a list Python dictionaries with interleaving <code>loss</code> (this is the training set loss) and <code>eval_loss</code> values.</p>
<p>How about we write some code to separate the training set metrics and the evaluation set metrics?</p>
<div id="cell-116" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pprint <span class="co"># import pretty print for nice printing of lists</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract training and evaluation metrics</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>trainer_history_training_set <span class="op">=</span> []</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_set <span class="op">=</span> []</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through metrics and filter for training and eval metrics</span></span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> trainer_history_metrics:</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>    item_keys <span class="op">=</span> <span class="bu">list</span>(item.keys())</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check to see if "eval" is in the keys of the item</span></span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"eval"</span> <span class="kw">in</span> item <span class="cf">for</span> item <span class="kw">in</span> item_keys):</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>        trainer_history_eval_set.append(item)</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>        trainer_history_training_set.append(item)</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the first two items in each metric set</span></span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] First two items in training set:"</span>)</span>
<span id="cb89-18"><a href="#cb89-18" aria-hidden="true" tabindex="-1"></a>pprint.pprint(trainer_history_training_set[:<span class="dv">2</span>])</span>
<span id="cb89-19"><a href="#cb89-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-20"><a href="#cb89-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[INFO] First two items in evaluation set:"</span>)</span>
<span id="cb89-21"><a href="#cb89-21" aria-hidden="true" tabindex="-1"></a>pprint.pprint(trainer_history_eval_set[:<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] First two items in training set:
[{'epoch': 1.0,
  'grad_norm': 1.2806360721588135,
  'learning_rate': 9e-05,
  'loss': 0.327,
  'step': 7},
 {'epoch': 2.0,
  'grad_norm': 0.08053876459598541,
  'learning_rate': 8e-05,
  'loss': 0.0183,
  'step': 14}]

[INFO] First two items in evaluation set:
[{'epoch': 1.0,
  'eval_accuracy': 1.0,
  'eval_loss': 0.03485037386417389,
  'eval_runtime': 0.0128,
  'eval_samples_per_second': 3911.429,
  'eval_steps_per_second': 156.457,
  'step': 7},
 {'epoch': 2.0,
  'eval_accuracy': 1.0,
  'eval_loss': 0.004165211692452431,
  'eval_runtime': 0.0127,
  'eval_samples_per_second': 3927.839,
  'eval_steps_per_second': 157.114,
  'step': 14}]</code></pre>
</div>
</div>
<p>Beautiful!</p>
<p>How about we take it a step further and turn our metrics into pandas DataFrames so we can view them easier?</p>
<div id="cell-118" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create pandas DataFrames for the training and evaluation metrics</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df <span class="op">=</span> pd.DataFrame(trainer_history_training_set)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df <span class="op">=</span> pd.DataFrame(trainer_history_eval_set)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df.head() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">grad_norm</th>
<th data-quarto-table-cell-role="th">learning_rate</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.3270</td>
<td>1.280636</td>
<td>0.00009</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0183</td>
<td>0.080539</td>
<td>0.00008</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.0033</td>
<td>0.034253</td>
<td>0.00007</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.0015</td>
<td>0.019484</td>
<td>0.00006</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0009</td>
<td>0.016791</td>
<td>0.00005</td>
<td>5.0</td>
<td>35</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Nice!</p>
<p>And the evaluation DataFrame?</p>
<div id="cell-120" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">eval_loss</th>
<th data-quarto-table-cell-role="th">eval_accuracy</th>
<th data-quarto-table-cell-role="th">eval_runtime</th>
<th data-quarto-table-cell-role="th">eval_samples_per_second</th>
<th data-quarto-table-cell-role="th">eval_steps_per_second</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.034850</td>
<td>1.0</td>
<td>0.0128</td>
<td>3911.429</td>
<td>156.457</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.004165</td>
<td>1.0</td>
<td>0.0127</td>
<td>3927.839</td>
<td>157.114</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.001551</td>
<td>1.0</td>
<td>0.0118</td>
<td>4226.340</td>
<td>169.054</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.000902</td>
<td>1.0</td>
<td>0.0120</td>
<td>4170.283</td>
<td>166.811</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.000657</td>
<td>1.0</td>
<td>0.0120</td>
<td>4183.594</td>
<td>167.344</td>
<td>5.0</td>
<td>35</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>And of course, we’ll have follow the data explorer’s motto of <em>visualize, visualize, visualize!</em> and inspect our loss curves.</p>
<div id="cell-122" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training and evaluation loss</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_training_df[<span class="st">"epoch"</span>], trainer_history_training_df[<span class="st">"loss"</span>], label<span class="op">=</span><span class="st">"Training loss"</span>)</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_eval_df[<span class="st">"epoch"</span>], trainer_history_eval_df[<span class="st">"eval_loss"</span>], label<span class="op">=</span><span class="st">"Evaluation loss"</span>)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Text classification with DistilBert training and evaluation loss over time"</span>)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hugging_face_text_classification_tutorial_files/figure-html/cell-54-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>B-e-a-utiful!</p>
<p>That is exactly what we wanted.</p>
<p>Training and evaluation loss going down over time.</p>
</section>
<section id="pushing-our-model-to-the-hugging-face-hub" class="level3" data-number="6.8">
<h3 data-number="6.8" class="anchored" data-anchor-id="pushing-our-model-to-the-hugging-face-hub"><span class="header-section-number">6.8</span> Pushing our model to the Hugging Face Hub</h3>
<p>We’ve saved our model locally and confirmed that it seems to be performing well on our training metrics but how about we push it to the Hugging Face Hub?</p>
<p>The Hugging Face Hub is one of the best sources of machine learning models on the internet.</p>
<p>And we can add our model there so others can use it or we can access it in the future (we could also keep it private on the Hugging Face Hub so only people from our organization can use it).</p>
<p>Sharing models on Hugging Face is also a great way to showcase your skills as a machine learning engineer, it gives you something to show potential employers and say “here’s what I’ve done”.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before sharing a model to the Hugging Face Hub, be sure to go through the following steps:</p>
<ol type="1">
<li>Setup a Hugging Face token using the <a href="https://huggingface.co/docs/huggingface_hub/en/guides/cli"><code>huggingface-cli login</code> command</a>.</li>
<li>Read through the <a href="https://huggingface.co/docs/hub/en/security-tokens">user access tokens guide</a>.</li>
<li>Set up an access token via <a href="https://huggingface.co/settings/tokens">https://huggingface.co/settings/tokens</a> (ensure it has “write” access).</li>
</ol>
<p>If you are using Google Colab, you can add your token under the “Secrets” tab on the left.</p>
<p>On my local computer, my token is saved to <code>/home/daniel/.cache/huggingface/token</code> (thanks to running <code>huggingface-cli login</code> on the command line).</p>
<p>And for more on sharing models to the Hugging Face Hub, be sure to check out the <a href="https://huggingface.co/docs/transformers/en/model_sharing">model sharing documentation</a>.</p>
</div>
</div>
<p>We can push our model, tokenizer and other assosciated files to the Hugging Face Hub using the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.push_to_hub"><code>transformers.Trainer.push_to_hub</code></a> method.</p>
<p>We can also optionally do the following:</p>
<ul>
<li>Add a <a href="https://huggingface.co/docs/hub/en/model-cards">model card</a> (something that describes how the model was created and what it can be used for) using <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.create_model_card"><code>transformers.Trainer.create_model_card</code></a>.</li>
<li>Add a custom <code>README.md</code> file to the model repository to explain more details about the model using <a href="https://huggingface.co/docs/huggingface_hub/en/guides/upload#upload-a-file"><code>huggingface_hub.HfApi.upload_file</code></a>. This method is similar to model card creation method above but with more customization.</li>
</ul>
<p>Let’s save our model to the Hub!</p>
<div id="cell-125" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save our model to the Hugging Face Hub</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This will be public, since we set hub_private_repo=False in our TrainingArguments</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>trainer.push_to_hub(</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier model"</span>,</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token="YOUR_HF_TOKEN_HERE" # This will default to the token you have saved in your Hugging Face config</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dfceb67b75e844d7bd1fc032dbb18356","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ef6844710ab64eda9207d1651cbcc6d1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a2d7f66df68540698951e95b8360d3f9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>CommitInfo(commit_url='https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/commit/90630c6063d2498e794ba6c982f1688ee3bcf969', commit_message='Uploading food not food text classifier model', commit_description='', oid='90630c6063d2498e794ba6c982f1688ee3bcf969', pr_url=None, pr_revision=None, pr_num=None)</code></pre>
</div>
</div>
<p>Model pushed to the Hugging Face Hub!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may see the following error:</p>
<blockquote class="blockquote">
<p>403 Forbidden: You don’t have the rights to create a model under the namespace “mrdbourke”. Cannot access content at: https://huggingface.co/api/repos/create. If you are trying to create or update content, make sure you have a token with the <code>write</code> role.</p>
</blockquote>
<p>Or even:</p>
<blockquote class="blockquote">
<p>HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-6699c52XXXXXX)</p>
<p>Invalid username or password.</p>
</blockquote>
<p>In this case, be sure to go through the <a href="https://huggingface.co/docs/hub/en/security-tokens">setup steps above</a> to make sure you have a Hugging Face access token with “write” access.</p>
</div>
</div>
<p>And since it’s public (by default), you can see it at <a href="https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased">https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</a> (it gets saved to the same name as our target local directory).</p>
<p>You can now share and interact with this model online.</p>
<p>As well as download it for use in your own applications.</p>
<ul>
<li>TK image - model on Hugging Face Hub ready to use/example of using the model already in the Hugging Face models page</li>
</ul>
<p>But before we make an application with it, let’s keep evaluating it.</p>
</section>
</section>
<section id="making-and-evaluating-predictions-on-the-test-data" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="making-and-evaluating-predictions-on-the-test-data"><span class="header-section-number">7</span> Making and evaluating predictions on the test data</h2>
<p>Model trained, let’s now evaluate it on the test data.</p>
<p>Or step 7 in our workflow:</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>✅ Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>✅ Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>✅ Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>✅ Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>✅ Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<p>A reminder that the test data is data that our model has never seen before.</p>
<p>So it will be a good estimate of how our model will do in a production setting.</p>
<p>We can make predictions on the test dataset using <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.predict"><code>transformers.Trainer.predict</code></a>.</p>
<p>And then we can get the prediction values with the <code>predictions</code> attribute and assosciated metrics with the <code>metrics</code> attribute.</p>
<div id="cell-128" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform predictions on the test set</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>predictions_all <span class="op">=</span> trainer.predict(tokenized_dataset[<span class="st">"test"</span>])</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>prediction_values <span class="op">=</span> predictions_all.predictions</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>prediction_metrics <span class="op">=</span> predictions_all.metrics</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Prediction metrics on the test data:"</span>)</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>prediction_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Prediction metrics on the test data:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>{'test_loss': 0.00042641552863642573,
 'test_accuracy': 1.0,
 'test_runtime': 0.0423,
 'test_samples_per_second': 1181.814,
 'test_steps_per_second': 47.273}</code></pre>
</div>
</div>
<p>Woah!</p>
<p>Looks like our model did an outstanding job!</p>
<p>And it was <em>very</em> quick too.</p>
<p>This is one of the benefits of using a smaller pretrained model and customizing it to your own dataset.</p>
<p>You can achieve outstanding results in a very quick time as well as have a model capable of performing thousands of predictions per second.</p>
<p>We can also calculate the accuracy by hand by comparing the prediction labels to the test labels.</p>
<p>To do so, we’ll:</p>
<ol type="1">
<li>Calculate the prediction probabilities (though this is optional as we could skip straight to 2 and get the same results) by passing the <code>prediction_values</code> to <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html"><code>torch.softmax</code></a>.</li>
<li>Find the index of the prediction value with the highest value (the index will be equivalent to the predicted label) using <a href="https://pytorch.org/docs/stable/generated/torch.argmax.html"><code>torch.argmax</code></a> (we could also use <a href="https://numpy.org/doc/stable/reference/generated/numpy.argmax.html"><code>np.argmax</code></a> here) to find the predicted labels.</li>
<li>Get the true labels from the test dataset using <code>dataset["test"]["label"]</code>.</li>
<li>Compare the predicted labels from 2 to the true labels from 3 using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"><code>sklearn.metrics.accuracy_score</code></a> to find the accuracy.</li>
</ol>
<div id="cell-130" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Get prediction probabilities (this is optional, could get the same results with step 2 onwards)</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> torch.softmax(torch.tensor(prediction_values), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Get the predicted labels</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>pred_labels <span class="op">=</span> torch.argmax(pred_probs, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Get the true labels</span></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> dataset[<span class="st">"test"</span>][<span class="st">"label"</span>]</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Compare predicted labels to true labels to get the test accuracy</span></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_true<span class="op">=</span>true_labels, </span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a>                               y_pred<span class="op">=</span>pred_labels)</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Test accuracy: </span><span class="sc">{</span>test_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Test accuracy: 100.0%</code></pre>
</div>
</div>
<p>Woah!</p>
<p>Looks like our model performs really well on our test set.</p>
<p>It will be interesting to see how it goes on real world samples.</p>
<p>We’ll test this later on.</p>
<p>How about we make a pandas DataFrame out of our test samples, predicted labels and predicted probabilities to further inspect our results?</p>
<div id="cell-132" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a DataFrame of test predictions</span></span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>test_predictions_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: dataset[<span class="st">"test"</span>][<span class="st">"text"</span>],</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"true_label"</span>: true_labels,</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_label"</span>: pred_labels,</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_prob"</span>: torch.<span class="bu">max</span>(pred_probs, dim<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>test_predictions_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A slice of pepperoni pizza with a layer of mel...</td>
<td>1</td>
<td>1</td>
<td>0.999552</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Red brick fireplace with a mantel serving as a...</td>
<td>0</td>
<td>0</td>
<td>0.999589</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A bowl of sliced bell peppers with a sprinkle ...</td>
<td>1</td>
<td>1</td>
<td>0.999555</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Set of mugs hanging on a hook</td>
<td>0</td>
<td>0</td>
<td>0.999628</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Standing floor lamp providing light next to an...</td>
<td>0</td>
<td>0</td>
<td>0.999625</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We can find the examples with the lowest prediction probability to see where the model is unsure.</p>
<div id="cell-134" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show 10 examples with low prediction probability</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>test_predictions_df.sort_values(<span class="st">"pred_prob"</span>, ascending<span class="op">=</span><span class="va">True</span>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>A bowl of cherries with a sprig of mint for ga...</td>
<td>1</td>
<td>1</td>
<td>0.999523</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>A close-up shot of a cheesy pizza slice being ...</td>
<td>1</td>
<td>1</td>
<td>0.999540</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>Two handfuls of bananas in a fruit bowl with g...</td>
<td>1</td>
<td>1</td>
<td>0.999545</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">26</td>
<td>A fruit platter with a variety of exotic fruit...</td>
<td>1</td>
<td>1</td>
<td>0.999549</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">43</td>
<td>Set of muffin tins stacked together</td>
<td>0</td>
<td>0</td>
<td>0.999549</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">42</td>
<td>Boxes of apples, pears, pineapple, manadrins a...</td>
<td>1</td>
<td>1</td>
<td>0.999551</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>Pizza with a seafood theme, featuring toppings...</td>
<td>1</td>
<td>1</td>
<td>0.999552</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">18</td>
<td>Traditional Japanese flavored sushi roll with ...</td>
<td>1</td>
<td>1</td>
<td>0.999552</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A slice of pepperoni pizza with a layer of mel...</td>
<td>1</td>
<td>1</td>
<td>0.999552</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">41</td>
<td>Sushi with a spicy kick, featuring jalapeno pe...</td>
<td>1</td>
<td>1</td>
<td>0.999553</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Hmmm, it looks like our model has quite a high prediction probability for almost all samples.</p>
<p>We can further evalaute our model by making predictions on new custom data.</p>
</section>
<section id="making-and-inspecting-predictions-on-custom-text-data" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="making-and-inspecting-predictions-on-custom-text-data"><span class="header-section-number">8</span> Making and inspecting predictions on custom text data</h2>
<p>We’ve seen how our model performs on the test dataset (quite well).</p>
<p>But how might we check its performance on our own custom data?</p>
<p>For example, text-based image captions from the wild.</p>
<p>Well, we’ve got two ways to load our model now too:</p>
<ol type="1">
<li>Load model locally from our computer (e.g.&nbsp;via <code>models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code>).</li>
<li>Load model from Hugging Face Hub (e.g.&nbsp;via <code>mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code>).</li>
</ol>
<p>Either way of loading the model results in the same outcome: being able to make predictions on given data.</p>
<p>So how about we start by setting up our model paths for both local loading and loading from the Hugging Face Hub.</p>
<div id="cell-137" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup local model path</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>local_model_path <span class="op">=</span> <span class="st">"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Hugging Face model path (see: https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased)</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>huggingface_model_path <span class="op">=</span> <span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="discussing-ways-to-make-predictions-inference" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="discussing-ways-to-make-predictions-inference"><span class="header-section-number">8.1</span> Discussing ways to make predictions (inference)</h3>
<p>When we’ve loaded our trained model, because of the way we’ve set it up, there are two main ways to make predictions on custom data:</p>
<ol type="1">
<li><strong>Pipeline mode</strong> using <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#pipelines"><code>transformers.pipeline</code></a> and passing it our target model, this allows us to preprocess custom data and make predictions in one step.</li>
<li><strong>PyTorch mode</strong> using a combination of <a href="https://huggingface.co/docs/transformers/v4.42.0/en/model_doc/auto#transformers.AutoTokenizer"><code>transformers.AutoTokenizer</code></a> and <a href="https://huggingface.co/docs/transformers/v4.42.0/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> and passing each our target model, this requires us to preprocess our data before passing to a model, however, it offers the most customization.</li>
</ol>
<p>Each method supports:</p>
<ol type="1">
<li>Predictions one at a time (batch size of 1), for example, one person using the app at a time.</li>
<li>Batches of predictions at a time (predictions with a batch size of <code>n</code> where <code>n</code> can be any number, e.g.&nbsp;<code>8</code>, <code>16</code>, <code>32</code>), for example, many people using a service simultaneously such as a voice chat and needing to filter comments (predicting on batches of size <code>n</code> is usually much faster than batches of 1).</li>
</ol>
<p>Whichever method we choose, we’ll have to set the target device we’d like the operations to happen on.</p>
<p>In general, it’s best to make predictions on the most powerful accelerator you have available.</p>
<p>And in most cases that will be a NVIDIA GPU &gt; Mac GPU &gt; CPU.</p>
<p>So let’s write a small function to pick the target device for us in that order.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Making predictions is also referred to as <strong>inference</strong>.</p>
<p>Because the model is going to <em>infer</em> on some data what the output should be.</p>
<p>Inference is often faster than training on a per sample basis as no model weights are updated (less computation).</p>
<p>However, inference can use more compute than training over the long run because you could train a model once over a few hours (or days or longer) and then use it for inference for several months (or longer), millions of times (or more).</p>
</div>
</div>
<div id="cell-139" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_device():</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Set device to CUDA if available, else MPS (Mac), else CPU.</span></span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This defaults to using the best available device (usually).</span></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> torch.backends.mps.is_available() <span class="kw">and</span> torch.backends.mps.is_built():</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> device</span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a>DEVICE <span class="op">=</span> set_device()</span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Using device: </span><span class="sc">{</span>DEVICE<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Using device: cuda</code></pre>
</div>
</div>
<p>Target device set!</p>
<p>Let’s start predicting.</p>
</section>
<section id="making-predictions-with-pipeline" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="making-predictions-with-pipeline"><span class="header-section-number">8.2</span> Making predictions with pipeline</h3>
<p>The <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.pipeline"><code>transformers.pipeline</code></a> method creates a machine learning pipeline.</p>
<p>Data goes in one end and predictions come out the other end.</p>
<p>You can create pipelines for many different tasks, such as, text classification, image classification, object detection, text generation and more.</p>
<p>Let’s see how we can create a pipeline for our text classification model.</p>
<p>To do so we’ll:</p>
<ol type="1">
<li>Instantiate an instance of <code>transformers.pipeline</code>.</li>
<li>Pass in the <code>task</code> parameter of <code>text-classification</code> (we can do this because our model is already formatted for text classification thanks to using <code>transformers.AutoModelForSequenceClassification</code>).</li>
<li>Setup the <code>model</code> parameter to be <code>local_model_path</code> (though we could also use <code>huggingface_model_path</code>).</li>
<li>Set the target device using the <code>device</code> parameter.</li>
<li>Set <code>top_k=1</code> to get to the top prediction back (e.g.&nbsp;either <code>"food"</code> or <code>"not_food"</code>, could set this higher to get more labels back).</li>
<li>Set the <code>BATCH_SIZE=32</code> so we can pass to the <code>batch_size</code> parameter. This will allow our model to make predictions on up to <code>32</code> samples at a time. Predicting on batches of data is usually much faster than single samples at a time, however, this often saturates at a point (e.g.&nbsp;predicting on batches of size 64 may be the same speed as 32 due to memory contraints).</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are many more pipelines available in the <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.pipeline">Hugging Face documentation</a>.</p>
<p>As an exericse, I’d spend 10-15 minutes reading through the pipeline documentation to get familiar with what’s available.</p>
</div>
</div>
<p>Let’s setup our pipeline!</p>
<div id="cell-142" class="cell" data-outputid="fb71c373-8dc5-42c3-9749-c58ab59253c3" data-execution_count="61">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the batch size for predictions</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of transformers.pipeline</span></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, <span class="co"># we can use this because our model is an instance of AutoModelForSequenceClassification</span></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>                                    model<span class="op">=</span>local_model_path, <span class="co"># could also pass in huggingface_model_path</span></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>                                    device<span class="op">=</span>DEVICE, <span class="co"># set the target device</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>                                    top_k<span class="op">=</span><span class="dv">1</span>, <span class="co"># only return the top predicted value</span></span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>                                    batch_size<span class="op">=</span>BATCH_SIZE) <span class="co"># perform predictions on up to BATCH_SIZE number of samples at a time </span></span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>&lt;transformers.pipelines.text_classification.TextClassificationPipeline at 0x7f33da4ed3d0&gt;</code></pre>
</div>
</div>
<p>We’ve created an instance of <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TextClassificationPipeline"><code>transformers.pipelines.text_classification.TextClassificationPipeline</code></a>!</p>
<p>Now let’s test it out by passing it a string of text about food.</p>
<div id="cell-144" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test our trained model on some example text </span></span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>sample_text_food <span class="op">=</span> <span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast"</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>[[{'label': 'food', 'score': 0.9995404481887817}]]</code></pre>
</div>
</div>
<p>Nice! Our model gets it right.</p>
<p>How about a string <em>not</em> about food?</p>
<div id="cell-146" class="cell" data-outputid="7d9f1336-883e-474a-cc9a-aa605ba2afc1" data-execution_count="70">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model on some more example text</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>sample_text_not_food <span class="op">=</span> <span class="st">"A yellow tractor driving over the hill"</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_not_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>[[{'label': 'not_food', 'score': 0.9995775818824768}]]</code></pre>
</div>
</div>
<p>Woohoo!</p>
<p>Correct again!</p>
<p>What if we passed in random text?</p>
<p>As in, someone types in something random to the model expecting an output.</p>
<div id="cell-148" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass in random text to the model</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"cvnhertiejhwgdjshdfgh394587"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>[[{'label': 'not_food', 'score': 0.9935680031776428}]]</code></pre>
</div>
</div>
<p>The nature of machine learning models is that they are a predictive/generative function.</p>
<p>If you input data, they will output something.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>When deploying machine learning models, there are many things to take into consideration.</p>
<p>One of the main ones being: “what data is going to go into the model?”</p>
<p>If this was a public facing model and people could enter any kind of text, they could enter random text rather than a sentence about food or not food.</p>
<p>Since our main goal of the model is be able to classify image captions into <code>food</code>/<code>not_food</code>, we’d also have to consider image cpations that are poorly written or contain little text.</p>
<p>This is why it’s important to continually test your models with as much example test/real-world data as you can.</p>
</div>
</div>
<p>Our <code>pipeline</code> can also work with the model we saved to the Hugging Face Hub.</p>
<p>Let’s try out the same pipeline with <code>model=hugggingface_model_path</code>.</p>
<div id="cell-150" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline also works with remote models (will have to laod the model locally first)</span></span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>                                           model<span class="op">=</span>huggingface_model_path, <span class="co"># load the model from Hugging Face Hub (will download the model if it doesn't already exist)</span></span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>                                           batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a>                                           device<span class="op">=</span>DEVICE)</span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote(<span class="st">"This is some new text about bananas and pancakes and ice cream"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e11404f516a4161bd81599ce45c781e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"14c9d71551f84b97bf68255c0a28c8b2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f242e4e4d5424325a82068a82206f0c7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>[{'label': 'food', 'score': 0.9995065927505493}]</code></pre>
</div>
</div>
<p>Beautiful!</p>
<p>Our model loaded from Hugging Face gets it right too!</p>
</section>
<section id="making-multiple-predictions-at-the-same-time-with-batch-prediction" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="making-multiple-predictions-at-the-same-time-with-batch-prediction"><span class="header-section-number">8.3</span> Making multiple predictions at the same time with batch prediction</h3>
<p>We can make predictions with our model one at a time but it’s often much faster to do them in batches.</p>
<p>To make predictions in batches, we can set up our <code>transformers.pipeline</code> instance with the <code>batch_size</code> parameter greater than <code>1</code>.</p>
<p>Then we’ll be able to pass multiple samples at once in the form of a Python list.</p>
<div id="cell-153" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create batch size (we don't need to do this again but we're doing it for clarity)</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span> <span class="co"># this number is experimental and will require testing on your hardware to find the optimal value (e.g. lower if there are memory issues or higher to try speed up inference)</span></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup pipeline to handle batches (we don't need to do this again either but we're doing it for clarity)</span></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>                                    model<span class="op">=</span>local_model_path,</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>                                    batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>                                    device<span class="op">=</span>DEVICE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wonderful, now we’ve set up a <code>pipeline</code> instance capable of handling batches, we can pass it a list of samples and it will make predictions on each.</p>
<p>How about we try with a collection of sentences which are a bit tricky?</p>
<div id="cell-155" class="cell" data-outputid="3a50b522-c155-49fd-8c0e-27541486bca4" data-execution_count="74">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of sentences to make predictions on</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>,</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"We need to marinate these ideas overnight before presenting them to the client."</span>,</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The new software is definitely a spicy upgrade, taking some time to get used to."</span>,</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Her social media post was the perfect recipe for a viral sensation."</span>,</span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"He served up a rebuttal full of facts, leaving his opponent speechless."</span>,</span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The team needs to simmer down a bit before tackling the next challenge."</span>,</span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The presentation was a delicious blend of humor and information, keeping the audience engaged."</span>,</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"A beautiful array of fake wax foods (shokuhin sampuru) in the front of a Japanese restaurant."</span>,</span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Daniel Bourke is really cool :D"</span>,</span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"My favoruite food is biltong!"</span></span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sentences)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>[{'label': 'not_food', 'score': 0.9972656965255737},
 {'label': 'not_food', 'score': 0.998143196105957},
 {'label': 'not_food', 'score': 0.9920535087585449},
 {'label': 'not_food', 'score': 0.997535228729248},
 {'label': 'not_food', 'score': 0.9985295534133911},
 {'label': 'not_food', 'score': 0.9983918070793152},
 {'label': 'not_food', 'score': 0.7593845725059509},
 {'label': 'food', 'score': 0.9995193481445312},
 {'label': 'not_food', 'score': 0.9990437626838684},
 {'label': 'food', 'score': 0.9853901863098145}]</code></pre>
</div>
</div>
<p>Woah! That was quick!</p>
<p>And it looks like our model performed fairly well.</p>
<p>Though there was one harder sample which may be deemed as <code>food</code>/<code>not_food</code>, the sentence containing “shokuhin sampuru” (meaning “<a href="https://en.wikipedia.org/wiki/Food_model">food model</a>” in Japanese).</p>
<p>Is a sentence about food models (fake foods) still about food?</p>
</section>
<section id="time-our-model-across-larger-sample-sizes" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="time-our-model-across-larger-sample-sizes"><span class="header-section-number">8.4</span> Time our model across larger sample sizes</h3>
<p>We can <em>say</em> that our model is fast or that making predictions in batches is faster than one at a time.</p>
<p>But how about we run some tests to confirm this?</p>
<p>Let’s start by making predictions one at a time across 100 sentences (10x our <code>sentences</code> list) and then we’ll write some code to make predictions in batches.</p>
<p>We’ll time each and see how they go.</p>
<div id="cell-158" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 1000 sentences</span></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>sentences_1000 <span class="op">=</span> sentences <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Time how long it takes to make predictions on all sentences (one at a time)</span></span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Number of sentences: </span><span class="sc">{</span><span class="bu">len</span>(sentences_1000)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a>start_time_one_at_a_time <span class="op">=</span> time.time()</span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sentence <span class="kw">in</span> sentences_1000:</span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make a prediction on each sentence one at a time</span></span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier(sentence)</span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a>end_time_one_at_a_time <span class="op">=</span> time.time()</span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Time taken for one at a time prediction: </span><span class="sc">{</span>end_time_one_at_a_time <span class="op">-</span> start_time_one_at_a_time<span class="sc">}</span><span class="ss"> seconds"</span>)</span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Avg inference time per sentence: </span><span class="sc">{</span>(end_time_one_at_a_time <span class="op">-</span> start_time_one_at_a_time) <span class="op">/</span> <span class="bu">len</span>(sentences_100)<span class="sc">}</span><span class="ss"> seconds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Number of sentences: 1000
[INFO] Time taken for one at a time prediction: 5.6913557052612305 seconds
[INFO] Avg inference time per sentence: 0.005691355705261231 seconds</code></pre>
</div>
</div>
<p>Ok, on my local NVIDIA RTX 4090 GPU, it took around 5.5 seconds to make 1000 predictions one at a time.</p>
<p>That’s pretty good!</p>
<p>But let’s see if we can make it faster with batching.</p>
<p>To do so, we can increase the size of our <code>sentences_big</code> list and pass the list directly to the model to enable batched prediction.</p>
<div id="cell-160" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10_000</span>]:</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>    sentences_big <span class="op">=</span> sentences <span class="op">*</span> i</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Number of sentences: </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on all sentences in batches </span></span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier(sentences_big)</span>
<span id="cb121-8"><a href="#cb121-8" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb121-9"><a href="#cb121-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-10"><a href="#cb121-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Inference time for </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss"> sentences: </span><span class="sc">{</span><span class="bu">round</span>(end_time <span class="op">-</span> start_time, <span class="dv">5</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb121-11"><a href="#cb121-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Avg inference time per sentence: </span><span class="sc">{</span><span class="bu">round</span>((end_time <span class="op">-</span> start_time) <span class="op">/</span> <span class="bu">len</span>(sentences_big), <span class="dv">8</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb121-12"><a href="#cb121-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Number of sentences: 100
[INFO] Inference time for 100 sentences: 0.15167 seconds.
[INFO] Avg inference time per sentence: 0.0015167 seconds.

[INFO] Number of sentences: 1000
[INFO] Inference time for 1000 sentences: 0.27526 seconds.
[INFO] Avg inference time per sentence: 0.00027526 seconds.

[INFO] Number of sentences: 10000
[INFO] Inference time for 10000 sentences: 3.32303 seconds.
[INFO] Avg inference time per sentence: 0.0003323 seconds.

[INFO] Number of sentences: 100000</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[77], line 7</span>
<span class="ansi-green-fg ansi-bold">      5</span> start_time <span style="color:rgb(98,98,98)">=</span> time<span style="color:rgb(98,98,98)">.</span>time()
<span class="ansi-green-fg ansi-bold">      6</span> <span style="font-style:italic;color:rgb(95,135,135)"># Predict on all sentences in batches </span>
<span class="ansi-green-fg">----&gt; 7</span> <span class="ansi-yellow-bg">food_not_food_classifier</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">sentences_big</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">      8</span> end_time <span style="color:rgb(98,98,98)">=</span> time<span style="color:rgb(98,98,98)">.</span>time()
<span class="ansi-green-fg ansi-bold">     10</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">[INFO] Inference time for </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span><span style="color:rgb(0,135,0)">len</span>(sentences_big)<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)"> sentences: </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span><span style="color:rgb(0,135,0)">round</span>(end_time<span style="color:rgb(188,188,188)"> </span><span style="color:rgb(98,98,98)">-</span><span style="color:rgb(188,188,188)"> </span>start_time,<span style="color:rgb(188,188,188)"> </span><span style="color:rgb(98,98,98)">5</span>)<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)"> seconds.</span><span style="color:rgb(175,0,0)">"</span>)

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:156</span>, in <span class="ansi-cyan-fg">TextClassificationPipeline.__call__</span><span class="ansi-blue-fg">(self, inputs, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">    122</span> <span style="font-style:italic;color:rgb(175,0,0)">"""</span>
<span class="ansi-green-fg ansi-bold">    123</span> <span style="font-style:italic;color:rgb(175,0,0)">Classify the text(s) given as inputs.</span>
<span class="ansi-green-fg ansi-bold">    124</span> 
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-fg ansi-bold">    153</span> <span style="font-style:italic;color:rgb(175,0,0)">    If `top_k` is used, one such dictionary is returned per label.</span>
<span class="ansi-green-fg ansi-bold">    154</span> <span style="font-style:italic;color:rgb(175,0,0)">"""</span>
<span class="ansi-green-fg ansi-bold">    155</span> inputs <span style="color:rgb(98,98,98)">=</span> (inputs,)
<span class="ansi-green-fg">--&gt; 156</span> result <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">super</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span style="color:rgb(0,0,255)" class="ansi-yellow-bg">__call__</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">    157</span> <span style="font-style:italic;color:rgb(95,135,135)"># TODO try and retrieve it in a nicer way from _sanitize_parameters.</span>
<span class="ansi-green-fg ansi-bold">    158</span> _legacy <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">top_k</span><span style="color:rgb(175,0,0)">"</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> <span style="font-weight:bold;color:rgb(175,0,255)">in</span> kwargs

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/base.py:1224</span>, in <span class="ansi-cyan-fg">Pipeline.__call__</span><span class="ansi-blue-fg">(self, inputs, num_workers, batch_size, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   1220</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> can_use_iterator:
<span class="ansi-green-fg ansi-bold">   1221</span>     final_iterator <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>get_iterator(
<span class="ansi-green-fg ansi-bold">   1222</span>         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params
<span class="ansi-green-fg ansi-bold">   1223</span>     )
<span class="ansi-green-fg">-&gt; 1224</span>     outputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">list</span>(final_iterator)
<span class="ansi-green-fg ansi-bold">   1225</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> outputs
<span class="ansi-green-fg ansi-bold">   1226</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124</span>, in <span class="ansi-cyan-fg">PipelineIterator.__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-fg ansi-bold">    121</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>loader_batch_item()
<span class="ansi-green-fg ansi-bold">    123</span> <span style="font-style:italic;color:rgb(95,135,135)"># We're out of items within a batch</span>
<span class="ansi-green-fg">--&gt; 124</span> item <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>iterator)
<span class="ansi-green-fg ansi-bold">    125</span> processed <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>infer(item, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span><span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>params)
<span class="ansi-green-fg ansi-bold">    126</span> <span style="font-style:italic;color:rgb(95,135,135)"># We now have a batch of "inferred things".</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:125</span>, in <span class="ansi-cyan-fg">PipelineIterator.__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-fg ansi-bold">    123</span> <span style="font-style:italic;color:rgb(95,135,135)"># We're out of items within a batch</span>
<span class="ansi-green-fg ansi-bold">    124</span> item <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>iterator)
<span class="ansi-green-fg">--&gt; 125</span> processed <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">infer</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">item</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">params</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">    126</span> <span style="font-style:italic;color:rgb(95,135,135)"># We now have a batch of "inferred things".</span>
<span class="ansi-green-fg ansi-bold">    127</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>loader_batch_size <span style="font-weight:bold;color:rgb(175,0,255)">is</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>:
<span class="ansi-green-fg ansi-bold">    128</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Try to infer the size of the batch</span>

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/base.py:1151</span>, in <span class="ansi-cyan-fg">Pipeline.forward</span><span class="ansi-blue-fg">(self, model_inputs, **forward_params)</span>
<span class="ansi-green-fg ansi-bold">   1149</span>         model_inputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_ensure_tensor_on_device(model_inputs, device<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>device)
<span class="ansi-green-fg ansi-bold">   1150</span>         model_outputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_forward(model_inputs, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>forward_params)
<span class="ansi-green-fg">-&gt; 1151</span>         model_outputs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_ensure_tensor_on_device</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">model_outputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">device</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">torch</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">device</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">cpu</span><span style="color:rgb(175,0,0)" class="ansi-yellow-bg">"</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1152</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg ansi-bold">   1153</span>     <span style="font-weight:bold;color:rgb(0,135,0)">raise</span> <span style="font-weight:bold;color:rgb(215,95,95)">ValueError</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Framework </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span><span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>framework<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)"> is not supported</span><span style="color:rgb(175,0,0)">"</span>)

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/base.py:1051</span>, in <span class="ansi-cyan-fg">Pipeline._ensure_tensor_on_device</span><span class="ansi-blue-fg">(self, inputs, device)</span>
<span class="ansi-green-fg ansi-bold">   1048</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span> <span style="color:rgb(0,0,255)">_ensure_tensor_on_device</span>(<span style="color:rgb(0,135,0)">self</span>, inputs, device):
<span class="ansi-green-fg ansi-bold">   1049</span>     <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">isinstance</span>(inputs, ModelOutput):
<span class="ansi-green-fg ansi-bold">   1050</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> ModelOutput(
<span class="ansi-green-fg">-&gt; 1051</span>             <span class="ansi-yellow-bg">{</span><span class="ansi-yellow-bg">name</span><span class="ansi-yellow-bg">:</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_ensure_tensor_on_device</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">tensor</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">device</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg"> </span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">for</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">name</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">tensor</span><span class="ansi-yellow-bg"> </span><span style="font-weight:bold;color:rgb(175,0,255)" class="ansi-yellow-bg">in</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">inputs</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">items</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span><span class="ansi-yellow-bg">}</span>
<span class="ansi-green-fg ansi-bold">   1052</span>         )
<span class="ansi-green-fg ansi-bold">   1053</span>     <span style="font-weight:bold;color:rgb(0,135,0)">elif</span> <span style="color:rgb(0,135,0)">isinstance</span>(inputs, <span style="color:rgb(0,135,0)">dict</span>):
<span class="ansi-green-fg ansi-bold">   1054</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> {name: <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_ensure_tensor_on_device(tensor, device) <span style="font-weight:bold;color:rgb(0,135,0)">for</span> name, tensor <span style="font-weight:bold;color:rgb(175,0,255)">in</span> inputs<span style="color:rgb(98,98,98)">.</span>items()}

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/base.py:1051</span>, in <span class="ansi-cyan-fg">&lt;dictcomp&gt;</span><span class="ansi-blue-fg">(.0)</span>
<span class="ansi-green-fg ansi-bold">   1048</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span> <span style="color:rgb(0,0,255)">_ensure_tensor_on_device</span>(<span style="color:rgb(0,135,0)">self</span>, inputs, device):
<span class="ansi-green-fg ansi-bold">   1049</span>     <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">isinstance</span>(inputs, ModelOutput):
<span class="ansi-green-fg ansi-bold">   1050</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> ModelOutput(
<span class="ansi-green-fg">-&gt; 1051</span>             {name: <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_ensure_tensor_on_device</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">tensor</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">device</span><span class="ansi-yellow-bg">)</span> <span style="font-weight:bold;color:rgb(0,135,0)">for</span> name, tensor <span style="font-weight:bold;color:rgb(175,0,255)">in</span> inputs<span style="color:rgb(98,98,98)">.</span>items()}
<span class="ansi-green-fg ansi-bold">   1052</span>         )
<span class="ansi-green-fg ansi-bold">   1053</span>     <span style="font-weight:bold;color:rgb(0,135,0)">elif</span> <span style="color:rgb(0,135,0)">isinstance</span>(inputs, <span style="color:rgb(0,135,0)">dict</span>):
<span class="ansi-green-fg ansi-bold">   1054</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> {name: <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_ensure_tensor_on_device(tensor, device) <span style="font-weight:bold;color:rgb(0,135,0)">for</span> name, tensor <span style="font-weight:bold;color:rgb(175,0,255)">in</span> inputs<span style="color:rgb(98,98,98)">.</span>items()}

File <span class="ansi-green-fg">~/miniconda3/envs/ai/lib/python3.11/site-packages/transformers/pipelines/base.py:1062</span>, in <span class="ansi-cyan-fg">Pipeline._ensure_tensor_on_device</span><span class="ansi-blue-fg">(self, inputs, device)</span>
<span class="ansi-green-fg ansi-bold">   1060</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span style="color:rgb(0,135,0)">tuple</span>([<span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_ensure_tensor_on_device(item, device) <span style="font-weight:bold;color:rgb(0,135,0)">for</span> item <span style="font-weight:bold;color:rgb(175,0,255)">in</span> inputs])
<span class="ansi-green-fg ansi-bold">   1061</span> <span style="font-weight:bold;color:rgb(0,135,0)">elif</span> <span style="color:rgb(0,135,0)">isinstance</span>(inputs, torch<span style="color:rgb(98,98,98)">.</span>Tensor):
<span class="ansi-green-fg">-&gt; 1062</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">inputs</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">to</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">device</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   1063</span> <span style="font-weight:bold;color:rgb(0,135,0)">else</span>:
<span class="ansi-green-fg ansi-bold">   1064</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> inputs

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
</div>
<p>Woah!</p>
<p>It looks like inference/prediction time is ~10-20x faster when using batched prediction versus predicting one at a time (on my local NVIDIA RTX 4090).</p>
<p>I ran some more tests with the same model on a different GPU on Google Colab (<a href="https://www.nvidia.com/en-au/data-center/l4/">NVIDIA L4 GPU</a>) and got similar results.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Number of Sentences</th>
<th style="text-align: left;">Total Prediction Time</th>
<th style="text-align: left;">Prediction Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">100</td>
<td style="text-align: left;">0.62</td>
<td style="text-align: left;">one at a time</td>
</tr>
<tr class="even">
<td style="text-align: left;">1000</td>
<td style="text-align: left;">6.19</td>
<td style="text-align: left;">one at a time</td>
</tr>
<tr class="odd">
<td style="text-align: left;">10000</td>
<td style="text-align: left;">61.08</td>
<td style="text-align: left;">one at a time</td>
</tr>
<tr class="even">
<td style="text-align: left;">100000</td>
<td style="text-align: left;">605.46</td>
<td style="text-align: left;">one at a time</td>
</tr>
<tr class="odd">
<td style="text-align: left;">100</td>
<td style="text-align: left;">0.06</td>
<td style="text-align: left;">batch</td>
</tr>
<tr class="even">
<td style="text-align: left;">1000</td>
<td style="text-align: left;">0.51</td>
<td style="text-align: left;">batch</td>
</tr>
<tr class="odd">
<td style="text-align: left;">10000</td>
<td style="text-align: left;">4.97</td>
<td style="text-align: left;">batch</td>
</tr>
<tr class="even">
<td style="text-align: left;">100000</td>
<td style="text-align: left;">49.7</td>
<td style="text-align: left;">batch</td>
</tr>
</tbody>
</table>
<p><em>Testing the speed of a custom text classifier model on different numbers of sentences with one at a time or batched prediction. Tests conducted on Google Colab with a NVIDIA L4 GPU. See the <a href="https://colab.research.google.com/drive/14oC-UDCIHrvRZOEKnAvr6JIHrvZzXOkB?usp=sharing">notebook for code to reproduce</a>.</em></p>
</section>
<section id="making-predictions-with-pytorch" class="level3" data-number="8.5">
<h3 data-number="8.5" class="anchored" data-anchor-id="making-predictions-with-pytorch"><span class="header-section-number">8.5</span> Making predictions with PyTorch</h3>
<p>We’ve seen how to make predictions/perform inference with <code>transformers.pipeline</code>, now let’s see how to do the same with PyTorch.</p>
<p>Performing predictions with PyTorch requires an extra step compared to <code>pipeline</code>, we have to prepare our inputs first (turn the text into numbers).</p>
<p>Good news is, we can prepare our inputs with the tokenizer that got automatically saved with our model.</p>
<p>And since we’ve already trained a model and uploaded it to the Hugging Face Hub, we can load our model and tokenizer with <code>transformers.AutoTokenizer</code> and <code>transformers.AutoModelForSequenceClassification</code> passing it the saved path we used (mine is <code>mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code>).</p>
<p>Let’s start by loading the tokenizer and see what it looks like to tokenize a piece of sample text.</p>
<div id="cell-163" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup model path (can be local or on Hugging Face)</span></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an example to predict on</span></span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>sample_text_food <span class="op">=</span> <span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast"</span></span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the tokenizer and tokenize the inputs</span></span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(pretrained_model_name_or_path<span class="op">=</span>model_path)</span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(sample_text_food, </span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>                   return_tensors<span class="op">=</span><span class="st">"pt"</span>) <span class="co"># return the output as PyTorch tensors </span></span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>inputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>{'input_ids': tensor([[  101,  1037, 12090,  6302,  1997,  1037,  5127,  1997, 13501,  6763,
          1010, 11611,  1998, 15174,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}</code></pre>
</div>
</div>
<p>Nice!</p>
<p>Text tokenized!</p>
<p>We get a dictionary of <code>input_ids</code> (our text in token form) and <code>attention_mask</code> (tells the model which tokens to pay attention to, <code>1</code> = pay attention, <code>0</code> = no attention).</p>
<p>Now we can load the model with the same path.</p>
<div id="cell-165" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load our text classification model</span></span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path<span class="op">=</span>model_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Model loaded!</p>
<p>Let’s make a prediction.</p>
<p>We can do so using the context manager <code>torch.no_grad()</code> (because no gradients/weights get updated during inference) and passing our model out <code>inputs</code> dictionary.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A little tidbit about using dictionaries as function inputs in Python is the ability to unpack the keys of the dictionary into function arguments.</p>
<p>This is possible using <code>**TARGET_DICTIONARY</code> syntax. Where the <code>**</code> means “use all the keys in the dictionary as function parameters”.</p>
<p>For example, the following two lines are equivalent:</p>
<pre><code># Using ** notation
outputs = model(**inputs)

# Using explicit notation
outputs = model(input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"])</code></pre>
</div>
</div>
<p>Let’s make a prediction with PyTorch!</p>
<div id="cell-167" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(<span class="op">**</span>inputs) <span class="co"># '**' means input all of the dictionary keys as arguments to the function</span></span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># outputs = model(input_ids=inputs["input_ids"],</span></span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#                 attention_mask=inputs["attention_mask"]) # same as above, but explicitly passing in the keys</span></span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>outputs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>SequenceClassifierOutput(loss=None, logits=tensor([[-3.4825,  4.2022]]), hidden_states=None, attentions=None)</code></pre>
</div>
</div>
<p>Beautiful, we’ve got some outputs, which contain <code>logits</code> with two values (one for each class).</p>
<p>The index of the higher value is our model’s predicted class.</p>
<p>We can find it by taking the <code>outputs.logits</code> and calling <a href="https://pytorch.org/docs/stable/generated/torch.argmax.html"><code>argmax().item()</code></a> on it.</p>
<p>We can also find the prediction probability by passing <code>outputs.logits</code> to <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html"><code>torch.softmax</code></a>.</p>
<div id="cell-169" class="cell" data-outputid="bfc30a2d-9a47-441f-f2e9-7cee7fd4989d" data-execution_count="89">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted class and prediction probability</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>predicted_class_id <span class="op">=</span> outputs.logits.argmax().item()</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>prediction_probability <span class="op">=</span> torch.softmax(outputs.logits, dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">max</span>().item()</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>sample_text_food<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted label: </span><span class="sc">{</span>model<span class="sc">.</span>config<span class="sc">.</span>id2label[predicted_class_id]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Prediction probability: </span><span class="sc">{</span>prediction_probability<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Text: A delicious photo of a plate of scrambled eggs, bacon and toast
Predicted label: food
Prediction probability: 0.9995404481887817</code></pre>
</div>
</div>
<p>Beautiful! A prediction made with pure PyTorch! It looks very much correct too.</p>
<p>How about we put it all together?</p>
<div id="cell-171" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForSequenceClassification</span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the model and tokenizer</span></span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(pretrained_model_name_or_path<span class="op">=</span>model_path)</span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path<span class="op">=</span>model_path)</span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sample text and tokenize it</span></span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> <span class="st">"A photo of a broccoli, salmon, rice and radish dish"</span></span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(sample_text, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb131-14"><a href="#cb131-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-15"><a href="#cb131-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction</span></span>
<span id="cb131-16"><a href="#cb131-16" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb131-17"><a href="#cb131-17" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(<span class="op">**</span>inputs)</span>
<span id="cb131-18"><a href="#cb131-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-19"><a href="#cb131-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted class and prediction probability</span></span>
<span id="cb131-20"><a href="#cb131-20" aria-hidden="true" tabindex="-1"></a>output_logits <span class="op">=</span> outputs.logits</span>
<span id="cb131-21"><a href="#cb131-21" aria-hidden="true" tabindex="-1"></a>predicted_class_id <span class="op">=</span> torch.argmax(output_logits, dim<span class="op">=</span><span class="dv">1</span>).item()</span>
<span id="cb131-22"><a href="#cb131-22" aria-hidden="true" tabindex="-1"></a>predicted_class_label <span class="op">=</span> model.config.id2label[predicted_class_id]</span>
<span id="cb131-23"><a href="#cb131-23" aria-hidden="true" tabindex="-1"></a>predicted_probability <span class="op">=</span> torch.softmax(output_logits, dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">max</span>().item()</span>
<span id="cb131-24"><a href="#cb131-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb131-25"><a href="#cb131-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Print outputs</span></span>
<span id="cb131-26"><a href="#cb131-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>sample_text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb131-27"><a href="#cb131-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted class: </span><span class="sc">{</span>predicted_class_label<span class="sc">}</span><span class="ss"> (prob: </span><span class="sc">{</span>predicted_probability <span class="op">*</span> <span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Text: A photo of a broccoli, salmon, rice and radish dish
Predicted class: food (prob: 99.96%)</code></pre>
</div>
</div>
</section>
</section>
<section id="turning-our-model-into-a-demo" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="turning-our-model-into-a-demo"><span class="header-section-number">9</span> Turning our model into a demo</h2>
<p>Once you’ve trained and saved a model, one of the best ways to continue to test it and show/share it with others is to create a demo.</p>
<p>Or step number 8 in our workflow:</p>
<ol type="1">
<li>✅ Create and preprocess data.</li>
<li>✅ Define the model we’d like use with <a href="https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSequenceClassification"><code>transformers.AutoModelForSequenceClassification</code></a> (or another similar model class).</li>
<li>✅ Define training arguments (these are hyperparameters for our model) with <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code></a>.</li>
<li>✅ Pass <code>TrainingArguments</code> from 3 and target datasets to an instance of <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer"><code>transformers.Trainer</code></a>.</li>
<li>✅ Train the model by calling <a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"><code>Trainer.train()</code></a>.</li>
<li>✅ Save the model (to our local machine or to the Hugging Face Hub).</li>
<li>✅ Evaluate the trained model by making and inspecting predctions on the test data.</li>
<li>Turn the model into a shareable demo.</li>
</ol>
<p>A demo is a small application with the focus of showing the workflow of your model from data in to data out.</p>
<p>It’s also one way to start testing your model in the wild.</p>
<p>You may know where it works and where it doesn’t but chances are someone out there will find a new bug before you do.</p>
<p>To build our demo, we’re going to use an open-source library called <a href="https://www.gradio.app/guides/quickstart">Gradio</a>.</p>
<p>Gradio allows you to make machine learning demo apps with Python code and best of all, it’s part of the Hugging Face ecosystem so you can share your demo to the public directly through Hugging Face.</p>
<p>TK image - showcase workflow of data -&gt; model -&gt; save -&gt; demo -&gt; share</p>
<p>Gradio works on the premise of input -&gt; function (this could be a model) -&gt; output.</p>
<p>In our case:</p>
<ul>
<li>Input = A string of text.</li>
<li>Function = Our trained text classification model.</li>
<li>Output = Predicted output of food/not_food with prediction probability.</li>
</ul>
<section id="creating-a-simple-function-to-perform-inference" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="creating-a-simple-function-to-perform-inference"><span class="header-section-number">9.1</span> Creating a simple function to perform inference</h3>
<p>Let’s create a function to take an input of text, process it with our model and return a dictionary of the predicted labels.</p>
<p>Our function will:</p>
<ol type="1">
<li>Take an input of a string of text.</li>
<li>Setup a text classification pipeline using <code>transformers.pipeline</code> as well as our trained model (this can be from our local machine or loaded from Hugging Face). We’ll return all the probabilities from the output using <code>top_k=None</code>.</li>
<li>Get the outputs of the text classification pipeline from 2 as a list of dictionaries (e.g.&nbsp;<code>[{'label': 'food', 'score': 0.999105}, {'label': 'not_food', 'score': 0.00089}]</code>).</li>
<li>Format and return the list of dictionaries from 3 to be compatible with Gradio’s <a href="https://www.gradio.app/docs/gradio/label"><code>gr.Label</code></a> output (we’ll see this later) which requires a dictionary in the form <code>[{"label_1": probability_1, "label_2": probability_2}]</code>.</li>
</ol>
<p>Onward!</p>
<div id="cell-174" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Create a function which takes text as input </span></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text: <span class="bu">str</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Takes an input string of text and classifies it into food/not_food in the form of a dictionary.</span></span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Setup the pipeline to use the local model (or Hugging Face model path)</span></span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span>local_model_path,</span>
<span id="cb133-12"><a href="#cb133-12" aria-hidden="true" tabindex="-1"></a>                                        batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb133-13"><a href="#cb133-13" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>, <span class="co"># set the device to work in any environment</span></span>
<span id="cb133-14"><a href="#cb133-14" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb133-15"><a href="#cb133-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-16"><a href="#cb133-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb133-17"><a href="#cb133-17" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb133-18"><a href="#cb133-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb133-19"><a href="#cb133-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb133-20"><a href="#cb133-20" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb133-21"><a href="#cb133-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb133-22"><a href="#cb133-22" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb133-23"><a href="#cb133-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-24"><a href="#cb133-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb133-25"><a href="#cb133-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-26"><a href="#cb133-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Test out the function</span></span>
<span id="cb133-27"><a href="#cb133-27" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"My lunch today was chicken and salad"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>{'food': 0.9991052746772766, 'not_food': 0.0008946915622800589}</code></pre>
</div>
</div>
<p>Beautiful!</p>
<p>Looks like our function is working.</p>
</section>
<section id="building-a-small-gradio-demo-to-run-locally" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="building-a-small-gradio-demo-to-run-locally"><span class="header-section-number">9.2</span> Building a small Gradio demo to run locally</h3>
<p>We’ve got a working function to go from text to predicted labels and probabilities.</p>
<p>Let’s now build a Gradio interface to showcase our model.</p>
<p>We can do so by:</p>
<ol type="1">
<li>Importing Gradio (using <code>import gradio as gr</code>).</li>
<li>Creating an instance of <a href="https://www.gradio.app/docs/gradio/interface"><code>gr.Interface</code></a> with parameters <code>inputs="text"</code> (for our text-based inputs) called <code>demo</code> and <code>outputs=gr.Label(num_top_classes=2)</code> to display our output dictionary. We can also add some descriptive aspects to our <code>demo</code> with the <code>title</code>, <code>description</code> and <code>examples</code> parameters.</li>
<li>Running/launching the demo with <a href="https://www.gradio.app/docs/gradio/interface#interface-launch"><code>gr.Interface.launch()</code></a>.</li>
</ol>
<div id="cell-177" class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Import Gradio as the common alias "gr"</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Setup a Gradio interface to accept text and output labels</span></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>    fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Food or Not Food Classifier"</span>,</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">"A text classifier to determine if a sentence is about food or not food."</span>,</span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>    examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a>              [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Launch the interface</span></span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a>demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running on local URL:  http://127.0.0.1:7863

To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7863/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code></code></pre>
</div>
</div>
<p>Woohoo!</p>
<p>We’ve made a very clean way of interacting with our model.</p>
<p>However, our model is still only largely accessible to us (except for the model file we’ve uploaded to Hugging Face).</p>
<p>How about we make our demo publicly available so it’s even easier for people to interact with our model?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <a href="https://www.gradio.app/docs/gradio/interface"><code>gradio.Interface</code></a> class is full of many different options, I’d highly recommend reading through the documentation for 10-15 minutes to get an idea of it.</p>
<p>If your workflow requires inputs -&gt; function (e.g.&nbsp;a model making predictions on the input) -&gt; output, chances are, you can build it with Gradio.</p>
</div>
</div>
</section>
</section>
<section id="making-our-demo-publicly-accessible" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="making-our-demo-publicly-accessible"><span class="header-section-number">10</span> Making our demo publicly accessible</h2>
<p>One of the best ways to share your machine learning work is by creating an application.</p>
<p>And one of the best places to share your applications is <a href="https://huggingface.co/docs/hub/spaces">Hugging Face Spaces</a>.</p>
<p>Hugging Face Spaces allows you to host machine learning (and non-machine learning) applications for free (with <a href="https://huggingface.co/docs/hub/spaces-overview#hardware-resources">optional paid hardware upgrades</a>).</p>
<p>If you’re familiar with GitHub, Hugging Face Spaces works similar to a GitHub repository (each Space is a Git repository itself).</p>
<p>If not, that’s okay, think of Hugging Face Spaces as an online folder where you can upload your files and have them accessed by others.</p>
<p>Creating a Hugging Face Space can be done in two main ways:</p>
<ol type="1">
<li><strong>Manually</strong> - By going to the <a href="https://huggingface.co/spaces">Hugging Face Spaces</a> website and clicking “Create new space”. Or by going directly to <a href="https://huggingface.co/new-space">https://www.huggingface.co/new-space</a>. Here, you’ll be able to setup a few settings for your Space and choose the framework/runtime (e.g.&nbsp;Streamlit, Gradio, Docker and more).</li>
<li><strong>Programmatically</strong> - By using the <a href="https://huggingface.co/docs/huggingface_hub/package_reference/hf_api">Hugging Face Hub Python API</a> we can write code to <a href="https://www.gradio.app/guides/using-hugging-face-integrations#hosting-your-gradio-demos-on-spaces">directly upload files to the Hugging Face Hub</a>, including Hugging Face Spaces.</li>
</ol>
<p>Both are great options but we’re going to take the second approach.</p>
<p>This is so we can create our Hugging Face Space right from this notebook.</p>
<p>To do so, we’ll create three files:</p>
<ol type="1">
<li><code>app.py</code> - This will be the Python file which will be the main running file on our Hugging Face Space. Inside we’ll include all the code necessary to run our Gradio demo (as above). Hugging Face Spaces will automatically recoginize the <code>app.py</code> file and run it for us.</li>
<li><code>requirements.txt</code> - This text file will include all of the Python packages we need to run our <code>app.py</code> file. Before our Space starts to run, all of the packages in this file will be installed.</li>
<li><code>README.md</code> - This markdown file will include details about our Space as well as specific Space-related metadata (we’ll see this later on).</li>
</ol>
<p>We’ll create these files with the following file structure:</p>
<pre><code>demos/
└── food_not_food_text_classifier/
    ├── app.py
    ├── README.md
    └── requirements.txt</code></pre>
<p>Why this way?</p>
<p>Doing it in the above style means we’ll have a directory which contains all of our demos (<code>demos/</code>) as well as a dedicated directory which contains our <code>food</code>/<code>not_food</code> demo application (<code>food_not_food_text_classifier/</code>).</p>
<p>This way, we’ll be able to upload the whole <code>demos/food_not_food_text_classifier/</code> folder to Hugging Face Spaces.</p>
<p>Let’s start by making a directory to store our demo application files.</p>
<div id="cell-180" class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a directory for demos</span></span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>demos_dir <span class="op">=</span> Path(<span class="st">"../demos"</span>)</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>demos_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a folder for the food_not_food_text_classifer demo</span></span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir <span class="op">=</span> Path(demos_dir, <span class="st">"food_not_food_text_classifier"</span>)</span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Demo directory created, let’s now create our requried files.</p>
<section id="making-an-app-file" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="making-an-app-file"><span class="header-section-number">10.1</span> Making an app file</h3>
<p>Our <code>app.py</code> file will be the main part of our Hugging Face Space.</p>
<p>The good news is, we’ve already created most of it when we created our original demo.</p>
<p>Inside the <code>app.py</code> folder we’ll:</p>
<ol type="1">
<li>Import the required libraries/packages for running our demo app.</li>
<li>Setup a function for going from text to our trained model’s predicted outputs. And because our model is already hosted on the Hugging Face Hub, we can pass <code>pipeline</code> our model’s name (e.g.&nbsp;<code>mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</code>) and when we upload our <code>app.py</code> file to Hugging Face Spaces, it will load the model directly from the Hub.</li>
<li>Create a demo just as before with <code>gr.Interface</code>.</li>
<li>Launch our demo with <code>gr.Interface.launch</code>.</li>
</ol>
<p>We can write all of the above in a notebook cell.</p>
<p>And we can turn it into a file by using the <a href="https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-writefile"><code>%%writefile</code></a> magic command and passing it our target filepath.</p>
<p>Let’s do it!</p>
<div id="cell-183" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>app.py</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Import the required packages</span></span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict</span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Define function to use our model on given text </span></span>
<span id="cb140-10"><a href="#cb140-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text: <span class="bu">str</span>) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb140-11"><a href="#cb140-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set up text classification pipeline</span></span>
<span id="cb140-12"><a href="#cb140-12" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb140-13"><a href="#cb140-13" aria-hidden="true" tabindex="-1"></a>                                        <span class="co"># Because our model is on Hugging Face already, we can pass in the model name directly</span></span>
<span id="cb140-14"><a href="#cb140-14" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span>, <span class="co"># link to model on HF Hub</span></span>
<span id="cb140-15"><a href="#cb140-15" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>,</span>
<span id="cb140-16"><a href="#cb140-16" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb140-17"><a href="#cb140-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb140-18"><a href="#cb140-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb140-19"><a href="#cb140-19" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb140-20"><a href="#cb140-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-21"><a href="#cb140-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb140-22"><a href="#cb140-22" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb140-23"><a href="#cb140-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb140-24"><a href="#cb140-24" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb140-25"><a href="#cb140-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-26"><a href="#cb140-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb140-27"><a href="#cb140-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-28"><a href="#cb140-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a Gradio interface with details about our app</span></span>
<span id="cb140-29"><a href="#cb140-29" aria-hidden="true" tabindex="-1"></a>description <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb140-30"><a href="#cb140-30" aria-hidden="true" tabindex="-1"></a><span class="st">A text classifier to determine if a sentence is about food or not food. </span></span>
<span id="cb140-31"><a href="#cb140-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-32"><a href="#cb140-32" aria-hidden="true" tabindex="-1"></a><span class="st">Fine-tuned from [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on a [small dataset of food and not food text](https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions).</span></span>
<span id="cb140-33"><a href="#cb140-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-34"><a href="#cb140-34" aria-hidden="true" tabindex="-1"></a><span class="st">TK - See source code:</span></span>
<span id="cb140-35"><a href="#cb140-35" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb140-36"><a href="#cb140-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-37"><a href="#cb140-37" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb140-38"><a href="#cb140-38" aria-hidden="true" tabindex="-1"></a>             inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb140-39"><a href="#cb140-39" aria-hidden="true" tabindex="-1"></a>             outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb140-40"><a href="#cb140-40" aria-hidden="true" tabindex="-1"></a>             title<span class="op">=</span><span class="st">"🍗🚫🥑 Food or Not Food Text Classifier"</span>,</span>
<span id="cb140-41"><a href="#cb140-41" aria-hidden="true" tabindex="-1"></a>             description<span class="op">=</span>description,</span>
<span id="cb140-42"><a href="#cb140-42" aria-hidden="true" tabindex="-1"></a>             examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb140-43"><a href="#cb140-43" aria-hidden="true" tabindex="-1"></a>                       [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb140-44"><a href="#cb140-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-45"><a href="#cb140-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Launch the interface</span></span>
<span id="cb140-46"><a href="#cb140-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb140-47"><a href="#cb140-47" aria-hidden="true" tabindex="-1"></a>    demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/app.py</code></pre>
</div>
</div>
<p><code>app.py</code> file created!</p>
<p>Now let’s setup the requirements file.</p>
</section>
<section id="making-a-requirements-file" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="making-a-requirements-file"><span class="header-section-number">10.2</span> Making a requirements file</h3>
<p>When you upload an <code>app.py</code> file to Hugging Face Spaces, it will attempt to run it automatically.</p>
<p>And just like running the file locally, we need to make sure all of the required packages are available.</p>
<p>Otherwise our Space will produce an error like the following:</p>
<pre><code>===== Application Startup at 2024-06-13 05:37:21 =====

Traceback (most recent call last):
  File "/home/user/app/app.py", line 1, in &lt;module&gt;
    import torch
ModuleNotFoundError: No module named 'torch'</code></pre>
<p>Good news is, our demo only has three requirements: <code>gradio</code>, <code>torch</code>, <code>transformers</code>.</p>
<p>Let’s create a <code>requirements.txt</code> file with the packages we need and save it to the same directory as our <code>app.py</code> file.</p>
<div id="cell-186" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>requirements.txt</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>gradio</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>torch</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/requirements.txt</code></pre>
</div>
</div>
<p>Beautiful!</p>
<p>Hugging Face Spaces will automatically recognize the <code>requirements.txt</code> file and install the listed packages into our Space.</p>
</section>
<section id="making-a-readme-file" class="level3" data-number="10.3">
<h3 data-number="10.3" class="anchored" data-anchor-id="making-a-readme-file"><span class="header-section-number">10.3</span> Making a README file</h3>
<p>Our <code>app.py</code> can contain information about our demo, however, we can also use a <code>README.md</code> file to further communicate our work.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is common practice in Git repositories (including GitHub and Hugging Face Hub) to add a <code>README.md</code> file to your project so people can read more (hence “read me”) about what your project is about.</p>
</div>
</div>
<p>We can include anything in <a href="https://huggingface.co/docs/hub/en/spaces-config-reference">markdown-style text</a> in the <code>README.md</code> file.</p>
<p>However, Spaces also have a special <a href="https://simple.wikipedia.org/wiki/YAML">YAML block</a> at the top of the <code>README.md</code> file in the root directory with configuration details.</p>
<p>Inside the YAML block you can put special metadata details about your Space including:</p>
<ul>
<li><code>title</code> - The title of your Space (e.g.&nbsp;<code>title: Food Not Food Text Classifier</code>).</li>
<li><code>emoji</code> - The emoji to display on your Space (e.g.&nbsp;<code>emoji: 🍗🚫🥑</code>).</li>
<li><code>app_file</code> - The target app file for Spaces to run (set to <code>app_file: app.py</code> by default).</li>
</ul>
<p>And there are plenty more in the <a href="https://huggingface.co/docs/hub/en/spaces-config-reference">Spaces Configuration References documentation</a>.</p>
<ul>
<li>TK image - YAML block + markdown text underneath</li>
</ul>
<p>Let’s create a <code>README.md</code> file with a YAML block at the top detailing some of the metadata about our project.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The YAML block at the top of the <code>README.md</code> can take some practice.</p>
<p>If you want to see a demo of how one gets created, try making a Hugging Face Space with the “Create new Space” button on the <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a> page and seeing what the <code>README.md</code> file starts with (that’s how I found out what to do!).</p>
</div>
</div>
<div id="cell-189" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>README.md</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a>title: Food Not Food Text Classifier</span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>emoji: 🍗🚫🥑</span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>colorFrom: blue</span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>colorTo: yellow</span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>sdk: gradio</span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a>sdk_version: <span class="fl">4.36.1</span></span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a>app_file: app.py</span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a>pinned: false</span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a>license: apache<span class="op">-</span><span class="fl">2.0</span></span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb145-13"><a href="#cb145-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-14"><a href="#cb145-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 🍗🚫🥑 Food Not Food Text Classifier</span></span>
<span id="cb145-15"><a href="#cb145-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-16"><a href="#cb145-16" aria-hidden="true" tabindex="-1"></a>Small demo to showcase a text classifier to determine <span class="cf">if</span> a sentence <span class="kw">is</span> about food <span class="kw">or</span> <span class="kw">not</span> food.</span>
<span id="cb145-17"><a href="#cb145-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-18"><a href="#cb145-18" aria-hidden="true" tabindex="-1"></a>DistillBERT model fine<span class="op">-</span>tuned on a small synthetic dataset of <span class="dv">250</span> generated [Food <span class="kw">or</span> Not Food image captions](https:<span class="op">//</span>huggingface.co<span class="op">/</span>datasets<span class="op">/</span>mrdbourke<span class="op">/</span>learn_hf_food_not_food_image_captions).</span>
<span id="cb145-19"><a href="#cb145-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-20"><a href="#cb145-20" aria-hidden="true" tabindex="-1"></a>TK <span class="op">-</span> see the demo notebook on how to create this</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/README.md</code></pre>
</div>
</div>
<p><code>README.md</code> created!</p>
<p>Now let’s check out the files we have in our <code>demos/food_not_food_text_classifier/</code> folder.</p>
<div id="cell-191" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>README.md  app.py  requirements.txt</code></pre>
</div>
</div>
<p>Perfect!</p>
<p>Looks like we’ve got all the files we need to create our Space.</p>
<p>Let’s upload them to the Hugging Face Hub.</p>
</section>
<section id="uploading-our-demo-to-hugging-face-spaces" class="level3" data-number="10.4">
<h3 data-number="10.4" class="anchored" data-anchor-id="uploading-our-demo-to-hugging-face-spaces"><span class="header-section-number">10.4</span> Uploading our demo to Hugging Face Spaces</h3>
<p>We’ve created all of the files required for our demo, now for the fun part!</p>
<p>Let’s upload them to Hugging Face Spaces.</p>
<p>To do so programmatically, we can use the <a href="https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api">Hugging Face Hub Python API</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <a href="https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api">Hugging Face Hub Python API</a> has many different options for interacting with the Hugging Face Hub programmatically.</p>
<p>You can create repositories, upload files, upload folders, add comments, change permissions and much much more.</p>
<p>Be sure to explore the documentation for at least 10-15 minutes to get an idea of what’s possible.</p>
</div>
</div>
<p>To get our demo hosted on Hugging Face Spaces we’ll go through the following steps:</p>
<ol type="1">
<li>Import the required methods from the <code>huggingface_hub</code> package, including <a href="https://huggingface.co/docs/huggingface_hub/package_reference/hf_api#huggingface_hub.HfApi.create_repo"><code>create_repo</code></a>, <a href="https://huggingface.co/docs/huggingface_hub/package_reference/hf_api#huggingface_hub.HfApi.get_full_repo_name"><code>get_full_repo_name</code></a>, <a href="https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api#huggingface_hub.HfApi.upload_file"><code>upload_file</code></a> (optional, we’ll be using <code>upload_folder</code>) and <a href="https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"><code>upload_folder</code></a>.</li>
<li>Define the demo folder we’d like to upload as well as the different parameters for the Hugging Face Space such as repo type (<code>"space"</code>), our target Space name, the target Space SDK (<code>"gradio"</code>), our <a href="https://huggingface.co/docs/hub/en/security-tokens">Hugging Face token</a> with write access (optional if it already isn’t setup).</li>
<li>Create a repository on Hugging Face Spaces using the <code>huggingface_hub.create_repo</code> method and filling out the appropriate parameters.</li>
<li>Get the full name of our created repository using the <code>huggingface_hub.get_full_repo_name</code> method (we could hard code this but I like to get it programmatically incase things change).</li>
<li>Upload the contents of our target demo folder (<code>../demos/food_not_food_text_classifier/</code>) to Hugging Face Hub with <a href="https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"><code>huggingface_hub.upload_folder</code></a>.</li>
<li>Hope it all works and inspect the results! 🤞</li>
</ol>
<p>A fair few steps but we’ve got this!</p>
<div id="cell-194" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Import the required methods for uploading to the Hugging Face Hub</span></span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> (</span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>    create_repo,</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a>    get_full_repo_name,</span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a>    upload_file, <span class="co"># for uploading a single file (if necessary)</span></span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>    upload_folder <span class="co"># for uploading multiple files (in a folder)</span></span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Define the parameters we'd like to use for the upload</span></span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD <span class="op">=</span> <span class="st">"../demos/food_not_food_text_classifier"</span></span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>HF_TARGET_SPACE_NAME <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier_demo"</span></span>
<span id="cb149-12"><a href="#cb149-12" aria-hidden="true" tabindex="-1"></a>HF_REPO_TYPE <span class="op">=</span> <span class="st">"space"</span> <span class="co"># we're creating a Hugging Face Space</span></span>
<span id="cb149-13"><a href="#cb149-13" aria-hidden="true" tabindex="-1"></a>HF_SPACE_SDK <span class="op">=</span> <span class="st">"gradio"</span></span>
<span id="cb149-14"><a href="#cb149-14" aria-hidden="true" tabindex="-1"></a>HF_TOKEN <span class="op">=</span> <span class="st">""</span> <span class="co"># optional: set to your Hugging Face token (but I'd advise storing this as an environment variable as previously discussed)</span></span>
<span id="cb149-15"><a href="#cb149-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-16"><a href="#cb149-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a Space repository on Hugging Face Hub </span></span>
<span id="cb149-17"><a href="#cb149-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Creating repo on Hugging Face Hub with name: </span><span class="sc">{</span>HF_TARGET_SPACE_NAME<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb149-18"><a href="#cb149-18" aria-hidden="true" tabindex="-1"></a>create_repo(</span>
<span id="cb149-19"><a href="#cb149-19" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>HF_TARGET_SPACE_NAME,</span>
<span id="cb149-20"><a href="#cb149-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token=HF_TOKEN, # optional: set token manually (though it will be automatically recognized if it's available as an environment variable)</span></span>
<span id="cb149-21"><a href="#cb149-21" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>HF_REPO_TYPE,</span>
<span id="cb149-22"><a href="#cb149-22" aria-hidden="true" tabindex="-1"></a>    private<span class="op">=</span><span class="va">False</span>, <span class="co"># set to True if you don't want your Space to be accessible to others</span></span>
<span id="cb149-23"><a href="#cb149-23" aria-hidden="true" tabindex="-1"></a>    space_sdk<span class="op">=</span>HF_SPACE_SDK,</span>
<span id="cb149-24"><a href="#cb149-24" aria-hidden="true" tabindex="-1"></a>    exist_ok<span class="op">=</span><span class="va">True</span>, <span class="co"># set to False if you want an error to raise if the repo_id already exists </span></span>
<span id="cb149-25"><a href="#cb149-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb149-26"><a href="#cb149-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-27"><a href="#cb149-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Get the full repository name (e.g. {username}/{model_id} or {username}/{space_name})</span></span>
<span id="cb149-28"><a href="#cb149-28" aria-hidden="true" tabindex="-1"></a>full_hf_repo_name <span class="op">=</span> get_full_repo_name(model_id<span class="op">=</span>HF_TARGET_SPACE_NAME)</span>
<span id="cb149-29"><a href="#cb149-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Full Hugging Face Hub repo name: </span><span class="sc">{</span>full_hf_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb149-30"><a href="#cb149-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb149-31"><a href="#cb149-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Upload our demo folder</span></span>
<span id="cb149-32"><a href="#cb149-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Uploading </span><span class="sc">{</span>LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD<span class="sc">}</span><span class="ss"> to repo: </span><span class="sc">{</span>full_hf_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb149-33"><a href="#cb149-33" aria-hidden="true" tabindex="-1"></a>folder_upload_url <span class="op">=</span> upload_folder(</span>
<span id="cb149-34"><a href="#cb149-34" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>full_hf_repo_name,</span>
<span id="cb149-35"><a href="#cb149-35" aria-hidden="true" tabindex="-1"></a>    folder_path<span class="op">=</span>LOCAL_DEMO_FOLDER_PATH_TO_UPLOAD,</span>
<span id="cb149-36"><a href="#cb149-36" aria-hidden="true" tabindex="-1"></a>    path_in_repo<span class="op">=</span><span class="st">"."</span>, <span class="co"># upload our folder to the root directory ("." means "base" or "root", this is the default)</span></span>
<span id="cb149-37"><a href="#cb149-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token=HF_TOKEN, # optional: set token manually</span></span>
<span id="cb149-38"><a href="#cb149-38" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>HF_REPO_TYPE,</span>
<span id="cb149-39"><a href="#cb149-39" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier demo app.py"</span></span>
<span id="cb149-40"><a href="#cb149-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb149-41"><a href="#cb149-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Demo folder successfully uploaded with commit URL: </span><span class="sc">{</span>folder_upload_url<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Creating repo on Hugging Face Hub with name: learn_hf_food_not_food_text_classifier_demo
[INFO] Full Hugging Face Hub repo name: mrdbourke/learn_hf_food_not_food_text_classifier_demo
[INFO] Uploading ../demos/food_not_food_text_classifier to repo: mrdbourke/learn_hf_food_not_food_text_classifier_demo
[INFO] Demo folder successfully uploaded with commit URL: https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo/tree/main/.</code></pre>
</div>
</div>
<p>Excellent!</p>
<p>Looks like all of the files in our target demo folder were uploaded!</p>
<p>Once this happens, Hugging Face Spaces will take a couple of minutes to build our application.</p>
<p>If there are any errors, it will let us know.</p>
<p>Otherwise, our demo application should be running live and be ready to test at a URL similar to: <a href="https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo">https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo</a> (though you may have to swap my username “<code>mrdbourke</code>” for your own as well as the name you chose for the Space).</p>
</section>
<section id="testing-our-hosted-demo" class="level3" data-number="10.5">
<h3 data-number="10.5" class="anchored" data-anchor-id="testing-our-hosted-demo"><span class="header-section-number">10.5</span> Testing our hosted demo</h3>
<p>One of the really cool things about Hugging Face Spaces is that we can share our demo application as a link so others can try it out.</p>
<p>We can also embed it right into our notebook.</p>
<p>To do so, we can go to the three dots in the top right of our <a href="https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo">hosted Space</a> and select “Embed this Space”.</p>
<p>We then have the option to embed our Space using a JavaScript web component, HTML <code>iframe</code> or via the direct URL.</p>
<p>Since Jupyter notebooks have the ability to render HTML via <a href="https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.HTML"><code>IPython.display.HTML</code></a>, let’s embed our Space with HTML.</p>
<div id="cell-197" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a><span class="co"># You can get embeddable HTML code for your demo by clicking the "Embed" button on the demo page</span></span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>HTML(data<span class="op">=</span><span class="st">'''</span></span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;iframe</span></span>
<span id="cb151-7"><a href="#cb151-7" aria-hidden="true" tabindex="-1"></a><span class="st">    src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space"</span></span>
<span id="cb151-8"><a href="#cb151-8" aria-hidden="true" tabindex="-1"></a><span class="st">    frameborder="0"</span></span>
<span id="cb151-9"><a href="#cb151-9" aria-hidden="true" tabindex="-1"></a><span class="st">    width="850"</span></span>
<span id="cb151-10"><a href="#cb151-10" aria-hidden="true" tabindex="-1"></a><span class="st">    height="450"</span></span>
<span id="cb151-11"><a href="#cb151-11" aria-hidden="true" tabindex="-1"></a><span class="st">&gt;&lt;/iframe&gt;     </span></span>
<span id="cb151-12"><a href="#cb151-12" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">

<iframe src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space" frameborder="0" width="850" height="450"></iframe>     
</div>
</div>
<p>Now that’s cool!</p>
<p>We can try out our Food Not Food Text Classifier app from right within our notebook!</p>
</section>
</section>
<section id="summary" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="summary"><span class="header-section-number">11</span> Summary</h2>
<p>You should be very proud of yourself!</p>
<p>We’ve just gone end-to-end on a machine learning workflow with Hugging Face.</p>
<p>From loading a dataset to training a model to deploying that model in the form of a public demo.</p>
<p>Here are some of the main takeaways from this project.</p>
<p><strong>The Hugging Face ecosystem is a collection of powerful and open-source tools for machine learning workflows.</strong></p>
<ul>
<li>Hugging Face <code>datasets</code> helps you to store and preprocess datasets of almost any shape and size.</li>
<li>Hugging Face <code>transformers</code> has many built-in pretrained models for many different use cases and components such as <code>transformers.Trainer</code> help you to tailor those models to your own custom use cases.</li>
<li>Hugging Face <code>tokenizers</code> works closely with <code>transformers</code> and allows the efficient conversion of raw text data into numerical representation (which is required for machine learning models).</li>
<li>The Hugging Face Hub is a great place to share your models and machine learning projects. Over time, you can build up a portfolio of machine learning-based projects to show future employers or clients and to help the community grow.</li>
<li>There are many more, but I’ll leave these for you to explore as extra-curriculum.</li>
</ul>
<p><strong>A common machine learning workflow: dataset -&gt; model -&gt; demo.</strong></p>
<p>Before a machine learning model is incorporated into a larger application, a very common workflow is to:</p>
<ol type="1">
<li>Find an existing or create a new dataset for your specific problem.</li>
<li>Train/fine-tune and evaluate an existing model on your dataset.</li>
<li>Create a small demo application to test your trained model.</li>
</ol>
<p>We’ve just gone through all of these steps for text classification!</p>
<p>Text classification is a very common problem in many business settings. If you have a similar problem but a different dataset, you can replicate this workflow.</p>
<p><strong>Building your own model has several advantages over using APIs.</strong></p>
<p>APIs are very helpful to try something out.</p>
<p>However, depending on your use case, you may often want to create your own custom model.</p>
<p>Training your own model can often result in faster predictions and far less running costs over time.</p>
<p>The Hugging Face ecosystem enables the creation of custom models for almost any kind of machine learning problem.</p>
</section>
<section id="tk---exercises-and-extensions" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="tk---exercises-and-extensions"><span class="header-section-number">12</span> TK - Exercises and Extensions</h2>
<p>There’s no better way to improve other than practicing what you’ve learned.</p>
<p>The following exercises and extensions are designed for you to practice the things we’ve covered in this project.</p>
<ol type="1">
<li>Our text classification model works on <code>food</code>/<code>not_food</code> text samples. How would you create your own binary text classification model on different classes?
<ul>
<li>Create ~10 or samples of your own text classes (e.g.&nbsp;10 samples each of <code>spam</code>/<code>not_spam</code> emails) and retrain a text classification model.</li>
<li>Bonus: Share the model you’ve made in a demo just like we did here. Send it to me, I’d love to see it! My email is on <a href="https://www.mrdbourke.com">my website</a>.</li>
</ul></li>
<li>We’ve trained our model on two classes (binary classification) but how might we increase that to 3 or more classes (multi-class classification)?
<ul>
<li>Hint: see the <code>num_labels</code> parameter in <code>transformers.AutoModelForSequenceClassification</code>.</li>
</ul></li>
<li>Our model seems to work pretty good on our test data and on the few number of examples we tried manually. Can you find any examples where our model fails? For example, what kind of sentences does it struggle with? How could you fix this?
<ul>
<li>Hint: Our model has been trained on examples with at least 5-12 words, does it still work with short sentences? (e.g.&nbsp;“pie”).</li>
<li>Bonus: If you find any cases where our model doesn’t perform well, make an extra 10-20 examples of these and add them to the dataset and then retrain the model (you’ll have to lookup <a href="https://discuss.huggingface.co/t/how-do-i-add-things-rows-to-an-already-saved-dataset/27423">“how to add rows to an existing Hugging Face dataset”</a>). How does the model perform after adding these additional samples?</li>
</ul></li>
<li>Datasets are fundamental to any machine learning project, getting to know how to process and interact with them is a fundamental skill. Spend 1 hour going through the <a href="https://huggingface.co/docs/datasets/en/tutorial">Hugging Face Datasets tutorial</a>.
<ul>
<li>Write 5 things you can do with Hugging Face Datasets and where they might come in handy.</li>
</ul></li>
<li>The Hugging Face <code>transformers</code> library has many features. The following readings are to help understand a handful of them.
<ul>
<li>Spend 10 minutes exploring the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments"><code>transformers.TrainingArguments</code> documentation</a>.</li>
<li>Spend 10 minutes reading the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#trainer"><code>transformers.Trainer</code> documentation</a>.<br>
</li>
<li>Spend 10 minutes reading the Hugging Face <a href="https://huggingface.co/docs/transformers/en/model_sharing">model sharing documentation</a>.<br>
</li>
<li>Spend 10 minutes reading the Hugging Face <a href="https://huggingface.co/docs/transformers/en/main_classes/pipelines#pipelines"><code>transformers.pipeline</code> documentation</a>.
<ul>
<li>What does a <code>pipeline</code> do?</li>
<li>Name 3 different kinds of pipelines and describe what they do in a sentence</li>
</ul></li>
</ul></li>
<li>Gradio is a powerful library for making machine learning demos, learning more about it will help you in future creations. Spend 10-15 minutes reading the <a href="https://www.gradio.app/guides/quickstart">Gradio quickstart documentation</a>.
<ul>
<li>What are 3 kinds of demos you can create?</li>
<li>What are 3 different inputs and outputs you can make?</li>
</ul></li>
</ol>
</section>
<section id="extra-resources" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="extra-resources"><span class="header-section-number">13</span> Extra resources</h2>
<p>There are many things we touched over but didn’t go into much depth in this notebook.</p>
<p>The following resources are for those who’d like to learn a little bit more.</p>
<ul>
<li>See how the food not food image caption dataset was created with synthetic text data (image captions generated by a Large Language Model) in the example <a href="https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing">Google Colab notebook</a>.</li>
<li>Hugging Face have a <a href="https://huggingface.co/docs/transformers/en/tasks/sequence_classification">great guide on sequence classification</a> (it’s what this notebook was built on).</li>
<li>For more on the concept of padding and truncation in sequence processing, I’d recommend the <a href="https://huggingface.co/docs/transformers/en/pad_truncation">Hugging Face padding and truncation guide</a>.</li>
<li>For more on Transformers (the architecture) as well as the DistilBert model:
<ul>
<li>Read <a href="https://peterbloem.nl/blog/transformers"><em>Transformers from scratch</em></a> by Peter Bloem.</li>
<li>Watch <a href="https://www.youtube.com/watch?v=XfpMkf4rD6E">Andrej Karpathy’s lecture on Transformers and their history</a>.</li>
<li>Read the original <a href="https://arxiv.org/abs/1706.03762"><em>Attention is all you need</em></a> paper (the paper that introduced the Transformer architecture).</li>
<li>Read the <a href="https://arxiv.org/abs/1910.01108"><em>DistilBert paper</em></a> from the Hugging Face team (paper that introduced the DistilBert architecture and training setup).</li>
</ul></li>
</ul>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"016181d9f51a4abea666046fb95f2aee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f82250d2e14f198dd0f561969d54ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0233456210f8469f85e648ba1c1f83ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2afc2c8167ad4d15ab6a35c1d1f1f3cb","max":152322,"min":0,"orientation":"horizontal","style":"IPY_MODEL_070785d29788406db9369ce39e24b7cf","value":152322}},"054e759a27a442afa8c666fc3d4c3f2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0673f25c77b04212bc2b63f56454a5d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"070785d29788406db9369ce39e24b7cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eaf7b7abd71413597e0533efa3feda2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c56c3c1ff2a040b0952b5bac655b71dc","placeholder":"​","style":"IPY_MODEL_3d5b841a59a3489ea5b4112182d4ae70","value":" 48.0/48.0 [00:00&lt;00:00, 3.86kB/s]"}},"103ff0dd04da40a69d85763bbf571490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13b1494b02194773a5fafe39b211c88a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1aa8fdd087ce42bdb16ae19a38e79b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ef815be4ac4b64b3b3d99a6c43fadb","placeholder":"​","style":"IPY_MODEL_d1cc110825034545a2532fc567b5325e","value":" 232k/232k [00:00&lt;00:00, 3.49MB/s]"}},"1b61ce44fb554db2bb906fb39b41b7e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5d45fa6fb14097bf36584ec7ef651c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ccbc146f4ad4382879b5d8b526cac4e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fda99413adc8497cba92a9c6416f77ad","value":231508}},"20a883d10ea945a9889429c5efb76a43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2afc2c8167ad4d15ab6a35c1d1f1f3cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cb043cfb0fc448e81a34710d65bb691":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f44328dc8a04f84a59e26d08d343c77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31cf1f106af54f7986b4d2f462125cca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_506baa608274455eae12e54e1d7b7dd5","placeholder":"​","style":"IPY_MODEL_103ff0dd04da40a69d85763bbf571490","value":"vocab.txt: 100%"}},"347ce846f3564c58ac1eb26ae2f3adc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a20bdb762700449097d5010ce7d29921","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cb043cfb0fc448e81a34710d65bb691","value":4203}},"34edb9945bb54a69868d62ecd5b1ae56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35205e647f814b97a2e977af48cc7a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8580f622bac8422a992b56b5f39b3693","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca74fdefa7844f11b1d9052269efd585","value":48}},"37cede645a5b48a9b89df987b9ef91e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39f3c0ec5b4446cda93df7a999d4fd41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5b841a59a3489ea5b4112182d4ae70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"470f2248b2444869914197c7481e10ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e1a02cf71743ec9da128ff6c882f34","placeholder":"​","style":"IPY_MODEL_6429d7801ba14ed4861726bd7832ecee","value":"config.json: 100%"}},"495cd338f7614f7a9a68fc3dc3916dcf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b6f81607c31496a83d5964983fed168":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c92f17cff2944a9a2a49be56649d81e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df9f85ae9e943ceb3ed1a5d9e143f5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ef091cf8c084af1acb95d62ffe1f0f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_495cd338f7614f7a9a68fc3dc3916dcf","placeholder":"​","style":"IPY_MODEL_dc17c88c62244e2f9a574ef895132a83","value":"tokenizer_config.json: 100%"}},"4ef76858d67f4ee6a99b305edb682a43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8713c60a0947ae86ee9d1d4de8ab3a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"506baa608274455eae12e54e1d7b7dd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"522f6c1e5e7340039b7bbf700704699f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6294e85e97a8495bb18d11dff1991a79","placeholder":"​","style":"IPY_MODEL_91ee20aae0474a4c90a26463f72bacf1","value":" 30465/30465 [00:00&lt;00:00, 31103.17 examples/s]"}},"54e1a02cf71743ec9da128ff6c882f34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5616046a1d1347cfbbe82fa67b79af1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"593b4aaa5c9e4e1898cc4d5064940770":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1fd51b695b4c81ab351ed5b1f92966":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e84d7134b646f6b291b0439d9ec890":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6294e85e97a8495bb18d11dff1991a79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e64e93abca400293b7b7742bd94aaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b791095b95214d82af1e344a2b5898a2","placeholder":"​","style":"IPY_MODEL_a3fa870efa0f4463b1e60fa106f782f1","value":" 268M/268M [00:01&lt;00:00, 287MB/s]"}},"6429d7801ba14ed4861726bd7832ecee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64513b9e43254d5a9bbbffc9cb9a054c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a7b459551104d47a90527c885647830":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8713c60a0947ae86ee9d1d4de8ab3a","placeholder":"​","style":"IPY_MODEL_4b6f81607c31496a83d5964983fed168","value":" 483/483 [00:00&lt;00:00, 39.6kB/s]"}},"6cdf8319c7184ee5b107cea1718b03c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ef091cf8c084af1acb95d62ffe1f0f2","IPY_MODEL_35205e647f814b97a2e977af48cc7a17","IPY_MODEL_0eaf7b7abd71413597e0533efa3feda2"],"layout":"IPY_MODEL_34edb9945bb54a69868d62ecd5b1ae56"}},"72df691ec7784ae7b0542171a7789555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f3c0ec5b4446cda93df7a999d4fd41","placeholder":"​","style":"IPY_MODEL_bb7f6dabc3ad4779a87b211227040606","value":" 466k/466k [00:00&lt;00:00, 2.36MB/s]"}},"79144b8d1ec44b6bb3dcc381f7e829ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b91cb6b9b5e4ba891a6cfaab2d5948b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80995fb6ed6f4557b1037dea2798b2fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb256ba48acd446bbe6b832c9558f7c6","placeholder":"​","style":"IPY_MODEL_4ef76858d67f4ee6a99b305edb682a43","value":" 121857/121857 [00:04&lt;00:00, 25895.88 examples/s]"}},"80ef815be4ac4b64b3b3d99a6c43fadb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8580f622bac8422a992b56b5f39b3693":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c3f85da75764955a572261460db619b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2f32fe9433d458dbc278da438f27449","max":121857,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64513b9e43254d5a9bbbffc9cb9a054c","value":121857}},"8fc36b3359d24eb987c4be9eaf5d4e95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b2772488464e80b333332d6cd46eeb","placeholder":"​","style":"IPY_MODEL_5616046a1d1347cfbbe82fa67b79af1a","value":"model.safetensors: 100%"}},"90455578408b4f33bc9a9c732d431236":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2e056a63fd34329a21330a4fc69429d","IPY_MODEL_347ce846f3564c58ac1eb26ae2f3adc4","IPY_MODEL_9a01bb7c8f5e4940ba2444fa63a3db6f"],"layout":"IPY_MODEL_b8beefe086284c7297004fcad9303617"}},"91ee20aae0474a4c90a26463f72bacf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9455512d944c418b87e4d1fe324619e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b93a51136d1146e08914db125d0259fb","IPY_MODEL_c74948f6d29e4e0e868a3ccf836d2377","IPY_MODEL_522f6c1e5e7340039b7bbf700704699f"],"layout":"IPY_MODEL_0673f25c77b04212bc2b63f56454a5d2"}},"985174675f354a9bb2580a70ad2b7625":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9e83e2c1d2f4970a0905efde0055e3d","IPY_MODEL_8c3f85da75764955a572261460db619b","IPY_MODEL_80995fb6ed6f4557b1037dea2798b2fb"],"layout":"IPY_MODEL_016181d9f51a4abea666046fb95f2aee"}},"9a01bb7c8f5e4940ba2444fa63a3db6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8d8eac2274a4040a4163663896753f7","placeholder":"​","style":"IPY_MODEL_01f82250d2e14f198dd0f561969d54ff","value":" 4.20k/4.20k [00:00&lt;00:00, 379kB/s]"}},"9ccbc146f4ad4382879b5d8b526cac4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20bdb762700449097d5010ce7d29921":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2e056a63fd34329a21330a4fc69429d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_593b4aaa5c9e4e1898cc4d5064940770","placeholder":"​","style":"IPY_MODEL_4df9f85ae9e943ceb3ed1a5d9e143f5c","value":"Downloading builder script: 100%"}},"a3fa870efa0f4463b1e60fa106f782f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5076ac1d4ad4c09aa1e6f12449915af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae6d2d013c03448887d53f8a0760e77d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6c20dee590f40e5b2c96beefc1643e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6cb26e5df334ac980005863a38581a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b791095b95214d82af1e344a2b5898a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8beefe086284c7297004fcad9303617":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d8eac2274a4040a4163663896753f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93a51136d1146e08914db125d0259fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_054e759a27a442afa8c666fc3d4c3f2e","placeholder":"​","style":"IPY_MODEL_e4633e912a57492497bc2fbfad02351c","value":"Map: 100%"}},"b9e83e2c1d2f4970a0905efde0055e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1fd51b695b4c81ab351ed5b1f92966","placeholder":"​","style":"IPY_MODEL_a5076ac1d4ad4c09aa1e6f12449915af","value":"Map: 100%"}},"bb7f6dabc3ad4779a87b211227040606":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb76be168f840d79c950efc4bdfc8d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8d378a142934482aa04a608ada9acdb","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6c20dee590f40e5b2c96beefc1643e1","value":267954768}},"c0028b925edf40ecb94ee219a26dfe36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6cb26e5df334ac980005863a38581a1","placeholder":"​","style":"IPY_MODEL_ae6d2d013c03448887d53f8a0760e77d","value":" 152322/152322 [00:06&lt;00:00, 24189.50 examples/s]"}},"c3faf065f2d2435697fb730bf04ff1cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fc36b3359d24eb987c4be9eaf5d4e95","IPY_MODEL_beb76be168f840d79c950efc4bdfc8d1","IPY_MODEL_63e64e93abca400293b7b7742bd94aaf"],"layout":"IPY_MODEL_d41ef095cc5b4c23b31236b501dcf8c1"}},"c4055bbdeb6c4833b4fb50970248a154":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31cf1f106af54f7986b4d2f462125cca","IPY_MODEL_1c5d45fa6fb14097bf36584ec7ef651c","IPY_MODEL_1aa8fdd087ce42bdb16ae19a38e79b27"],"layout":"IPY_MODEL_ef3b72dea05d404db610152cb17ba8f9"}},"c45933bed8084b53b562621699870695":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37cede645a5b48a9b89df987b9ef91e2","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13b1494b02194773a5fafe39b211c88a","value":466062}},"c56c3c1ff2a040b0952b5bac655b71dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6cbefbc4f4d4cfe98400aa05370e3e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0c86013f8194633be0ac27ca9b8876c","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b91cb6b9b5e4ba891a6cfaab2d5948b","value":483}},"c74948f6d29e4e0e868a3ccf836d2377":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79144b8d1ec44b6bb3dcc381f7e829ce","max":30465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60e84d7134b646f6b291b0439d9ec890","value":30465}},"ca74fdefa7844f11b1d9052269efd585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca79aac952ca41c096241ad371c055fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b61ce44fb554db2bb906fb39b41b7e0","placeholder":"​","style":"IPY_MODEL_dcc6949983954dfb9b7f8bd0ad6cd6d8","value":"Map: 100%"}},"cf51cae23d2b4026a4f890069983da4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca79aac952ca41c096241ad371c055fe","IPY_MODEL_0233456210f8469f85e648ba1c1f83ff","IPY_MODEL_c0028b925edf40ecb94ee219a26dfe36"],"layout":"IPY_MODEL_d4a7a1f7a10040ccb07704d845de6cd6"}},"d0080133b35c40578eba5db18dc82db6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0c86013f8194633be0ac27ca9b8876c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1cc110825034545a2532fc567b5325e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d41ef095cc5b4c23b31236b501dcf8c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a7a1f7a10040ccb07704d845de6cd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6b2772488464e80b333332d6cd46eeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc17c88c62244e2f9a574ef895132a83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcc6949983954dfb9b7f8bd0ad6cd6d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2f32fe9433d458dbc278da438f27449":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4633e912a57492497bc2fbfad02351c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb256ba48acd446bbe6b832c9558f7c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec74087b5c9d4e538675956af72ae138":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe87ce116db84d5ba3d00e4a8c249dc1","IPY_MODEL_c45933bed8084b53b562621699870695","IPY_MODEL_72df691ec7784ae7b0542171a7789555"],"layout":"IPY_MODEL_4c92f17cff2944a9a2a49be56649d81e"}},"ef3b72dea05d404db610152cb17ba8f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1fa4e09b42c4904b9be033d33943e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_470f2248b2444869914197c7481e10ae","IPY_MODEL_c6cbefbc4f4d4cfe98400aa05370e3e7","IPY_MODEL_6a7b459551104d47a90527c885647830"],"layout":"IPY_MODEL_d0080133b35c40578eba5db18dc82db6"}},"f8d378a142934482aa04a608ada9acdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda99413adc8497cba92a9c6416f77ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe87ce116db84d5ba3d00e4a8c249dc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a883d10ea945a9889429c5efb76a43","placeholder":"​","style":"IPY_MODEL_2f44328dc8a04f84a59e26d08d343c77","value":"tokenizer.json: 100%"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrdbourke\.github\.io\/learn-huggingface\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>