<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Learn Hugging Face ü§ó - Text Classification with Hugging Face Transformers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Learn Hugging Face ü§ó</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Natural Language Processing (NLP)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/hugging_face_text_classification_tutorial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Text Classification (work in progress)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tk---overview" id="toc-tk---overview" class="nav-link active" data-scroll-target="#tk---overview"><span class="header-section-number">1</span> TK - Overview</a>
  <ul class="collapse">
  <li><a href="#tk---what-were-going-to-build" id="toc-tk---what-were-going-to-build" class="nav-link" data-scroll-target="#tk---what-were-going-to-build"><span class="header-section-number">1.1</span> TK - What we‚Äôre going to build</a></li>
  <li><a href="#tk---what-is-hugging-face" id="toc-tk---what-is-hugging-face" class="nav-link" data-scroll-target="#tk---what-is-hugging-face"><span class="header-section-number">1.2</span> TK - What is Hugging Face?</a></li>
  <li><a href="#tk---why-hugging-face" id="toc-tk---why-hugging-face" class="nav-link" data-scroll-target="#tk---why-hugging-face"><span class="header-section-number">1.3</span> TK - Why Hugging Face?</a></li>
  <li><a href="#tk---what-is-text-classification" id="toc-tk---what-is-text-classification" class="nav-link" data-scroll-target="#tk---what-is-text-classification"><span class="header-section-number">1.4</span> TK - What is text classification?</a></li>
  <li><a href="#tk---why-train-your-own-text-classification-models" id="toc-tk---why-train-your-own-text-classification-models" class="nav-link" data-scroll-target="#tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.5</span> TK - Why train your own text classification models?</a></li>
  </ul></li>
  <li><a href="#tk---importing-necessary-libraries" id="toc-tk---importing-necessary-libraries" class="nav-link" data-scroll-target="#tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</a></li>
  <li><a href="#tk---getting-a-dataset" id="toc-tk---getting-a-dataset" class="nav-link" data-scroll-target="#tk---getting-a-dataset"><span class="header-section-number">3</span> TK - Getting a dataset</a>
  <ul class="collapse">
  <li><a href="#where-can-you-get-more-datasets" id="toc-where-can-you-get-more-datasets" class="nav-link" data-scroll-target="#where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</a></li>
  <li><a href="#loading-the-dataset" id="toc-loading-the-dataset" class="nav-link" data-scroll-target="#loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</a></li>
  <li><a href="#tk---inspect-random-examples-from-the-dataset" id="toc-tk---inspect-random-examples-from-the-dataset" class="nav-link" data-scroll-target="#tk---inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> TK - Inspect random examples from the dataset</a></li>
  </ul></li>
  <li><a href="#tk---preparing-data-for-text-classification" id="toc-tk---preparing-data-for-text-classification" class="nav-link" data-scroll-target="#tk---preparing-data-for-text-classification"><span class="header-section-number">4</span> TK - Preparing data for text classification</a>
  <ul class="collapse">
  <li><a href="#tk---split-the-dataset-into-training-and-test-sets" id="toc-tk---split-the-dataset-into-training-and-test-sets" class="nav-link" data-scroll-target="#tk---split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.1</span> TK - Split the dataset into training and test sets</a></li>
  <li><a href="#tk---tokenizing-text-data" id="toc-tk---tokenizing-text-data" class="nav-link" data-scroll-target="#tk---tokenizing-text-data"><span class="header-section-number">4.2</span> TK - Tokenizing text data</a></li>
  <li><a href="#tk---make-sure-all-text-is-the-same-length" id="toc-tk---make-sure-all-text-is-the-same-length" class="nav-link" data-scroll-target="#tk---make-sure-all-text-is-the-same-length"><span class="header-section-number">4.3</span> TK - Make sure all text is the same length</a></li>
  </ul></li>
  <li><a href="#tk---setup-evaluation-metric" id="toc-tk---setup-evaluation-metric" class="nav-link" data-scroll-target="#tk---setup-evaluation-metric"><span class="header-section-number">5</span> TK - Setup Evaluation Metric</a></li>
  <li><a href="#tk---training-our-model" id="toc-tk---training-our-model" class="nav-link" data-scroll-target="#tk---training-our-model"><span class="header-section-number">6</span> TK - Training our model</a>
  <ul class="collapse">
  <li><a href="#tk---create-a-directory-for-saving-models" id="toc-tk---create-a-directory-for-saving-models" class="nav-link" data-scroll-target="#tk---create-a-directory-for-saving-models"><span class="header-section-number">6.1</span> TK - Create a directory for saving models</a></li>
  <li><a href="#tk---setup-training-arguments" id="toc-tk---setup-training-arguments" class="nav-link" data-scroll-target="#tk---setup-training-arguments"><span class="header-section-number">6.2</span> TK - Setup training arguments</a></li>
  <li><a href="#tk---setup-trainer-class" id="toc-tk---setup-trainer-class" class="nav-link" data-scroll-target="#tk---setup-trainer-class"><span class="header-section-number">6.3</span> TK - Setup trainer class</a></li>
  <li><a href="#tk---train-the-model" id="toc-tk---train-the-model" class="nav-link" data-scroll-target="#tk---train-the-model"><span class="header-section-number">6.4</span> TK - Train the model</a></li>
  <li><a href="#tk---inspect-the-model-results" id="toc-tk---inspect-the-model-results" class="nav-link" data-scroll-target="#tk---inspect-the-model-results"><span class="header-section-number">6.5</span> TK - Inspect the model results</a></li>
  <li><a href="#tk---save-the-model-for-later-use" id="toc-tk---save-the-model-for-later-use" class="nav-link" data-scroll-target="#tk---save-the-model-for-later-use"><span class="header-section-number">6.6</span> TK - Save the model for later use</a></li>
  <li><a href="#tk---push-the-model-to-hugging-face-hub" id="toc-tk---push-the-model-to-hugging-face-hub" class="nav-link" data-scroll-target="#tk---push-the-model-to-hugging-face-hub"><span class="header-section-number">6.7</span> TK - Push the model to Hugging Face Hub</a></li>
  <li><a href="#tk---make-and-evaluate-predictions-on-the-test-set" id="toc-tk---make-and-evaluate-predictions-on-the-test-set" class="nav-link" data-scroll-target="#tk---make-and-evaluate-predictions-on-the-test-set"><span class="header-section-number">6.8</span> TK - Make and evaluate predictions on the test set</a></li>
  </ul></li>
  <li><a href="#tk---make-and-inspect-predictions-on-new-text-data" id="toc-tk---make-and-inspect-predictions-on-new-text-data" class="nav-link" data-scroll-target="#tk---make-and-inspect-predictions-on-new-text-data"><span class="header-section-number">7</span> TK - Make and inspect predictions on new text data</a>
  <ul class="collapse">
  <li><a href="#tk---pipeline-mode" id="toc-tk---pipeline-mode" class="nav-link" data-scroll-target="#tk---pipeline-mode"><span class="header-section-number">7.1</span> TK - Pipeline mode</a></li>
  <li><a href="#tk---batch-prediction" id="toc-tk---batch-prediction" class="nav-link" data-scroll-target="#tk---batch-prediction"><span class="header-section-number">7.2</span> TK - Batch prediction</a></li>
  <li><a href="#tk---time-our-model-across-larger-sample-sizes" id="toc-tk---time-our-model-across-larger-sample-sizes" class="nav-link" data-scroll-target="#tk---time-our-model-across-larger-sample-sizes"><span class="header-section-number">7.3</span> TK - Time our model across larger sample sizes</a></li>
  <li><a href="#pytorch-mode" id="toc-pytorch-mode" class="nav-link" data-scroll-target="#pytorch-mode"><span class="header-section-number">7.4</span> PyTorch mode</a></li>
  </ul></li>
  <li><a href="#tk---turning-our-model-into-a-demo" id="toc-tk---turning-our-model-into-a-demo" class="nav-link" data-scroll-target="#tk---turning-our-model-into-a-demo"><span class="header-section-number">8</span> TK - Turning our model into a demo</a>
  <ul class="collapse">
  <li><a href="#tk---creating-a-simple-function-to-perform-inference" id="toc-tk---creating-a-simple-function-to-perform-inference" class="nav-link" data-scroll-target="#tk---creating-a-simple-function-to-perform-inference"><span class="header-section-number">8.1</span> TK - Creating a simple function to perform inference</a></li>
  <li><a href="#tk---uploadingrunning-the-demo" id="toc-tk---uploadingrunning-the-demo" class="nav-link" data-scroll-target="#tk---uploadingrunning-the-demo"><span class="header-section-number">8.2</span> TK - Uploading/running the demo</a></li>
  <li><a href="#tk---testing-the-live-demo" id="toc-tk---testing-the-live-demo" class="nav-link" data-scroll-target="#tk---testing-the-live-demo"><span class="header-section-number">8.3</span> TK - Testing the live demo</a></li>
  </ul></li>
  <li><a href="#tk---exercises-and-extensions" id="toc-tk---exercises-and-extensions" class="nav-link" data-scroll-target="#tk---exercises-and-extensions"><span class="header-section-number">9</span> TK - Exercises and Extensions</a></li>
  <li><a href="#tk---extra-resources" id="toc-tk---extra-resources" class="nav-link" data-scroll-target="#tk---extra-resources"><span class="header-section-number">10</span> TK - Extra resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Natural Language Processing (NLP)</a></li><li class="breadcrumb-item"><a href="../notebooks/hugging_face_text_classification_tutorial.html">Text Classification (work in progress)</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Text Classification with Hugging Face Transformers</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a target="_blank" href="https://colab.research.google.com/github/mrdbourke/learn-huggingface/blob/main/notebooks/hugging_face_text_classification_tutorial.ipynb"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"> </a></p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Next:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add tools used in this overview (e.g. overview of the project)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a small dataset with text generation, e.g. 50x spam/not_spam emails and train a classifier on it ‚úÖ</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see notebook: https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the dataset to Hugging Face Datasets ‚úÖ</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>   <span class="co"># Done, see dataset: https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a classifier on it ‚úÖ</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the model to the Hugging Face Model Hub ‚úÖ</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a with Gradio and test the model in the wild ‚úÖ </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="tk---overview" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="tk---overview"><span class="header-section-number">1</span> TK - Overview</h2>
<section id="tk---what-were-going-to-build" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="tk---what-were-going-to-build"><span class="header-section-number">1.1</span> TK - What we‚Äôre going to build</h3>
<p>In this project, we‚Äôre going to learn various aspects of the Hugging Face ecosystem whilst building a text classification model.</p>
<p>To keep things as practical as possible, we‚Äôre going to be bulding a <code>food</code>/<code>not_food</code> text classification model.</p>
<p>Given a piece of a text, our model will be able to predict if it‚Äôs about food or not.</p>
<p>This is the same kind of model I use in my own work on <a href="https://www.nutrify.app">Nutrify</a> (an app to help people learn about food).</p>
<p>More specifically, we‚Äôre going to follow the following steps:</p>
<ol type="1">
<li><strong>Problem defintion and dataset preparation</strong> - Getting a dataset/setting up the problem space.</li>
<li><strong>Finding, training and evaluating a model</strong> - Finding a text classification model suitable for our problem on Hugging Face and customizing it to our own dataset.</li>
<li><strong>Creating a demo and put our model into the real world</strong> - Sharing our trained model in a way others can access and use.</li>
</ol>
<p>By the end of this project, you‚Äôll have a trained model and <a href="https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo">demo on Hugging Face</a> you can share with others.</p>
<p>TK image - see the finished product (demo)</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note this is a hands-on project, so we‚Äôll be focused on writing reusable code and building a model that can be used in the real world. If you are looking for explainers to the theory of what we‚Äôre doing, I‚Äôll leave links in the extra-curriculum section.</p>
</div>
</div>
</section>
<section id="tk---what-is-hugging-face" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="tk---what-is-hugging-face"><span class="header-section-number">1.2</span> TK - What is Hugging Face?</h3>
<p>Hugging Face is a platform that offers access to many different kinds of open-source machine learning models and datasets.</p>
<p>They‚Äôre also the creators of the popular <code>transformers</code> library which is a Python-based library for working with pre-trained models as well as custom models and datasets.</p>
<p>If you‚Äôre getting into the world of AI and machine learning, you‚Äôre going to come across Hugging Face.</p>
</section>
<section id="tk---why-hugging-face" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="tk---why-hugging-face"><span class="header-section-number">1.3</span> TK - Why Hugging Face?</h3>
<p>Many of the biggest companies in the world use Hugging Face for their open-source machine learning projects including <a href="https://huggingface.co/apple">Apple</a>, <a href="https://huggingface.co/google">Google</a>, <a href="https://huggingface.co/facebook">Facebook</a> (Meta), <a href="https://huggingface.co/microsoft">Microsoft</a>, <a href="https://huggingface.co/openai">OpenAI</a>, <a href="https://huggingface.co/ByteDance">ByteDance</a> and more.</p>
<p>TK image - image of people using Hugging Face</p>
<p>Not only does Hugging Face make it so you can use state-of-the-art machine learning models such as <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1">Stable Diffusion</a> (for image generation) and <a href="https://huggingface.co/openai/whisper-large-v3">Whipser</a> (for audio transcription) easily, it also makes it so you can share your own models, datasets and resources.</p>
<p>Consider Hugging Face the homepage of your AI/machine learning profile.</p>
</section>
<section id="tk---what-is-text-classification" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="tk---what-is-text-classification"><span class="header-section-number">1.4</span> TK - What is text classification?</h3>
<p>Text classification is the process of assigning a category to a piece of text.</p>
<p>Where a category can be almost anything and a piece of text can be a word, phrase, sentence, paragraph or entire document.</p>
<p>TK image - example of text classification</p>
<p>Example text classification problems include:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Problem</strong></th>
<th><strong>Description</strong></th>
<th><strong>Problem Type</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Spam email detection</td>
<td>Is an email spam or not spam?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Sentiment analysis</td>
<td>Is a piece of text positive, negative or neutral?</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="odd">
<td>Language detection</td>
<td>What language is a piece of text written in?</td>
<td>Multi-class classification (one thing from many)</td>
</tr>
<tr class="even">
<td>Topic classification</td>
<td>What topic(s) does a news article belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
<tr class="odd">
<td>Hate speech detection</td>
<td>Is a comment hateful or not hateful?</td>
<td>Binary classification (one thing or another)</td>
</tr>
<tr class="even">
<td>Product categorization</td>
<td>What categories does a product belong to?</td>
<td>Multi-label classification (one or more things from many)</td>
</tr>
</tbody>
</table>
<p>There are several different kinds of models you can use for text classification.</p>
<p>And each will have its pros and cons depending on the problem you‚Äôre working on.</p>
<p>Example text classification models include:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Description</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Rule-based</td>
<td>Uses a set of rules to classify text (e.g.&nbsp;if text contains ‚Äúsad‚Äù -&gt; sentiment = low)</td>
<td>Simple, easy to understand</td>
<td>Requires manual creation of rules</td>
</tr>
<tr class="even">
<td><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Bag of Words</a></td>
<td>Counts the frequency of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn‚Äôt capture word order</td>
</tr>
<tr class="odd">
<td><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a></td>
<td>Weighs the importance of words in a piece of text</td>
<td>Simple, easy to understand</td>
<td>Doesn‚Äôt capture word order</td>
</tr>
<tr class="even">
<td>Deep learning-based models</td>
<td>Uses neural networks to learn patterns in text</td>
<td>Can learn complex patterns at scale</td>
<td>Can require large amounts of data/compute power to run, not as easy to understand (can be hard to debug)</td>
</tr>
</tbody>
</table>
<p>We‚Äôre going to use a deep learning model our case.</p>
<p>Why?</p>
<p>Because Hugging Face helps us do so.</p>
<p>And in most cases, with a large enough dataset, a deep learning model will often perform better than a rule-based or other model.</p>
</section>
<section id="tk---why-train-your-own-text-classification-models" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="tk---why-train-your-own-text-classification-models"><span class="header-section-number">1.5</span> TK - Why train your own text classification models?</h3>
<p>You can use pre-trained models for text classification as well as API-powered models and LLMs such as GPT-4 or Gemini.</p>
<p>However, it‚Äôs often a good idea to train your own text classification models for a few reasons:</p>
<ul>
<li>They can be much faster than API-powered models (since they‚Äôre running on your own hardware, this can save on costs and time).</li>
<li>They‚Äôre customized to your own data.</li>
<li>They don‚Äôt require you to send your data elsewhere (privacy).</li>
<li>If a service goes down, you‚Äôll still have access to your model (reliability).</li>
</ul>
<p>TK image - example of training your own model vs using an API-powered model</p>
</section>
</section>
<section id="tk---importing-necessary-libraries" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="tk---importing-necessary-libraries"><span class="header-section-number">2</span> TK - Importing necessary libraries</h2>
<p>Let‚Äôs get started!</p>
<p>First, we‚Äôll import the required libraries.</p>
<p>If you‚Äôre running on your local computer, be sure to check out the getting setup guide (tk - link to getting setup guide) to make sure you have everything you need.</p>
<p>If you‚Äôre using Google Colab, many of them the following libraries will be installed by default.</p>
<p>However, we‚Äôll have to install a few extras to get everything working.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you‚Äôre running on Google Colab, this notebook will work best with access to a GPU. To enable a GPU, go to <code>Runtime</code> ‚û°Ô∏è <code>Change runtime type</code> ‚û°Ô∏è <code>Hardware accelerator</code> ‚û°Ô∏è <code>GPU</code>.</p>
</div>
</div>
<p>We‚Äôll need to install the following libraries from the Hugging Face ecosystem:</p>
<ul>
<li><a href="https://huggingface.co/docs/transformers/en/installation"><code>transformers</code></a> - comes pre-installed on Google Colab but if you‚Äôre running on your local machine, you can install it via <code>pip install transformers</code>.</li>
<li><a href="https://huggingface.co/docs/datasets/installation"><code>datasets</code></a> - a library for accessing and manipulating datasets on and off the Hugging Face Hub, you can install it via <code>pip install datasets</code>.</li>
<li><a href="https://huggingface.co/docs/evaluate/installation"><code>evaluate</code></a> - a library for evaluating machine learning model performance with various metrics, you can install it via <code>pip install evaluate</code>.</li>
<li><a href="https://huggingface.co/docs/accelerate/basic_tutorials/install"><code>accelerate</code></a> - a library for training machine learning models faster, you can install it via <code>pip install accelerate</code>.</li>
<li><a href="https://www.gradio.app/guides/quickstart#installation"><code>gradio</code></a> - a library for creating interactive demos of machine learning models, you can install it via <code>pip install gradio</code>.</li>
</ul>
<p>We can also check the versions of our software with <code>package_name.__version__</code>.</p>
<div id="cell-9" class="cell" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-outputid="ccd72531-249d-402f-91b0-7b701b2dc7eb" data-scrolled="true" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install dependencies (this is mostly for Google Colab, as the other dependences are available by default in Colab)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ModuleNotFoundError</span>:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">!</span>pip install <span class="op">-</span>U datasets evaluate accelerate gradio <span class="co"># -U stands for "upgrade" so we'll get the latest version by default</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> datasets, evaluate, accelerate</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using transformers version: </span><span class="sc">{</span>transformers<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using datasets version: </span><span class="sc">{</span>datasets<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using torch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using transformers version: 4.40.2
Using datasets version: 2.19.1
Using torch version: 2.2.0+cu121</code></pre>
</div>
</div>
<p>Wonderful, as long as your versions are the same or higher to the versions above, you should be able to run the code below.</p>
</section>
<section id="tk---getting-a-dataset" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="tk---getting-a-dataset"><span class="header-section-number">3</span> TK - Getting a dataset</h2>
<p>Okay, now we‚Äôre got the required libraries, let‚Äôs get a dataset.</p>
<p>Getting a dataset is one of the most important things a machine learning project.</p>
<p>The dataset you often determines the type of model you use as well as the quality of the outputs of that model.</p>
<p>Meaning, if you have a high quality dataset, chances are, your future model could also have high quality outputs.</p>
<p>It also means if your dataset is of poor quality, your model will likely also have poor quality outputs.</p>
<p>For a text classificaiton problem, your dataset will likely come in the form of text (e.g.&nbsp;a paragraph, sentence or phrase) and a label (e.g.&nbsp;what category the text belongs to).</p>
<ul>
<li>TK image - showcase what a supervised dataset looks like (e.g.&nbsp;text and label, this can be the dataset we‚Äôve got on Hugging Face hub, showcase the different parts of the dataset as well including the name etc)</li>
</ul>
<p>In our case, our dataset comes in the form of a collection of synthetic image captions and their corresponding labels (food or not food).</p>
<p>This is a dataset I‚Äôve created earlier to help us practice building a text classification model.</p>
<p>You can find it on Hugging Face under the name <a href="https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions"><code>mrdbourke/learn_hf_food_not_food_image_captions</code></a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Resource
</div>
</div>
<div class="callout-body-container callout-body">
<p>See how the food/not_food image caption dataset was created in the (TK - add notebook link and title, make this available on the website)</p>
<ul>
<li>TK - see dataset creation:
<ul>
<li>Done, see notebook: https://colab.research.google.com/drive/14xr3KN_HINY5LjV0s2E-4i7v0o_XI3U8?usp=sharing</li>
<li>Done, see dataset: https://huggingface.co/datasets/mrdbourke/learn_hf_food_not_food_image_captions</li>
</ul></li>
</ul>
</div>
</div>
<section id="where-can-you-get-more-datasets" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="where-can-you-get-more-datasets"><span class="header-section-number">3.1</span> Where can you get more datasets?</h3>
<p>The are many different places you can get datasets for text-based problems.</p>
<p>One of the best places is on the Hugging Face Hub, specifically <a href="https://huggingface.co/datasets">huggingface.co/datasets</a>.</p>
<p>Here you can find many different kinds of problem specific data such as <a href="https://huggingface.co/datasets?task_categories=task_categories:text-classification&amp;sort=trending">text classification</a>.</p>
<p>TK image - show example image of text classification datasets</p>
</section>
<section id="loading-the-dataset" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="loading-the-dataset"><span class="header-section-number">3.2</span> Loading the dataset</h3>
<p>Once we‚Äôve found/prepared a dataset on the Hugging Face Hub, we can use the <code>datasets</code> library to load it.</p>
<p>To load a dataset we can use the <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/loading_methods#datasets.load_dataset"><code>datasets.load_dataset(path=NAME_OR_PATH_OF_DATASET)</code></a> function and pass it the name/path of the dataset we want to load.</p>
<p>In our case, our dataset name is <code>mrdbourke/learn_hf_food_not_food_image_captions</code>.</p>
<p>And since our dataset is hosted on Hugging Face, when we run the following code for the first time, it will download it.</p>
<p>If your target dataset is quite large, this download may take a while.</p>
<p>However, once the dataset is downloaded, subsequent reloads will be mush faster.</p>
<div id="cell-14" class="cell" data-outputid="2f45489c-02e8-4c03-bb7c-d73faa46c5b1" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset from Hugging Face Hub</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> datasets.load_dataset(path<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_image_captions"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the dataset</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 250
    })
})</code></pre>
</div>
</div>
<p>Dataset loaded!</p>
<p>Looks like our dataset has two features, <code>text</code> and <code>label</code>.</p>
<p>And 250 total rows (the number of examples in our dataset).</p>
<p>We can check the column names with <code>dataset.column_names</code>.</p>
<div id="cell-16" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What features are there?</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dataset.column_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>{'train': ['text', 'label']}</code></pre>
</div>
</div>
<p>Looks like our dataset comes with a <code>train</code> split already (the whole dataset).</p>
<p>We can access the <code>train</code> split with <code>dataset["train"]</code> (some datasets also come with built-in <code>"test"</code> splits too).</p>
<div id="cell-18" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the training split</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Dataset({
    features: ['text', 'label'],
    num_rows: 250
})</code></pre>
</div>
</div>
<p>How about we check out a single sample?</p>
<p>We can do so with indexing.</p>
<div id="cell-20" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>{'text': 'Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
 'label': 'food'}</code></pre>
</div>
</div>
<p>Nice! We get back a dictionary with the keys <code>text</code> and <code>label</code>.</p>
<p>The <code>text</code> key contains the text of the image caption and the <code>label</code> key contains the label (food or not food).</p>
</section>
<section id="tk---inspect-random-examples-from-the-dataset" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="tk---inspect-random-examples-from-the-dataset"><span class="header-section-number">3.3</span> TK - Inspect random examples from the dataset</h3>
<p>At 250 total samples, our dataset isn‚Äôt too large.</p>
<p>So we could sit there and explore the samples one by one.</p>
<p>But whenever I interact with a new dataset, I like to view a bunch of random examples and get a <em>feel</em> of the data.</p>
<p>Doing so is inline with the data explorer‚Äôs motto: <em>visualize, visualize, visualize!</em></p>
<p>As a rule of thumb, I like to view at least 20-100 random examples when interacting with a new dataset.</p>
<p>Let‚Äôs write some code to view 5 random indexes of our data and their corresponding text and labels at a time.</p>
<div id="cell-23" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>random_indexs <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset[<span class="st">"train"</span>])), <span class="dv">5</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>random_samples <span class="op">=</span> dataset[<span class="st">"train"</span>][random_indexs]</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random samples from dataset:</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> <span class="bu">zip</span>(random_samples[<span class="st">"text"</span>], random_samples[<span class="st">"label"</span>]):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>item[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> | Label: </span><span class="sc">{</span>item[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random samples from dataset:

Text: Set of knitting needles with yarn waiting to be knitted | Label: not_food
Text: A bowl of sliced pears with a sprinkle of ginger and a side of honey | Label: food
Text: Sweet and spicy sushi roll with ingredients like mango and jalapeno. | Label: food
Text: Vibrant red curry with tofu and bell peppers, featuring tofu and sweet bell peppers in a rich coconut milk sauce. | Label: food
Text: Lawn mower stored in a shed | Label: not_food</code></pre>
</div>
</div>
<p>Beautiful! Looks like our data contains a mix of shorter and longer sentences (between 5 and 20 words) of texts about food and not food.</p>
<p>We can get the unique labels in our dataset with <a href="https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.Dataset.unique"><code>dataset["train"].unique("label")</code></a>.</p>
<div id="cell-25" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get unique label values</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>].unique(<span class="st">"label"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>['food', 'not_food']</code></pre>
</div>
</div>
<p>If our dataset is small enough to fit into memory, we can count the number of different labels with Python‚Äôs <a href="https://docs.python.org/3/library/collections.html#counter-objects"><code>collections.Counter</code></a> (a method for counting objects in an iterable or mapping).</p>
<div id="cell-27" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check number of each label</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>Counter(dataset[<span class="st">"train"</span>][<span class="st">"label"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>Counter({'food': 125, 'not_food': 125})</code></pre>
</div>
</div>
<p>Excellent, looks like our dataset is well balanced with 125 samples of food and 125 samples of not food.</p>
<p>In a binary classification case, this is ideal.</p>
<p>If the classes were dramatically unbalanced (e.g.&nbsp;90% food and 10% not food) we might have to consider collecting/creating more data.</p>
<p>But best to train a model and see how it goes before making any drastic dataset changes.</p>
<p>Because our dataset is small, we could also inspect it via a pandas DataFrame (however, this may not be possible for extremely large datasets).</p>
<div id="cell-29" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn our dataset into a DataFrame and get a random sample</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df <span class="op">=</span> pd.DataFrame(dataset[<span class="st">"train"</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>food_not_food_df.sample(<span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">160</td>
<td>Set of speakers perched on a shelf</td>
<td>not_food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">91</td>
<td>Garage door with a remote control ready for use</td>
<td>not_food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">37</td>
<td>Guitar leaning casually against a couch</td>
<td>not_food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">151</td>
<td>Round wooden dining table with chairs gathered...</td>
<td>not_food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">199</td>
<td>Crunchy sushi roll with a creamy filling, feat...</td>
<td>food</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">116</td>
<td>A girl feeding her rabbit in the garden</td>
<td>not_food</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">109</td>
<td>Jicama in a bowl, sprinkled with chili powder ...</td>
<td>food</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-30" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the value counts of the label column</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>food_not_food_df[<span class="st">"label"</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>label
food        125
not_food    125
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
</section>
<section id="tk---preparing-data-for-text-classification" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="tk---preparing-data-for-text-classification"><span class="header-section-number">4</span> TK - Preparing data for text classification</h2>
<p>UPTOHERE</p>
<ul>
<li>There are many ways to get data ready for various machine learning tasks, see: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#preprocess</li>
</ul>
<div id="cell-32" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping from id2label and label2id</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>id2label <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"not_food"</span>, <span class="dv">1</span>: <span class="st">"food"</span>}</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>label2id <span class="op">=</span> {<span class="st">"not_food"</span>: <span class="dv">0</span>, <span class="st">"food"</span>: <span class="dv">1</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-33" class="cell" data-outputid="eba840c3-7652-41a8-a121-546cb9a8147f" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Turn labels into 0 or 1 (e.g. 0 for "not_food", 1 for "food"), see: https://huggingface.co/docs/datasets/en/process#map</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> map_labels_to_number(example):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  example[<span class="st">"label"</span>] <span class="op">=</span> label2id[example[<span class="st">"label"</span>]]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> example</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset[<span class="st">"train"</span>].<span class="bu">map</span>(map_labels_to_number)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>dataset[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>{'text': ['Creamy cauliflower curry with garlic naan, featuring tender cauliflower in a rich sauce with cream and spices, served with garlic naan bread.',
  'Set of books stacked on a desk',
  'Watching TV together, a family has their dog stretched out on the floor',
  'Wooden dresser with a mirror reflecting the room',
  'Lawn mower stored in a shed'],
 'label': [1, 0, 0, 0, 0]}</code></pre>
</div>
</div>
<div id="cell-34" class="cell" data-outputid="8089bfe3-2322-4bac-d2fd-89f626d0a1e6" data-execution_count="23">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>dataset.shuffle()[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>{'text': ["King-size bed with a white comforter inviting a good night's sleep",
  'A slice of pizza with a spicy kick, featuring jalapeno peppers',
  'Red brick fireplace with a mantel serving as a centerpiece',
  'Creamy spinach and potato curry, featuring fluffy potatoes and nutritious spinach in a rich sauce with cream and garam masala.',
  'Set of cookie cutters collected in a jar'],
 'label': [0, 1, 0, 1, 0]}</code></pre>
</div>
</div>
<section id="tk---split-the-dataset-into-training-and-test-sets" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="tk---split-the-dataset-into-training-and-test-sets"><span class="header-section-number">4.1</span> TK - Split the dataset into training and test sets</h3>
<div id="cell-36" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create train/test splits, see: https://huggingface.co/docs/datasets/en/process#split</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.train_test_split(test_size<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>) <span class="co"># note: seed isn't needed, just here for reproducibility, without it you will get different splits each time you run the cell</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 200
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 50
    })
})</code></pre>
</div>
</div>
<div id="cell-37" class="cell" data-outputid="35f0da00-ab15-42e0-9d81-757ad3da1618" data-execution_count="27">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>random_idx_train <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"train"</span>]))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>random_sample_train <span class="op">=</span> dataset[<span class="st">"train"</span>][random_idx_train]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>random_idx_test <span class="op">=</span> random.randint(<span class="dv">0</span>, <span class="bu">len</span>(dataset[<span class="st">"test"</span>]))</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>random_sample_test <span class="op">=</span> dataset[<span class="st">"test"</span>][random_idx_test]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from training dataset:"</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_train[<span class="st">'text'</span>]<span class="sc">}</span><span class="ss"> | Label: </span><span class="sc">{</span>random_sample_train[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_train[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Random sample from testing dataset:"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>random_sample_test[<span class="st">'text'</span>]<span class="sc">}</span><span class="ss"> | Label: </span><span class="sc">{</span>random_sample_test[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>id2label[random_sample_test[<span class="st">'label'</span>]]<span class="sc">}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Random sample from training dataset:
Text: Pizza with a unique topping combination of pineapple and ham | Label: 1 (food)

[INFO] Random sample from testing dataset:
Text: Tangy tomato curry with chicken, featuring tender chicken pieces in a zesty tomato-based sauce with onions and spices. | Label: 1 (food)</code></pre>
</div>
</div>
</section>
<section id="tk---tokenizing-text-data" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="tk---tokenizing-text-data"><span class="header-section-number">4.2</span> TK - Tokenizing text data</h3>
<ul>
<li>TK - what is tokenization? E.g. turning data from text to numbers (machines like numbers)</li>
<li>TK - see OpenAI guide on tokenization: https://openai.com/tokenization/</li>
</ul>
<div id="cell-39" class="cell" data-outputid="f277b622-267d-4d06-b2cb-6bc204b2f62d" data-execution_count="28">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"distilbert/distilbert-base-uncased"</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>], truncation<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/daniel/miniconda3/envs/ai/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(</code></pre>
</div>
</div>
<div id="cell-40" class="cell" data-outputid="d72b4325-b4de-4f65-f930-50007d45c8d5" data-execution_count="29">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>tokenized_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"35036ad022284cab965462c7c2591b2c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f64f1a5a4b1a45e699e488a9dafd61f9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 200
    })
    test: Dataset({
        features: ['text', 'label', 'input_ids', 'attention_mask'],
        num_rows: 50
    })
})</code></pre>
</div>
</div>
<div id="cell-41" class="cell" data-outputid="c1b0b958-b9a5-4274-e8c1-eaf0ac4cdf3a" data-execution_count="30">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>tokenized_dataset[<span class="st">"train"</span>][<span class="dv">0</span>], tokenized_dataset[<span class="st">"test"</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>({'text': 'Set of headphones placed on a desk',
  'label': 0,
  'input_ids': [101, 2275, 1997, 2132, 19093, 2872, 2006, 1037, 4624, 102],
  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},
 {'text': 'A slice of pepperoni pizza with a layer of melted cheese',
  'label': 1,
  'input_ids': [101,
   1037,
   14704,
   1997,
   11565,
   10698,
   10733,
   2007,
   1037,
   6741,
   1997,
   12501,
   8808,
   102],
  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})</code></pre>
</div>
</div>
</section>
<section id="tk---make-sure-all-text-is-the-same-length" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="tk---make-sure-all-text-is-the-same-length"><span class="header-section-number">4.3</span> TK - Make sure all text is the same length</h3>
<div id="cell-43" class="cell" data-outputid="1e3640b5-b13b-44d1-adae-1064deece079" data-execution_count="31">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Collate examples and pad them each batch</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - this is not 100% needed as the tokenizer can handle padding, but it's good to know how to do it</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> DataCollatorWithPadding</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>                                        padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>data_collator</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
    0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    100: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    101: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    102: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
    103: AddedToken("[MASK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')</code></pre>
</div>
</div>
</section>
</section>
<section id="tk---setup-evaluation-metric" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="tk---setup-evaluation-metric"><span class="header-section-number">5</span> TK - Setup Evaluation Metric</h2>
<ul>
<li>TK - What evaluation metrics are there?</li>
</ul>
<p>See: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#evaluate</p>
<div id="cell-45" class="cell" data-outputid="4a2b0f85-db47-4f0f-cbc3-fa148c19a646" data-execution_count="104">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> evaluate.load(<span class="st">"accuracy"</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  predictions, labels <span class="op">=</span> eval_pred</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  predictions <span class="op">=</span> np.argmax(predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> accuracy.compute(predictions<span class="op">=</span>predictions, references<span class="op">=</span>labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---training-our-model" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="tk---training-our-model"><span class="header-section-number">6</span> TK - Training our model</h2>
<p>See: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#train</p>
<p>Steps for training:</p>
<ol type="1">
<li>Define model</li>
<li>Define training arguments</li>
<li>Pass training arguments to Trainer</li>
<li>Call <code>train()</code></li>
</ol>
<ul>
<li>TK - What kind of training are we doing? Supervised learning + fine-tuning an existing model</li>
</ul>
<div id="cell-47" class="cell" data-outputid="ed01beb4-3cf7-4209-eaea-444e5aa51c5b" data-execution_count="42">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, Trainer, TrainingArguments</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    pretrained_model_name_or_path<span class="op">=</span><span class="st">"distilbert/distilbert-base-uncased"</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">2</span>, <span class="co"># can customize this to the number of classes in your dataset</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    id2label<span class="op">=</span>id2label,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    label2id<span class="op">=</span>label2id</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/daniel/miniconda3/envs/ai/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
</div>
<ul>
<li>TK - notice this output on pretraining advice</li>
</ul>
<blockquote class="blockquote">
<p>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: [‚Äòclassifier.bias‚Äô, ‚Äòclassifier.weight‚Äô, ‚Äòpre_classifier.bias‚Äô, ‚Äòpre_classifier.weight‚Äô] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p>
</blockquote>
<p>Let‚Äôs try and make a prediction with our model and see what happens.</p>
<div id="cell-49" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try and make a prediction with the loaded model (this will error)</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>model(<span class="op">**</span>tokenized_dataset[<span class="st">"train"</span>][:<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>TypeError: DistilBertForSequenceClassification.forward() got an unexpected keyword argument 'text'</code></pre>
</div>
</div>
<section id="tk---create-a-directory-for-saving-models" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="tk---create-a-directory-for-saving-models"><span class="header-section-number">6.1</span> TK - Create a directory for saving models</h3>
<div id="cell-51" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model output directory</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models directory</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>models_dir <span class="op">=</span> Path(<span class="st">"models"</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>models_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save name</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>model_save_name <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model save path</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>model_save_dir <span class="op">=</span> Path(models_dir, model_save_name)</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>model_save_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')</code></pre>
</div>
</div>
</section>
<section id="tk---setup-training-arguments" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="tk---setup-training-arguments"><span class="header-section-number">6.2</span> TK - Setup training arguments</h3>
<ul>
<li>TK - add markdown table of different parameters and what they do (e.g.&nbsp;most of the common ones but add a note that these may want to be changed depending on the problem + there are many more in the docs)</li>
</ul>
<div id="cell-53" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training arguments</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See: https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.TrainingArguments</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Turn off Weights &amp; Biases logging? Or add it in?</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - exercise: spend 10 minutes reading the TrainingArguments documentation</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>model_save_dir, <span class="co"># </span><span class="al">TODO</span><span class="co">: change this path to model save path, e.g. 'learn_hf_food_not_food_text_classifier_model' </span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>, <span class="co"># load the best model when finished training</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    logging_strategy<span class="op">=</span><span class="st">"epoch"</span>, <span class="co"># log training results every epoch</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span> <span class="co"># optional: log experiments to Weights &amp; Biases/other similar experimenting tracking services (we'll turn this off for now) </span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># push_to_hub=True # optional: automatically upload the model to the Hub (we'll do this manually later on)</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># hub_token="your_token_here" # optional: add your Hugging Face Hub token to push to the Hub (will default to huggingface-cli login)</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---setup-trainer-class" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="tk---setup-trainer-class"><span class="header-section-number">6.3</span> TK - Setup trainer class</h3>
<div id="cell-55" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Trainer</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: Trainer applies dynamic padding by default when you pass `tokenizer` to it.</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case, you don't need to specify a data collator explicitly.</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"train"</span>],</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_dataset[<span class="st">"test"</span>],</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#data_collator=data_collator, # not necessary if using pre-built tokenizer padding (default)</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---train-the-model" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="tk---train-the-model"><span class="header-section-number">6.4</span> TK - Train the model</h3>
<div id="cell-57" class="cell" data-outputid="22937d9f-a794-4579-bc67-70ba6cb05dcd" data-execution_count="47">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="70" max="70" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [70/70 00:06, Epoch 10/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.615200</td>
<td>0.450918</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.405600</td>
<td>0.257541</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.219900</td>
<td>0.123121</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.108100</td>
<td>0.062602</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.056800</td>
<td>0.036242</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.035900</td>
<td>0.025235</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.026700</td>
<td>0.019986</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.021900</td>
<td>0.017336</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>9</td>
<td>0.019400</td>
<td>0.016042</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.018200</td>
<td>0.015633</td>
<td>1.000000</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
</section>
<section id="tk---inspect-the-model-results" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="tk---inspect-the-model-results"><span class="header-section-number">6.5</span> TK - Inspect the model results</h3>
<div id="cell-59" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - go through these</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>total_train_time <span class="op">=</span> results.metrics[<span class="st">"train_runtime"</span>]</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>train_samples_per_second <span class="op">=</span> results.metrics[<span class="st">"train_samples_per_second"</span>]</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total training time: </span><span class="sc">{</span>total_train_time<span class="sc">}</span><span class="ss"> seconds"</span>)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training samples per second: </span><span class="sc">{</span>train_samples_per_second<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total training time: 6.7168 seconds
Training samples per second: 297.761</code></pre>
</div>
</div>
<div id="cell-60" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - get loss curves</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>trainer_history <span class="op">=</span> trainer.state.log_history[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>trainer_training_time <span class="op">=</span> trainer_history[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>trainer_history[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>[{'loss': 0.6152,
  'grad_norm': 3.3377952575683594,
  'learning_rate': 1.8e-05,
  'epoch': 1.0,
  'step': 7},
 {'eval_loss': 0.45091766119003296,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0113,
  'eval_samples_per_second': 4423.998,
  'eval_steps_per_second': 176.96,
  'epoch': 1.0,
  'step': 7},
 {'loss': 0.4056,
  'grad_norm': 2.4789676666259766,
  'learning_rate': 1.6000000000000003e-05,
  'epoch': 2.0,
  'step': 14},
 {'eval_loss': 0.25754112005233765,
  'eval_accuracy': 1.0,
  'eval_runtime': 0.0124,
  'eval_samples_per_second': 4023.931,
  'eval_steps_per_second': 160.957,
  'epoch': 2.0,
  'step': 14},
 {'loss': 0.2199,
  'grad_norm': 1.6385667324066162,
  'learning_rate': 1.4e-05,
  'epoch': 3.0,
  'step': 21}]</code></pre>
</div>
</div>
<div id="cell-61" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract training and evaluation metrics</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>trainer_history_training_set <span class="op">=</span> []</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_set <span class="op">=</span> []</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> trainer_history[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    item_keys <span class="op">=</span> <span class="bu">list</span>(item.keys())</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">any</span>(<span class="st">"eval"</span> <span class="kw">in</span> item <span class="cf">for</span> item <span class="kw">in</span> item_keys):</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>        trainer_history_eval_set.append(item)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>        trainer_history_training_set.append(item)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-62" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df <span class="op">=</span> pd.DataFrame(trainer_history_training_set)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df <span class="op">=</span> pd.DataFrame(trainer_history_eval_set)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>trainer_history_training_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">grad_norm</th>
<th data-quarto-table-cell-role="th">learning_rate</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.6152</td>
<td>3.337795</td>
<td>0.000018</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.4056</td>
<td>2.478968</td>
<td>0.000016</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.2199</td>
<td>1.638567</td>
<td>0.000014</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.1081</td>
<td>0.902428</td>
<td>0.000012</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.0568</td>
<td>0.546689</td>
<td>0.000010</td>
<td>5.0</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.0359</td>
<td>0.347724</td>
<td>0.000008</td>
<td>6.0</td>
<td>42</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.0267</td>
<td>0.309794</td>
<td>0.000006</td>
<td>7.0</td>
<td>49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0.0219</td>
<td>0.273363</td>
<td>0.000004</td>
<td>8.0</td>
<td>56</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.0194</td>
<td>0.244860</td>
<td>0.000002</td>
<td>9.0</td>
<td>63</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>0.0182</td>
<td>0.245236</td>
<td>0.000000</td>
<td>10.0</td>
<td>70</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-63" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>trainer_history_eval_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">eval_loss</th>
<th data-quarto-table-cell-role="th">eval_accuracy</th>
<th data-quarto-table-cell-role="th">eval_runtime</th>
<th data-quarto-table-cell-role="th">eval_samples_per_second</th>
<th data-quarto-table-cell-role="th">eval_steps_per_second</th>
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">step</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.450918</td>
<td>1.0</td>
<td>0.0113</td>
<td>4423.998</td>
<td>176.960</td>
<td>1.0</td>
<td>7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.257541</td>
<td>1.0</td>
<td>0.0124</td>
<td>4023.931</td>
<td>160.957</td>
<td>2.0</td>
<td>14</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.123121</td>
<td>1.0</td>
<td>0.0115</td>
<td>4338.068</td>
<td>173.523</td>
<td>3.0</td>
<td>21</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.062602</td>
<td>1.0</td>
<td>0.0115</td>
<td>4349.855</td>
<td>173.994</td>
<td>4.0</td>
<td>28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.036242</td>
<td>1.0</td>
<td>0.0112</td>
<td>4448.585</td>
<td>177.943</td>
<td>5.0</td>
<td>35</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0.025235</td>
<td>1.0</td>
<td>0.0122</td>
<td>4100.485</td>
<td>164.019</td>
<td>6.0</td>
<td>42</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.019986</td>
<td>1.0</td>
<td>0.0116</td>
<td>4327.147</td>
<td>173.086</td>
<td>7.0</td>
<td>49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0.017336</td>
<td>1.0</td>
<td>0.0113</td>
<td>4406.522</td>
<td>176.261</td>
<td>8.0</td>
<td>56</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.016042</td>
<td>1.0</td>
<td>0.0116</td>
<td>4315.128</td>
<td>172.605</td>
<td>9.0</td>
<td>63</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-64" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training and evaluation loss</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_training_df[<span class="st">"epoch"</span>], trainer_history_training_df[<span class="st">"loss"</span>], label<span class="op">=</span><span class="st">"Training loss"</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>plt.plot(trainer_history_eval_df[<span class="st">"epoch"</span>], trainer_history_eval_df[<span class="st">"eval_loss"</span>], label<span class="op">=</span><span class="st">"Evaluation loss"</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Training and evaluation loss over time"</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hugging_face_text_classification_tutorial_files/figure-html/cell-34-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="tk---save-the-model-for-later-use" class="level3" data-number="6.6">
<h3 data-number="6.6" class="anchored" data-anchor-id="tk---save-the-model-for-later-use"><span class="header-section-number">6.6</span> TK - Save the model for later use</h3>
<div id="cell-66" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save model</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See docs: https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.save_model </span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>trainer.save_model(model_save_dir)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tk---push-the-model-to-hugging-face-hub" class="level3" data-number="6.7">
<h3 data-number="6.7" class="anchored" data-anchor-id="tk---push-the-model-to-hugging-face-hub"><span class="header-section-number">6.7</span> TK - Push the model to Hugging Face Hub</h3>
<p>TK - optional to share the model/use elsewhere</p>
<ul>
<li>see here: https://huggingface.co/docs/transformers/en/model_sharing</li>
<li>also see here for how to setup <code>huggingface-cli</code> so you can write your model to your account</li>
</ul>
<div id="cell-68" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - have a note here for the errors</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: you may see the following error</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 403 Forbidden: You don't have the rights to create a model under the namespace "mrdbourke".</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cannot access content at: https://huggingface.co/api/repos/create.</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are trying to create or update content,make sure you have a token with the `write` role.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-69" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - Push model to hub (for later re-use)</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Push this model to the hub to be able to use it later</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - this requires a "write" token from the Hugging Face Hub</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - see docs: https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.Trainer.push_to_hub </span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - for example, on my local computer, my token is saved to: "/home/daniel/.cache/huggingface/token"</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - Can create a model card with create_model_card()</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co"># see here: https://huggingface.co/docs/transformers/v4.41.3/en/main_classes/trainer#transformers.Trainer.create_model_card </span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>trainer.push_to_hub(</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier model"</span> <span class="co"># set to False if you want the model to be public</span></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># token="YOUR_HF_TOKEN_HERE" # note: this will default to the token you have saved in your Hugging Face config</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>CommitInfo(commit_url='https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased/commit/7c9a4a6b17da981559f484538d51f6ff9a14c12d', commit_message='Uploading food not food text classifier model', commit_description='', oid='7c9a4a6b17da981559f484538d51f6ff9a14c12d', pr_url=None, pr_revision=None, pr_num=None)</code></pre>
</div>
</div>
<ul>
<li>TK - note: this will make the model public, to make it private,</li>
</ul>
<p>See the model here saved for later: https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased</p>
</section>
<section id="tk---make-and-evaluate-predictions-on-the-test-set" class="level3" data-number="6.8">
<h3 data-number="6.8" class="anchored" data-anchor-id="tk---make-and-evaluate-predictions-on-the-test-set"><span class="header-section-number">6.8</span> TK - Make and evaluate predictions on the test set</h3>
<div id="cell-72" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform predictions on the test set</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>predictions_all <span class="op">=</span> trainer.predict(tokenized_dataset[<span class="st">"test"</span>])</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>prediction_metrics <span class="op">=</span> predictions_all.metrics</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>prediction_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>{'test_loss': 0.015632618218660355,
 'test_accuracy': 1.0,
 'test_runtime': 0.0391,
 'test_samples_per_second': 1280.07,
 'test_steps_per_second': 51.203}</code></pre>
</div>
</div>
<div id="cell-73" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>predictions_all</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>PredictionOutput(predictions=array([[-2.261428 ,  1.890655 ],
       [ 1.8613493, -1.8532594],
       [-2.2970695,  1.9171791],
       [ 2.187019 , -2.1593657],
       [ 2.1193414, -2.1615388],
       [-2.2868803,  1.9454829],
       [ 2.0827348, -2.1099336],
       [ 2.154141 , -2.1266923],
       [-2.279855 ,  1.9362432],
       [-2.277952 ,  1.9518106],
       [-2.2772808,  1.9423369],
       [-1.9777709,  1.5732591],
       [ 2.1512635, -2.0508409],
       [-2.3032587,  1.9534686],
       [-2.138177 ,  1.7531359],
       [ 2.194142 , -2.1277084],
       [-2.2709608,  1.9498663],
       [ 1.9596925, -1.919577 ],
       [-2.2827635,  1.9249418],
       [-2.290854 ,  1.9592198],
       [-2.2823153,  1.8799024],
       [-2.3003585,  1.9387653],
       [ 2.043029 , -2.0384376],
       [ 2.0885575, -2.1244206],
       [-2.2873669,  1.9443382],
       [-2.2972584,  1.9009027],
       [-2.2450745,  1.8596792],
       [ 2.1050394, -2.040059 ],
       [-2.2972147,  1.8946056],
       [ 2.130832 , -2.133735 ],
       [-2.2846339,  1.9422101],
       [-2.2931519,  1.9279182],
       [-2.3040657,  1.9485677],
       [ 2.1816792, -2.141174 ],
       [-2.3019922,  1.9271733],
       [-2.2885954,  1.9124153],
       [-2.2813184,  1.9542999],
       [-2.304743 ,  1.8892938],
       [ 2.1249578, -2.089177 ],
       [ 2.043159 , -1.941504 ],
       [-2.1469579,  1.8099191],
       [-2.269732 ,  1.9235427],
       [-2.0776005,  1.7352381],
       [ 1.9634217, -2.0820174],
       [-2.2788396,  1.9341636],
       [-2.2946444,  1.9408271],
       [-2.2920046,  1.9059081],
       [-2.3030152,  1.9264866],
       [ 2.1768198, -2.1458352],
       [-2.301217 ,  1.9053475]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,
       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,
       1, 1, 1, 1, 0, 1]), metrics={'test_loss': 0.015632618218660355, 'test_accuracy': 1.0, 'test_runtime': 0.0391, 'test_samples_per_second': 1280.07, 'test_steps_per_second': 51.203})</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>predictions_all._asdict().keys()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>dict_keys(['predictions', 'label_ids', 'metrics'])</code></pre>
</div>
</div>
<div id="cell-75" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>pred_probs <span class="op">=</span> torch.softmax(torch.tensor(predictions_all.predictions), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>pred_labels <span class="op">=</span> np.argmax(predictions_all.predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> dataset[<span class="st">"test"</span>][<span class="st">"label"</span>]</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(true_labels, pred_labels)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>1.0</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a DataFrame of test predictions</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>test_predictions_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: dataset[<span class="st">"test"</span>][<span class="st">"text"</span>],</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"true_label"</span>: true_labels,</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_label"</span>: pred_labels,</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred_prob"</span>: torch.<span class="bu">max</span>(pred_probs, dim<span class="op">=</span><span class="dv">1</span>).values</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>test_predictions_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A slice of pepperoni pizza with a layer of mel...</td>
<td>1</td>
<td>1</td>
<td>0.984512</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Red brick fireplace with a mantel serving as a...</td>
<td>0</td>
<td>0</td>
<td>0.976215</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A bowl of sliced bell peppers with a sprinkle ...</td>
<td>1</td>
<td>1</td>
<td>0.985432</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Set of mugs hanging on a hook</td>
<td>0</td>
<td>0</td>
<td>0.987212</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Standing floor lamp providing light next to an...</td>
<td>0</td>
<td>0</td>
<td>0.986358</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-77" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show 10 examples with low prediction probability</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - this is good to find samples where the model is unsure </span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>test_predictions_df.sort_values(<span class="st">"pred_prob"</span>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">true_label</th>
<th data-quarto-table-cell-role="th">pred_label</th>
<th data-quarto-table-cell-role="th">pred_prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">11</td>
<td>A close-up shot of a cheesy pizza slice being ...</td>
<td>1</td>
<td>1</td>
<td>0.972105</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Red brick fireplace with a mantel serving as a...</td>
<td>0</td>
<td>0</td>
<td>0.976215</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>Boxes of apples, pears, pineapple, manadrins a...</td>
<td>1</td>
<td>1</td>
<td>0.978392</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>Relaxing on the porch, a couple enjoys the com...</td>
<td>0</td>
<td>0</td>
<td>0.979753</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>Two handfuls of bananas in a fruit bowl with g...</td>
<td>1</td>
<td>1</td>
<td>0.979990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">40</td>
<td>A bowl of cherries with a sprig of mint for ga...</td>
<td>1</td>
<td>1</td>
<td>0.981236</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">39</td>
<td>A close-up of a woman practicing yoga in the l...</td>
<td>0</td>
<td>0</td>
<td>0.981741</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">43</td>
<td>Set of muffin tins stacked together</td>
<td>0</td>
<td>0</td>
<td>0.982799</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>Two people sitting at a dining room table with...</td>
<td>0</td>
<td>0</td>
<td>0.983398</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">26</td>
<td>A fruit platter with a variety of exotic fruit...</td>
<td>1</td>
<td>1</td>
<td>0.983774</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="tk---make-and-inspect-predictions-on-new-text-data" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="tk---make-and-inspect-predictions-on-new-text-data"><span class="header-section-number">7</span> TK - Make and inspect predictions on new text data</h2>
<p>UPTOHERE - load the model (locally + from Hub) - make sure to change the save paths when loading the model to the new paths - make predictions on new text data - build a demo with Gradio (optional)</p>
<p>Making predictions on our own text options.</p>
<p>See: https://huggingface.co/docs/transformers/en/tasks/sequence_classification#inference</p>
<div id="cell-79" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>model_save_dir</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>PosixPath('models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased')</code></pre>
</div>
</div>
<div id="cell-80" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup local model path</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>local_model_path <span class="op">=</span> <span class="st">"models/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup Hugging Face model path (see: https://huggingface.co/mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased)</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>huggingface_model_path <span class="op">=</span> <span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="tk---pipeline-mode" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="tk---pipeline-mode"><span class="header-section-number">7.1</span> TK - Pipeline mode</h3>
<ul>
<li>Tk - what is a pipeline?</li>
</ul>
<div id="cell-82" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: TK - set device agnostic code for CUDA/Mac/CPU?</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_device():</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Set device to CUDA if available, else MPS (Mac), else CPU.</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co">    This defaults to using the best available device (usually).</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> torch.backends.mps.is_available() <span class="kw">and</span> torch.backends.mps.is_built():</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> device</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>DEVICE <span class="op">=</span> set_device()</span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Using device: </span><span class="sc">{</span>DEVICE<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Using device: cuda</code></pre>
</div>
</div>
<div id="cell-83" class="cell" data-outputid="fb71c373-8dc5-42c3-9749-c58ab59253c3" data-execution_count="146">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup batch size for batched inference (can be adjusted depending on how much memory is available)</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co"># TK - why use batch size? -&gt; multiple samples at inference = faster</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>                                    model<span class="op">=</span>local_model_path,</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>                                    batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>                                    device<span class="op">=</span>DEVICE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-84" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>sample_text_food <span class="op">=</span> <span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast"</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="147">
<pre><code>[{'label': 'food', 'score': 0.99871826171875}]</code></pre>
</div>
</div>
<div id="cell-85" class="cell" data-outputid="7d9f1336-883e-474a-cc9a-aa605ba2afc1" data-execution_count="148">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>sample_text_not_food <span class="op">=</span> <span class="st">"A yellow tractor driving over the hill"</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sample_text_not_food)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="148">
<pre><code>[{'label': 'not_food', 'score': 0.9989410042762756}]</code></pre>
</div>
</div>
<div id="cell-86" class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline also works with remote models (will have to laod the model locally first)</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>                                           model<span class="op">=</span>huggingface_model_path,</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>                                           batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>                                           device<span class="op">=</span>DEVICE)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier_remote(<span class="st">"This is some new text about bananas and pancakes and ice cream"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="150">
<pre><code>[{'label': 'food', 'score': 0.9981549382209778}]</code></pre>
</div>
</div>
</section>
<section id="tk---batch-prediction" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="tk---batch-prediction"><span class="header-section-number">7.2</span> TK - Batch prediction</h3>
<ul>
<li>TK - what is batch prediction?</li>
</ul>
<div id="cell-88" class="cell" data-outputid="3a50b522-c155-49fd-8c0e-27541486bca4" data-execution_count="151">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting works with lists</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Can find the examples with highest confidence and keep those</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>,</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"We need to marinate these ideas overnight before presenting them to the client."</span>,</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The new software is definitely a spicy upgrade, taking some time to get used to."</span>,</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Her social media post was the perfect recipe for a viral sensation."</span>,</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"He served up a rebuttal full of facts, leaving his opponent speechless."</span>,</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The team needs to simmer down a bit before tackling the next challenge."</span>,</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Our budget is a bit thin, so we'll have to use budget-friendly materials for this project."</span>,</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The presentation was a delicious blend of humor and information, keeping the audience engaged."</span>,</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Daniel Bourke is really cool :D"</span>,</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"My favoruite food is biltong!"</span></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(sentences)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="151">
<pre><code>[{'label': 'not_food', 'score': 0.9410305619239807},
 {'label': 'not_food', 'score': 0.9650871753692627},
 {'label': 'not_food', 'score': 0.9215793609619141},
 {'label': 'not_food', 'score': 0.9115400910377502},
 {'label': 'not_food', 'score': 0.9625208377838135},
 {'label': 'not_food', 'score': 0.9476941823959351},
 {'label': 'not_food', 'score': 0.9451109170913696},
 {'label': 'not_food', 'score': 0.9027702808380127},
 {'label': 'not_food', 'score': 0.9954429864883423},
 {'label': 'food', 'score': 0.7653573155403137}]</code></pre>
</div>
</div>
</section>
<section id="tk---time-our-model-across-larger-sample-sizes" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="tk---time-our-model-across-larger-sample-sizes"><span class="header-section-number">7.3</span> TK - Time our model across larger sample sizes</h3>
<ul>
<li>TK - our model is fast!</li>
</ul>
<div id="cell-90" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10_000</span>]:</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    sentences_big <span class="op">=</span> sentences <span class="op">*</span> i</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Number of sentences: </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier(sentences_big)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Inference time for </span><span class="sc">{</span><span class="bu">len</span>(sentences_big)<span class="sc">}</span><span class="ss"> sentences: </span><span class="sc">{</span><span class="bu">round</span>(end_time <span class="op">-</span> start_time, <span class="dv">5</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"[INFO] Avg inference time per sentence: </span><span class="sc">{</span><span class="bu">round</span>((end_time <span class="op">-</span> start_time) <span class="op">/</span> <span class="bu">len</span>(sentences_big), <span class="dv">8</span>)<span class="sc">}</span><span class="ss"> seconds."</span>)</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Number of sentences: 100
[INFO] Inference time for 100 sentences: 0.07726 seconds.
[INFO] Avg inference time per sentence: 0.0007726 seconds.

[INFO] Number of sentences: 1000
[INFO] Inference time for 1000 sentences: 0.32344 seconds.
[INFO] Avg inference time per sentence: 0.00032344 seconds.

[INFO] Number of sentences: 10000
[INFO] Inference time for 10000 sentences: 1.43834 seconds.
[INFO] Avg inference time per sentence: 0.00014383 seconds.

[INFO] Number of sentences: 100000
[INFO] Inference time for 100000 sentences: 14.4585 seconds.
[INFO] Avg inference time per sentence: 0.00014459 seconds.

CPU times: user 15.8 s, sys: 552 ms, total: 16.3 s
Wall time: 16.3 s</code></pre>
</div>
</div>
</section>
<section id="pytorch-mode" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="pytorch-mode"><span class="header-section-number">7.4</span> PyTorch mode</h3>
<div id="cell-92" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"learn_hf_food_not_food_text_classifier_model"</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(sample_text_food, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-93" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(<span class="st">"learn_hf_food_not_food_text_classifier_model"</span>)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>  logits <span class="op">=</span> model(<span class="op">**</span>inputs).logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-94" class="cell" data-outputid="bfc30a2d-9a47-441f-f2e9-7cee7fd4989d" data-execution_count="54">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted class</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>predicted_class_id <span class="op">=</span> logits.argmax().item()</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Text: </span><span class="sc">{</span>sample_text_food<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted label: </span><span class="sc">{</span>model<span class="sc">.</span>config<span class="sc">.</span>id2label[predicted_class_id]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Text: A delicious photo of a plate of scrambled eggs, bacon and toast
Predicted label: food</code></pre>
</div>
</div>
</section>
</section>
<section id="tk---turning-our-model-into-a-demo" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="tk---turning-our-model-into-a-demo"><span class="header-section-number">8</span> TK - Turning our model into a demo</h2>
<ul>
<li>TK - why build a demo?
<ul>
<li><ul>
<li>try our model in the wild, see samples which don‚Äôt work properly, e.g.&nbsp;use cases we didn‚Äôt think of‚Ä¶ ‚Äúpie‚Äù/‚Äútea‚Äù (short words), ‚Äúhjflasdjhfhwerr‚Äù (gibberish)</li>
</ul></li>
</ul></li>
<li>TK - build a demo with Gradio, see it here: https://www.gradio.app/guides/quickstart</li>
<li>TK - requires <code>pip install gradio</code></li>
</ul>
<div id="cell-96" class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set top_k=2 to get top 2 predictions (in our case, food and not_food)</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"Testing the pipeline"</span>, top_k<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>[{'label': 'not_food', 'score': 0.9977033734321594},
 {'label': 'food', 'score': 0.002296620048582554}]</code></pre>
</div>
</div>
<section id="tk---creating-a-simple-function-to-perform-inference" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="tk---creating-a-simple-function-to-perform-inference"><span class="header-section-number">8.1</span> TK - Creating a simple function to perform inference</h3>
<ul>
<li>TK - this is required for gradio -&gt; output a dict of {‚Äúlabel_1‚Äù: probability_1, ‚Äúlabel_2‚Äù: probability_2‚Ä¶}</li>
<li>2 options:
<ul>
<li>Local demo (for our own inspection)</li>
<li>Hosted demo on Hugging Face Spaces (for sharing with others)</li>
</ul></li>
</ul>
<div id="cell-98" class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text):</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span>local_model_path,</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>                                        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>,</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a>food_not_food_classifier(<span class="st">"My lunch today was bacon and eggs"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="160">
<pre><code>{'food': 0.7966588139533997, 'not_food': 0.20334114134311676}</code></pre>
</div>
</div>
<div id="cell-99" class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>    fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Food or Not Food Classifier"</span>,</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">"A text classifier to determine if a sentence is about food or not food."</span>,</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>              [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running on local URL:  http://127.0.0.1:7863

To create a public link, set `share=True` in `launch()`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="http://127.0.0.1:7863/" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code></code></pre>
</div>
</div>
</section>
<section id="tk---uploadingrunning-the-demo" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="tk---uploadingrunning-the-demo"><span class="header-section-number">8.2</span> TK - Uploading/running the demo</h3>
<p>Options: * Uploading manually to Hugging Face Spaces - hf.co/new-space * Uploading programmatically to Hugging Face Spaces - https://www.gradio.app/guides/using-hugging-face-integrations#hosting-your-gradio-demos-on-spaces * Running the demo locally - <code>Interface.launch()</code> (only works if you have Gradio installed)</p>
<div id="cell-101" class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a directory for demos</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>demos_dir <span class="op">=</span> Path(<span class="st">"../demos"</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>demos_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a folder for the food_not_food_text_classifer demo</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir <span class="op">=</span> Path(demos_dir, <span class="st">"food_not_food_text_classifier"</span>)</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>food_not_food_text_classifier_demo_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-102" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>app.py</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> food_not_food_classifier(text):</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set up text classification pipeline</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>    food_not_food_classifier <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-classification"</span>, </span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>                                        model<span class="op">=</span><span class="st">"mrdbourke/learn_hf_food_not_food_text_classifier-distilbert-base-uncased"</span>, <span class="co"># link to model on HF Hub</span></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>                                        device<span class="op">=</span><span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>,</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a>                                        top_k<span class="op">=</span><span class="va">None</span>) <span class="co"># return all possible scores (not just top-1)</span></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get outputs from pipeline (as a list of dicts)</span></span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> food_not_food_classifier(text)[<span class="dv">0</span>]</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format output for Gradio (e.g. {"label_1": probability_1, "label_2": probability_2})</span></span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a>    output_dict <span class="op">=</span> {}</span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> outputs:</span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a>        output_dict[item[<span class="st">"label"</span>]] <span class="op">=</span> item[<span class="st">"score"</span>]</span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output_dict</span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a>description <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb99-25"><a href="#cb99-25" aria-hidden="true" tabindex="-1"></a><span class="st">A text classifier to determine if a sentence is about food or not food.</span></span>
<span id="cb99-26"><a href="#cb99-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-27"><a href="#cb99-27" aria-hidden="true" tabindex="-1"></a><span class="st">TK - See source code:</span></span>
<span id="cb99-28"><a href="#cb99-28" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb99-29"><a href="#cb99-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-30"><a href="#cb99-30" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> gr.Interface(fn<span class="op">=</span>food_not_food_classifier, </span>
<span id="cb99-31"><a href="#cb99-31" aria-hidden="true" tabindex="-1"></a>             inputs<span class="op">=</span><span class="st">"text"</span>, </span>
<span id="cb99-32"><a href="#cb99-32" aria-hidden="true" tabindex="-1"></a>             outputs<span class="op">=</span>gr.Label(num_top_classes<span class="op">=</span><span class="dv">2</span>), <span class="co"># show top 2 classes (that's all we have)</span></span>
<span id="cb99-33"><a href="#cb99-33" aria-hidden="true" tabindex="-1"></a>             title<span class="op">=</span><span class="st">"üçóüö´ü•ë Food or Not Food Text Classifier"</span>,</span>
<span id="cb99-34"><a href="#cb99-34" aria-hidden="true" tabindex="-1"></a>             description<span class="op">=</span>description,</span>
<span id="cb99-35"><a href="#cb99-35" aria-hidden="true" tabindex="-1"></a>             examples<span class="op">=</span>[[<span class="st">"I whipped up a fresh batch of code, but it seems to have a syntax error."</span>],</span>
<span id="cb99-36"><a href="#cb99-36" aria-hidden="true" tabindex="-1"></a>                       [<span class="st">"A delicious photo of a plate of scrambled eggs, bacon and toast."</span>]])</span>
<span id="cb99-37"><a href="#cb99-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-38"><a href="#cb99-38" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">"__main__"</span>:</span>
<span id="cb99-39"><a href="#cb99-39" aria-hidden="true" tabindex="-1"></a>    demo.launch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/app.py</code></pre>
</div>
</div>
<p>TK - note: you will often need a requirements.txt file</p>
<pre><code>===== Application Startup at 2024-06-13 05:37:21 =====

Traceback (most recent call last):
  File "/home/user/app/app.py", line 1, in &lt;module&gt;
    import torch
ModuleNotFoundError: No module named 'torch'</code></pre>
<div id="cell-104" class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>requirements.txt</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>gradio</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>torch</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>transformers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/requirements.txt</code></pre>
</div>
</div>
<p>Create a <code>README.md</code> file with metadata instructions (these are specific to Hugging Face Spaces).</p>
<div id="cell-106" class="cell" data-execution_count="166">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile ..<span class="op">/</span>demos<span class="op">/</span>food_not_food_text_classifier<span class="op">/</span>README.md</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>title: Food Not Food Text Classifier</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>emoji: üçóüö´ü•ë</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>colorFrom: blue</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>colorTo: yellow</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>sdk: gradio</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>sdk_version: <span class="fl">4.36.1</span></span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>app_file: app.py</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a>pinned: false</span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a>license: apache<span class="op">-</span><span class="fl">2.0</span></span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a><span class="op">---</span></span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a><span class="co"># üçóüö´ü•ë Food Not Food Text Classifier</span></span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a>Small demo to showcase a text classifier to determine <span class="cf">if</span> a sentence <span class="kw">is</span> about food <span class="kw">or</span> <span class="kw">not</span> food.</span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a>DistillBERT model fine<span class="op">-</span>tuned on a small synthetic dataset of <span class="dv">250</span> generated [Food <span class="kw">or</span> Not Food image captions](https:<span class="op">//</span>huggingface.co<span class="op">/</span>datasets<span class="op">/</span>mrdbourke<span class="op">/</span>learn_hf_food_not_food_image_captions).</span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a>TK <span class="op">-</span> see the demo notebook on how to create this</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting ../demos/food_not_food_text_classifier/README.md</code></pre>
</div>
</div>
<div id="cell-107" class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> (</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    create_repo,</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    get_full_repo_name,</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    upload_file, <span class="co"># for uploading a single file</span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    upload_folder <span class="co"># for uploading multiple files (in a folder)</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>path_to_demo_folder <span class="op">=</span> <span class="st">"../demos/food_not_food_text_classifier"</span></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>repo_type <span class="op">=</span> <span class="st">"space"</span> <span class="co"># we're creating a Hugging Face Space</span></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a repo on Hugging Face</span></span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a><span class="co"># see docs: https://huggingface.co/docs/huggingface_hub/v0.23.3/en/package_reference/hf_api#huggingface_hub.HfApi.create_repo</span></span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>target_space_name <span class="op">=</span> <span class="st">"learn_hf_food_not_food_text_classifier_demo"</span></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Creating repo: </span><span class="sc">{</span>target_space_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>create_repo(</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>target_space_name,</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#token="YOUR_HF_TOKEN"</span></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>    private<span class="op">=</span><span class="va">False</span>, <span class="co"># set to True if you want the repo to be private</span></span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>repo_type, <span class="co"># create a Hugging Face Space</span></span>
<span id="cb106-20"><a href="#cb106-20" aria-hidden="true" tabindex="-1"></a>    space_sdk<span class="op">=</span><span class="st">"gradio"</span>, <span class="co"># we're using Gradio to build our demo </span></span>
<span id="cb106-21"><a href="#cb106-21" aria-hidden="true" tabindex="-1"></a>    exist_ok<span class="op">=</span><span class="va">True</span>, <span class="co"># set to False if you want to create the repo even if it already exists            </span></span>
<span id="cb106-22"><a href="#cb106-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb106-23"><a href="#cb106-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-24"><a href="#cb106-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the full repo name (e.g. "mrdbourke/learn_hf_food_not_food_text_classifier_demo")</span></span>
<span id="cb106-25"><a href="#cb106-25" aria-hidden="true" tabindex="-1"></a>full_repo_name <span class="op">=</span> get_full_repo_name(model_id<span class="op">=</span>target_space_name)</span>
<span id="cb106-26"><a href="#cb106-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Full repo name: </span><span class="sc">{</span>full_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb106-27"><a href="#cb106-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-28"><a href="#cb106-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload a file</span></span>
<span id="cb106-29"><a href="#cb106-29" aria-hidden="true" tabindex="-1"></a><span class="co"># see docs: https://huggingface.co/docs/huggingface_hub/v0.23.3/en/package_reference/hf_api#huggingface_hub.HfApi.upload_file </span></span>
<span id="cb106-30"><a href="#cb106-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"[INFO] Uploading </span><span class="sc">{</span>path_to_demo_folder<span class="sc">}</span><span class="ss"> to repo: </span><span class="sc">{</span>full_repo_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb106-31"><a href="#cb106-31" aria-hidden="true" tabindex="-1"></a>file_url <span class="op">=</span> upload_folder(</span>
<span id="cb106-32"><a href="#cb106-32" aria-hidden="true" tabindex="-1"></a>    folder_path<span class="op">=</span>path_to_demo_folder,</span>
<span id="cb106-33"><a href="#cb106-33" aria-hidden="true" tabindex="-1"></a>    path_in_repo<span class="op">=</span><span class="st">"."</span>, <span class="co"># save to the root of the repo</span></span>
<span id="cb106-34"><a href="#cb106-34" aria-hidden="true" tabindex="-1"></a>    repo_id<span class="op">=</span>full_repo_name,</span>
<span id="cb106-35"><a href="#cb106-35" aria-hidden="true" tabindex="-1"></a>    repo_type<span class="op">=</span>repo_type,</span>
<span id="cb106-36"><a href="#cb106-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">#token="YOUR_HF_TOKEN"</span></span>
<span id="cb106-37"><a href="#cb106-37" aria-hidden="true" tabindex="-1"></a>    commit_message<span class="op">=</span><span class="st">"Uploading food not food text classifier demo app.py"</span></span>
<span id="cb106-38"><a href="#cb106-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[INFO] Creating repo: learn_hf_food_not_food_text_classifier_demo
[INFO] Full repo name: mrdbourke/learn_hf_food_not_food_text_classifier_demo
[INFO] Uploading ../demos/food_not_food_text_classifier to repo: mrdbourke/learn_hf_food_not_food_text_classifier_demo</code></pre>
</div>
</div>
<ul>
<li>TK - see the demo link here: https://huggingface.co/spaces/mrdbourke/learn_hf_food_not_food_text_classifier_demo</li>
</ul>
</section>
<section id="tk---testing-the-live-demo" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="tk---testing-the-live-demo"><span class="header-section-number">8.3</span> TK - Testing the live demo</h3>
<div id="cell-110" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a><span class="co"># You can get embeddable HTML code for your demo by clicking the "Embed" button on the demo page</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>HTML(<span class="st">'''</span></span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;iframe</span></span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a><span class="st">    src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space"</span></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a><span class="st">    frameborder="0"</span></span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a><span class="st">    width="850"</span></span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a><span class="st">    height="450"</span></span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a><span class="st">&gt;&lt;/iframe&gt;     </span></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

<iframe src="https://mrdbourke-learn-hf-food-not-food-text-classifier-demo.hf.space" frameborder="0" width="850" height="450"></iframe>     
</div>
</div>
</section>
</section>
<section id="tk---exercises-and-extensions" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="tk---exercises-and-extensions"><span class="header-section-number">9</span> TK - Exercises and Extensions</h2>
<ul>
<li>Where does our model fail? E.g. what kind of sentences does it struggle with? How could you fix this?
<ul>
<li>Make an extra 10-50 examples of these and add them to the dataset and then retrain the model</li>
<li>See here: https://discuss.huggingface.co/t/how-do-i-add-things-rows-to-an-already-saved-dataset/27423</li>
</ul></li>
<li>Build your own text classifier on a different dataset/your own custom dataset</li>
<li>How might we make our dataset multi-class? (e.g.&nbsp;more than 2 classes)</li>
</ul>
</section>
<section id="tk---extra-resources" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="tk---extra-resources"><span class="header-section-number">10</span> TK - Extra resources</h2>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"016181d9f51a4abea666046fb95f2aee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f82250d2e14f198dd0f561969d54ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0233456210f8469f85e648ba1c1f83ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2afc2c8167ad4d15ab6a35c1d1f1f3cb","max":152322,"min":0,"orientation":"horizontal","style":"IPY_MODEL_070785d29788406db9369ce39e24b7cf","value":152322}},"054e759a27a442afa8c666fc3d4c3f2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0673f25c77b04212bc2b63f56454a5d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"070785d29788406db9369ce39e24b7cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eaf7b7abd71413597e0533efa3feda2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c56c3c1ff2a040b0952b5bac655b71dc","placeholder":"‚Äã","style":"IPY_MODEL_3d5b841a59a3489ea5b4112182d4ae70","value":"‚Äá48.0/48.0‚Äá[00:00&lt;00:00,‚Äá3.86kB/s]"}},"103ff0dd04da40a69d85763bbf571490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13b1494b02194773a5fafe39b211c88a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1aa8fdd087ce42bdb16ae19a38e79b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ef815be4ac4b64b3b3d99a6c43fadb","placeholder":"‚Äã","style":"IPY_MODEL_d1cc110825034545a2532fc567b5325e","value":"‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá3.49MB/s]"}},"1b61ce44fb554db2bb906fb39b41b7e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5d45fa6fb14097bf36584ec7ef651c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ccbc146f4ad4382879b5d8b526cac4e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fda99413adc8497cba92a9c6416f77ad","value":231508}},"20a883d10ea945a9889429c5efb76a43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2afc2c8167ad4d15ab6a35c1d1f1f3cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cb043cfb0fc448e81a34710d65bb691":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f44328dc8a04f84a59e26d08d343c77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31cf1f106af54f7986b4d2f462125cca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_506baa608274455eae12e54e1d7b7dd5","placeholder":"‚Äã","style":"IPY_MODEL_103ff0dd04da40a69d85763bbf571490","value":"vocab.txt:‚Äá100%"}},"347ce846f3564c58ac1eb26ae2f3adc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a20bdb762700449097d5010ce7d29921","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cb043cfb0fc448e81a34710d65bb691","value":4203}},"34edb9945bb54a69868d62ecd5b1ae56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35205e647f814b97a2e977af48cc7a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8580f622bac8422a992b56b5f39b3693","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca74fdefa7844f11b1d9052269efd585","value":48}},"37cede645a5b48a9b89df987b9ef91e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39f3c0ec5b4446cda93df7a999d4fd41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5b841a59a3489ea5b4112182d4ae70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"470f2248b2444869914197c7481e10ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e1a02cf71743ec9da128ff6c882f34","placeholder":"‚Äã","style":"IPY_MODEL_6429d7801ba14ed4861726bd7832ecee","value":"config.json:‚Äá100%"}},"495cd338f7614f7a9a68fc3dc3916dcf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b6f81607c31496a83d5964983fed168":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c92f17cff2944a9a2a49be56649d81e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df9f85ae9e943ceb3ed1a5d9e143f5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ef091cf8c084af1acb95d62ffe1f0f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_495cd338f7614f7a9a68fc3dc3916dcf","placeholder":"‚Äã","style":"IPY_MODEL_dc17c88c62244e2f9a574ef895132a83","value":"tokenizer_config.json:‚Äá100%"}},"4ef76858d67f4ee6a99b305edb682a43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8713c60a0947ae86ee9d1d4de8ab3a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"506baa608274455eae12e54e1d7b7dd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"522f6c1e5e7340039b7bbf700704699f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6294e85e97a8495bb18d11dff1991a79","placeholder":"‚Äã","style":"IPY_MODEL_91ee20aae0474a4c90a26463f72bacf1","value":"‚Äá30465/30465‚Äá[00:00&lt;00:00,‚Äá31103.17‚Äáexamples/s]"}},"54e1a02cf71743ec9da128ff6c882f34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5616046a1d1347cfbbe82fa67b79af1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"593b4aaa5c9e4e1898cc4d5064940770":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b1fd51b695b4c81ab351ed5b1f92966":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e84d7134b646f6b291b0439d9ec890":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6294e85e97a8495bb18d11dff1991a79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e64e93abca400293b7b7742bd94aaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b791095b95214d82af1e344a2b5898a2","placeholder":"‚Äã","style":"IPY_MODEL_a3fa870efa0f4463b1e60fa106f782f1","value":"‚Äá268M/268M‚Äá[00:01&lt;00:00,‚Äá287MB/s]"}},"6429d7801ba14ed4861726bd7832ecee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64513b9e43254d5a9bbbffc9cb9a054c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a7b459551104d47a90527c885647830":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8713c60a0947ae86ee9d1d4de8ab3a","placeholder":"‚Äã","style":"IPY_MODEL_4b6f81607c31496a83d5964983fed168","value":"‚Äá483/483‚Äá[00:00&lt;00:00,‚Äá39.6kB/s]"}},"6cdf8319c7184ee5b107cea1718b03c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ef091cf8c084af1acb95d62ffe1f0f2","IPY_MODEL_35205e647f814b97a2e977af48cc7a17","IPY_MODEL_0eaf7b7abd71413597e0533efa3feda2"],"layout":"IPY_MODEL_34edb9945bb54a69868d62ecd5b1ae56"}},"72df691ec7784ae7b0542171a7789555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f3c0ec5b4446cda93df7a999d4fd41","placeholder":"‚Äã","style":"IPY_MODEL_bb7f6dabc3ad4779a87b211227040606","value":"‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá2.36MB/s]"}},"79144b8d1ec44b6bb3dcc381f7e829ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b91cb6b9b5e4ba891a6cfaab2d5948b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80995fb6ed6f4557b1037dea2798b2fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb256ba48acd446bbe6b832c9558f7c6","placeholder":"‚Äã","style":"IPY_MODEL_4ef76858d67f4ee6a99b305edb682a43","value":"‚Äá121857/121857‚Äá[00:04&lt;00:00,‚Äá25895.88‚Äáexamples/s]"}},"80ef815be4ac4b64b3b3d99a6c43fadb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8580f622bac8422a992b56b5f39b3693":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c3f85da75764955a572261460db619b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2f32fe9433d458dbc278da438f27449","max":121857,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64513b9e43254d5a9bbbffc9cb9a054c","value":121857}},"8fc36b3359d24eb987c4be9eaf5d4e95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b2772488464e80b333332d6cd46eeb","placeholder":"‚Äã","style":"IPY_MODEL_5616046a1d1347cfbbe82fa67b79af1a","value":"model.safetensors:‚Äá100%"}},"90455578408b4f33bc9a9c732d431236":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2e056a63fd34329a21330a4fc69429d","IPY_MODEL_347ce846f3564c58ac1eb26ae2f3adc4","IPY_MODEL_9a01bb7c8f5e4940ba2444fa63a3db6f"],"layout":"IPY_MODEL_b8beefe086284c7297004fcad9303617"}},"91ee20aae0474a4c90a26463f72bacf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9455512d944c418b87e4d1fe324619e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b93a51136d1146e08914db125d0259fb","IPY_MODEL_c74948f6d29e4e0e868a3ccf836d2377","IPY_MODEL_522f6c1e5e7340039b7bbf700704699f"],"layout":"IPY_MODEL_0673f25c77b04212bc2b63f56454a5d2"}},"985174675f354a9bb2580a70ad2b7625":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9e83e2c1d2f4970a0905efde0055e3d","IPY_MODEL_8c3f85da75764955a572261460db619b","IPY_MODEL_80995fb6ed6f4557b1037dea2798b2fb"],"layout":"IPY_MODEL_016181d9f51a4abea666046fb95f2aee"}},"9a01bb7c8f5e4940ba2444fa63a3db6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8d8eac2274a4040a4163663896753f7","placeholder":"‚Äã","style":"IPY_MODEL_01f82250d2e14f198dd0f561969d54ff","value":"‚Äá4.20k/4.20k‚Äá[00:00&lt;00:00,‚Äá379kB/s]"}},"9ccbc146f4ad4382879b5d8b526cac4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20bdb762700449097d5010ce7d29921":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2e056a63fd34329a21330a4fc69429d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_593b4aaa5c9e4e1898cc4d5064940770","placeholder":"‚Äã","style":"IPY_MODEL_4df9f85ae9e943ceb3ed1a5d9e143f5c","value":"Downloading‚Äábuilder‚Äáscript:‚Äá100%"}},"a3fa870efa0f4463b1e60fa106f782f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5076ac1d4ad4c09aa1e6f12449915af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae6d2d013c03448887d53f8a0760e77d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6c20dee590f40e5b2c96beefc1643e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6cb26e5df334ac980005863a38581a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b791095b95214d82af1e344a2b5898a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8beefe086284c7297004fcad9303617":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d8eac2274a4040a4163663896753f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93a51136d1146e08914db125d0259fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_054e759a27a442afa8c666fc3d4c3f2e","placeholder":"‚Äã","style":"IPY_MODEL_e4633e912a57492497bc2fbfad02351c","value":"Map:‚Äá100%"}},"b9e83e2c1d2f4970a0905efde0055e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b1fd51b695b4c81ab351ed5b1f92966","placeholder":"‚Äã","style":"IPY_MODEL_a5076ac1d4ad4c09aa1e6f12449915af","value":"Map:‚Äá100%"}},"bb7f6dabc3ad4779a87b211227040606":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb76be168f840d79c950efc4bdfc8d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8d378a142934482aa04a608ada9acdb","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6c20dee590f40e5b2c96beefc1643e1","value":267954768}},"c0028b925edf40ecb94ee219a26dfe36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6cb26e5df334ac980005863a38581a1","placeholder":"‚Äã","style":"IPY_MODEL_ae6d2d013c03448887d53f8a0760e77d","value":"‚Äá152322/152322‚Äá[00:06&lt;00:00,‚Äá24189.50‚Äáexamples/s]"}},"c3faf065f2d2435697fb730bf04ff1cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fc36b3359d24eb987c4be9eaf5d4e95","IPY_MODEL_beb76be168f840d79c950efc4bdfc8d1","IPY_MODEL_63e64e93abca400293b7b7742bd94aaf"],"layout":"IPY_MODEL_d41ef095cc5b4c23b31236b501dcf8c1"}},"c4055bbdeb6c4833b4fb50970248a154":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31cf1f106af54f7986b4d2f462125cca","IPY_MODEL_1c5d45fa6fb14097bf36584ec7ef651c","IPY_MODEL_1aa8fdd087ce42bdb16ae19a38e79b27"],"layout":"IPY_MODEL_ef3b72dea05d404db610152cb17ba8f9"}},"c45933bed8084b53b562621699870695":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37cede645a5b48a9b89df987b9ef91e2","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13b1494b02194773a5fafe39b211c88a","value":466062}},"c56c3c1ff2a040b0952b5bac655b71dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6cbefbc4f4d4cfe98400aa05370e3e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0c86013f8194633be0ac27ca9b8876c","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b91cb6b9b5e4ba891a6cfaab2d5948b","value":483}},"c74948f6d29e4e0e868a3ccf836d2377":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79144b8d1ec44b6bb3dcc381f7e829ce","max":30465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60e84d7134b646f6b291b0439d9ec890","value":30465}},"ca74fdefa7844f11b1d9052269efd585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca79aac952ca41c096241ad371c055fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b61ce44fb554db2bb906fb39b41b7e0","placeholder":"‚Äã","style":"IPY_MODEL_dcc6949983954dfb9b7f8bd0ad6cd6d8","value":"Map:‚Äá100%"}},"cf51cae23d2b4026a4f890069983da4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca79aac952ca41c096241ad371c055fe","IPY_MODEL_0233456210f8469f85e648ba1c1f83ff","IPY_MODEL_c0028b925edf40ecb94ee219a26dfe36"],"layout":"IPY_MODEL_d4a7a1f7a10040ccb07704d845de6cd6"}},"d0080133b35c40578eba5db18dc82db6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0c86013f8194633be0ac27ca9b8876c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1cc110825034545a2532fc567b5325e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d41ef095cc5b4c23b31236b501dcf8c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a7a1f7a10040ccb07704d845de6cd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6b2772488464e80b333332d6cd46eeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc17c88c62244e2f9a574ef895132a83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcc6949983954dfb9b7f8bd0ad6cd6d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2f32fe9433d458dbc278da438f27449":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4633e912a57492497bc2fbfad02351c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb256ba48acd446bbe6b832c9558f7c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec74087b5c9d4e538675956af72ae138":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe87ce116db84d5ba3d00e4a8c249dc1","IPY_MODEL_c45933bed8084b53b562621699870695","IPY_MODEL_72df691ec7784ae7b0542171a7789555"],"layout":"IPY_MODEL_4c92f17cff2944a9a2a49be56649d81e"}},"ef3b72dea05d404db610152cb17ba8f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1fa4e09b42c4904b9be033d33943e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_470f2248b2444869914197c7481e10ae","IPY_MODEL_c6cbefbc4f4d4cfe98400aa05370e3e7","IPY_MODEL_6a7b459551104d47a90527c885647830"],"layout":"IPY_MODEL_d0080133b35c40578eba5db18dc82db6"}},"f8d378a142934482aa04a608ada9acdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda99413adc8497cba92a9c6416f77ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe87ce116db84d5ba3d00e4a8c249dc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a883d10ea945a9889429c5efb76a43","placeholder":"‚Äã","style":"IPY_MODEL_2f44328dc8a04f84a59e26d08d343c77","value":"tokenizer.json:‚Äá100%"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mrdbourke\.github\.io\/learn-huggingface\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>